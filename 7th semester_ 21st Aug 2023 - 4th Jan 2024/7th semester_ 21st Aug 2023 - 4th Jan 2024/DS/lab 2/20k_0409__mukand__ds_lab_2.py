# -*- coding: utf-8 -*-
"""20K-0409_ Mukand_ DS_LAB#2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZiHuDLT_gFzO3JH7DCFsgONiZipxWioJ
"""

import pandas as pd
import numpy as np

df1 = pd.read_csv('data1.csv', index_col=0)
df2 = pd.read_csv('data2.csv', index_col=1)

print("data 1: \n", df1)
print("\ndata 2: \n", df2)

"""## Concat
b. Modify (a) to concatenate df1 and df2 and assign it to df3. Print df3
"""

df3 = pd.concat([df1, df2], axis = 0, join='outer')
print("Concated data in df 3 : \n", df3)

"""## Read data 4 as df4, merging data
c. Read data3.csv as df4 dataframe object and print df4
"""

df4 = pd.read_csv('data3.csv', index_col=0)

df5 = pd.concat([df3, df4], axis=1, join='outer')
print(df5)

"""d. Read data.json as df6 and concatenate with df5."""

df6 = pd.read_json('data.json')
print(df6)


df7 = pd.concat([df5, df6], axis=0, ignore_index=True)
print(df7)

"""e. Replace Hello with NaN."""

df7 = df7.replace('Hello', value=np.nan)
print(df7)

"""f. Replace NaN with mean values of the columns."""

df7.fillna(df7.mean(), inplace=True)

df7.to_csv("newdata.csv")
print(df7)

"""#**TASK 2**"""

import pandas as pd
import numpy as np

df = pd.read_csv('BL-Flickr-Images-Book.csv')

df.head(5)
df.columns

# Dropping columns

to_drop = ['Edition Statement',
           'Corporate Author',
           'Corporate Contributors',
           'Former owner',
           'Engraver',
           'Contributors',
           'Issuance type',
           'Shelfmarks']

df.drop(to_drop, inplace=True, axis=1)
df.head()


# Changing the index of a DataFrame

df = df.set_index('Identifier')
df.head()

# Accessing records using loc[]:
df.loc[206]

data = pd.read_csv('BL-Flickr-Images-Book.csv')

# Cleaning the 'Date of Publication' column:

extr = data['Date of Publication'].str.extract(r'^(\\d{4})', expand=False)
extr.head()
data['Date of Publication'] = pd.to_numeric(extr)
data['Date of Publication'].dtype
data['Date of Publication'].isnull().sum() / len(df)

# Cleaning 'Place of Publication' column:

pub = data['Place of Publication']
london = pub.str.contains('London')
london[:5]
oxford = pub.str.contains('Oxford')
data['Place of Publication'] = np.where(london, 'London',
                                      np.where(oxford, 'Oxford',
                                               pub.str.replace('-', ' ')))
data['Place of Publication'].head()
#  cleaned DataFrame:

data.head(5)

olympics_df = pd.read_csv('olympics.csv')
olympics_df.head()


new_names =  {'Unnamed: 0': 'Country', '? Summer': 'Summer Olympics', '01 !': 'Gold', '02 !': 'Silver','03 !': 'Bronze', '? Winter': 'Winter Olympics','01 !.1': 'Gold.1',
               '02 !.1': 'Silver.1', '03 !.1': 'Bronze.1', '? Games': '# Games', '01 !.2': 'Gold.2', '02 !.2': 'Silver.2', '03 !.2': 'Bronze.2'}

olympics_df.rename(columns=new_names, inplace=True)
olympics_df.head()

