{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "2yYlGliiIfBJ",
        "outputId": "8a2f2fba-055d-4887-9c6b-05cdf5e10de2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     8-QAM  Unnamed: 1  \\\n",
              "0    1.22474487139159 - 0.408248290463863i         NaN   \n",
              "1   0.408248290463863 - 0.408248290463863i         NaN   \n",
              "2   -1.22474487139159 - 0.408248290463863i         NaN   \n",
              "3  -0.408248290463863 + 0.408248290463863i         NaN   \n",
              "4   -1.22474487139159 + 0.408248290463863i         NaN   \n",
              "\n",
              "                                    32-QAM  Unnamed: 3  \\\n",
              "0   -1.11803398874990 - 0.670820393249937i         NaN   \n",
              "1  -0.223606797749979 + 0.223606797749979i         NaN   \n",
              "2  -0.670820393249937 + 0.670820393249937i         NaN   \n",
              "3   -0.223606797749979 - 1.11803398874990i         NaN   \n",
              "4   -1.11803398874990 - 0.670820393249937i         NaN   \n",
              "\n",
              "                                   128-QAM  Unnamed: 5  \\\n",
              "0  -0.773020682523926 - 0.993883734673619i         NaN   \n",
              "1  -0.773020682523926 - 0.552157630374233i         NaN   \n",
              "2    1.21474678682331 - 0.110431526074847i         NaN   \n",
              "3  -0.993883734673619 + 0.110431526074847i         NaN   \n",
              "4   0.773020682523926 + 0.331294578224540i         NaN   \n",
              "\n",
              "                                      OFDM  Unnamed: 7  \\\n",
              "0  -0.773020682523926 - 0.993883734673619i         NaN   \n",
              "1  -0.773020682523926 - 0.552157630374233i         NaN   \n",
              "2    1.21474678682331 - 0.110431526074847i         NaN   \n",
              "3  -0.993883734673619 + 0.110431526074847i         NaN   \n",
              "4   0.773020682523926 + 0.331294578224540i         NaN   \n",
              "\n",
              "                                           LTE  \n",
              "0    -0.0227232682938660 + 0.0258335168130960i  \n",
              "1    -0.0194529249087370 - 0.0121231728678195i  \n",
              "2    0.0128642672165898 - 0.00221777822416349i  \n",
              "3  0.00947980732883384 - 0.000851714289104194i  \n",
              "4   -0.0396036825815445 + 0.00974998525029402i  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-762d62ae-9a9b-4d4f-9ef8-33564b3d5358\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>8-QAM</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>32-QAM</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>128-QAM</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>OFDM</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>LTE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.22474487139159 - 0.408248290463863i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.11803398874990 - 0.670820393249937i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.773020682523926 - 0.993883734673619i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.773020682523926 - 0.993883734673619i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.0227232682938660 + 0.0258335168130960i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.408248290463863 - 0.408248290463863i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.223606797749979 + 0.223606797749979i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.773020682523926 - 0.552157630374233i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.773020682523926 - 0.552157630374233i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.0194529249087370 - 0.0121231728678195i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.22474487139159 - 0.408248290463863i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.670820393249937 + 0.670820393249937i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.21474678682331 - 0.110431526074847i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.21474678682331 - 0.110431526074847i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0128642672165898 - 0.00221777822416349i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.408248290463863 + 0.408248290463863i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.223606797749979 - 1.11803398874990i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.993883734673619 + 0.110431526074847i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.993883734673619 + 0.110431526074847i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00947980732883384 - 0.000851714289104194i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.22474487139159 + 0.408248290463863i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.11803398874990 - 0.670820393249937i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.773020682523926 + 0.331294578224540i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.773020682523926 + 0.331294578224540i</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.0396036825815445 + 0.00974998525029402i</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-762d62ae-9a9b-4d4f-9ef8-33564b3d5358')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-762d62ae-9a9b-4d4f-9ef8-33564b3d5358 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-762d62ae-9a9b-4d4f-9ef8-33564b3d5358');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b95971a-29fc-452f-a71d-3d4e5f15dc5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b95971a-29fc-452f-a71d-3d4e5f15dc5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b95971a-29fc-452f-a71d-3d4e5f15dc5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "df = pd.read_csv('Dataset1 (1).csv')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lcOhfcpI-4a",
        "outputId": "bcf3f743-b1c3-42ca-b9cd-b1adc57eef01"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38400 entries, 0 to 38399\n",
            "Data columns (total 9 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   8-QAM       20000 non-null  object \n",
            " 1   Unnamed: 1  0 non-null      float64\n",
            " 2   32-QAM      12000 non-null  object \n",
            " 3   Unnamed: 3  0 non-null      float64\n",
            " 4   128-QAM     8571 non-null   object \n",
            " 5   Unnamed: 5  0 non-null      float64\n",
            " 6   OFDM        8571 non-null   object \n",
            " 7   Unnamed: 7  0 non-null      float64\n",
            " 8   LTE         38400 non-null  object \n",
            "dtypes: float64(4), object(5)\n",
            "memory usage: 2.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.dropna(axis=1, how='all', inplace=True)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEDgVPmUI18A",
        "outputId": "f520a401-ed01-48e6-e645-f6b2647760d8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         8-QAM  \\\n",
            "0        1.22474487139159 - 0.408248290463863i   \n",
            "1       0.408248290463863 - 0.408248290463863i   \n",
            "2       -1.22474487139159 - 0.408248290463863i   \n",
            "3      -0.408248290463863 + 0.408248290463863i   \n",
            "4       -1.22474487139159 + 0.408248290463863i   \n",
            "...                                        ...   \n",
            "38395                                      NaN   \n",
            "38396                                      NaN   \n",
            "38397                                      NaN   \n",
            "38398                                      NaN   \n",
            "38399                                      NaN   \n",
            "\n",
            "                                        32-QAM  \\\n",
            "0       -1.11803398874990 - 0.670820393249937i   \n",
            "1      -0.223606797749979 + 0.223606797749979i   \n",
            "2      -0.670820393249937 + 0.670820393249937i   \n",
            "3       -0.223606797749979 - 1.11803398874990i   \n",
            "4       -1.11803398874990 - 0.670820393249937i   \n",
            "...                                        ...   \n",
            "38395                                      NaN   \n",
            "38396                                      NaN   \n",
            "38397                                      NaN   \n",
            "38398                                      NaN   \n",
            "38399                                      NaN   \n",
            "\n",
            "                                       128-QAM  \\\n",
            "0      -0.773020682523926 - 0.993883734673619i   \n",
            "1      -0.773020682523926 - 0.552157630374233i   \n",
            "2        1.21474678682331 - 0.110431526074847i   \n",
            "3      -0.993883734673619 + 0.110431526074847i   \n",
            "4       0.773020682523926 + 0.331294578224540i   \n",
            "...                                        ...   \n",
            "38395                                      NaN   \n",
            "38396                                      NaN   \n",
            "38397                                      NaN   \n",
            "38398                                      NaN   \n",
            "38399                                      NaN   \n",
            "\n",
            "                                          OFDM  \\\n",
            "0      -0.773020682523926 - 0.993883734673619i   \n",
            "1      -0.773020682523926 - 0.552157630374233i   \n",
            "2        1.21474678682331 - 0.110431526074847i   \n",
            "3      -0.993883734673619 + 0.110431526074847i   \n",
            "4       0.773020682523926 + 0.331294578224540i   \n",
            "...                                        ...   \n",
            "38395                                      NaN   \n",
            "38396                                      NaN   \n",
            "38397                                      NaN   \n",
            "38398                                      NaN   \n",
            "38399                                      NaN   \n",
            "\n",
            "                                               LTE  \n",
            "0        -0.0227232682938660 + 0.0258335168130960i  \n",
            "1        -0.0194529249087370 - 0.0121231728678195i  \n",
            "2        0.0128642672165898 - 0.00221777822416349i  \n",
            "3      0.00947980732883384 - 0.000851714289104194i  \n",
            "4       -0.0396036825815445 + 0.00974998525029402i  \n",
            "...                                            ...  \n",
            "38395    0.00834641044530244 - 0.0129987117038719i  \n",
            "38396   -0.0145435491097858 - 0.00241052572985562i  \n",
            "38397    0.00324006845705913 + 0.0136952910353754i  \n",
            "38398    0.0109718045501465 - 0.00782518587892983i  \n",
            "38399   -0.0109144739359003 - 0.00702302718609357i  \n",
            "\n",
            "[38400 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df['8-QAM '].head()\n",
        "# df.columns\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0yowfUZLm6t",
        "outputId": "0e20fa77-e87f-44f2-8ee5-e4519cf1bfb7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38400, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P-o4VjbJwbc",
        "outputId": "9ccd9388-b0f3-438d-97df-ffe551cf5fa0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['8-QAM', '32-QAM', '128-QAM', 'OFDM', 'LTE'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCN9Y6gFTZUO",
        "outputId": "1cf8e2d2-1759-4080-e463-4c93ce7ba6ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38400 entries, 0 to 38399\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   8-QAM    20000 non-null  object\n",
            " 1   32-QAM   12000 non-null  object\n",
            " 2   128-QAM  8571 non-null   object\n",
            " 3   OFDM     8571 non-null   object\n",
            " 4   LTE      38400 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K48BL37Zb9Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTwbljS8MCXk",
        "outputId": "de96af6d-c1d6-4641-e33b-60fd0c78f77c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8571, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: drop null rows\n",
        "\n",
        "df.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "6ueYfujSNKC_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove white spaces\n",
        "for col in df.columns:\n",
        "    df[col] = df[col].str.replace(' ', '')\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ansaFSf5KtvX",
        "outputId": "ac789c6d-9ec9-4244-9dce-a9b3366f98ec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      8-QAM  \\\n",
            "0       1.22474487139159-0.408248290463863i   \n",
            "1      0.408248290463863-0.408248290463863i   \n",
            "2      -1.22474487139159-0.408248290463863i   \n",
            "3     -0.408248290463863+0.408248290463863i   \n",
            "4      -1.22474487139159+0.408248290463863i   \n",
            "...                                     ...   \n",
            "8566  -0.408248290463863+0.408248290463863i   \n",
            "8567   -1.22474487139159+0.408248290463863i   \n",
            "8568  -0.408248290463863-0.408248290463863i   \n",
            "8569   -1.22474487139159+0.408248290463863i   \n",
            "8570   -1.22474487139159-0.408248290463863i   \n",
            "\n",
            "                                     32-QAM  \\\n",
            "0      -1.11803398874990-0.670820393249937i   \n",
            "1     -0.223606797749979+0.223606797749979i   \n",
            "2     -0.670820393249937+0.670820393249937i   \n",
            "3      -0.223606797749979-1.11803398874990i   \n",
            "4      -1.11803398874990-0.670820393249937i   \n",
            "...                                     ...   \n",
            "8566   0.670820393249937+0.670820393249937i   \n",
            "8567   0.670820393249937+0.670820393249937i   \n",
            "8568  -0.223606797749979+0.670820393249937i   \n",
            "8569   -0.223606797749979+1.11803398874990i   \n",
            "8570    0.670820393249937+1.11803398874990i   \n",
            "\n",
            "                                    128-QAM  \\\n",
            "0     -0.773020682523926-0.993883734673619i   \n",
            "1     -0.773020682523926-0.552157630374233i   \n",
            "2       1.21474678682331-0.110431526074847i   \n",
            "3     -0.993883734673619+0.110431526074847i   \n",
            "4      0.773020682523926+0.331294578224540i   \n",
            "...                                     ...   \n",
            "8566  -0.331294578224540+0.773020682523926i   \n",
            "8567   0.993883734673619-0.773020682523926i   \n",
            "8568   0.552157630374233+0.773020682523926i   \n",
            "8569   0.773020682523926+0.331294578224540i   \n",
            "8570  -0.552157630374233+0.331294578224540i   \n",
            "\n",
            "                                       OFDM  \\\n",
            "0     -0.773020682523926-0.993883734673619i   \n",
            "1     -0.773020682523926-0.552157630374233i   \n",
            "2       1.21474678682331-0.110431526074847i   \n",
            "3     -0.993883734673619+0.110431526074847i   \n",
            "4      0.773020682523926+0.331294578224540i   \n",
            "...                                     ...   \n",
            "8566  -0.331294578224540+0.773020682523926i   \n",
            "8567   0.993883734673619-0.773020682523926i   \n",
            "8568   0.552157630374233+0.773020682523926i   \n",
            "8569   0.773020682523926+0.331294578224540i   \n",
            "8570  -0.552157630374233+0.331294578224540i   \n",
            "\n",
            "                                            LTE  \n",
            "0       -0.0227232682938660+0.0258335168130960i  \n",
            "1       -0.0194529249087370-0.0121231728678195i  \n",
            "2       0.0128642672165898-0.00221777822416349i  \n",
            "3     0.00947980732883384-0.000851714289104194i  \n",
            "4      -0.0396036825815445+0.00974998525029402i  \n",
            "...                                         ...  \n",
            "8566    -0.0134020184082583+0.0151515590934546i  \n",
            "8567    0.0178589901836325+0.00442549831866548i  \n",
            "8568   -0.00370077804665655-0.0160566215312079i  \n",
            "8569   -0.0112847516557207+0.00911319731625038i  \n",
            "8570    0.0112186969285489+0.00559665549095463i  \n",
            "\n",
            "[8571 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EfojlofPYKcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for testing purpose, not included in actual code\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # Example DataFrame\n",
        "# data = {\n",
        "#     '8-QAM': ['1.22474487139159 - 0.408248290463863i', '0.408248290463863 - 0.408248290463863i'],\n",
        "#     '16-QAM': ['-1.11803398874990 - 0.670820393249937i', '-0.223606797749979 + 0.223606797749979i'],\n",
        "#     '32-QAM': ['-1.11803398874990 - 0.670820393249937i', '-0.223606797749979 + 0.223606797749979i'],\n",
        "#     '64-QAM': ['-1.11803398874990 - 0.670820393249937i', '-0.223606797749979 + 0.223606797749979i'],\n",
        "#     '128-QAM': ['-0.773020682523926 - 0.993883734673619i', '-0.773020682523926 - 0.552157630374233i']\n",
        "# }\n",
        "\n",
        "# df = pd.DataFrame(data)\n",
        "\n",
        "# # Remove white spaces\n",
        "# for col in df.columns:\n",
        "#     df[col] = df[col].str.replace(' ', '')\n",
        "\n",
        "# # Add more rows\n",
        "# for _ in range(1000):\n",
        "#     df = df.append(pd.Series(df.iloc[0], index=df.columns), ignore_index=True)\n",
        "\n",
        "# # Display the DataFrame\n",
        "# print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo1NdYc7YLt4",
        "outputId": "e2407d1d-6997-435f-902f-1594b26d35b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-125-739bb087d35e>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(pd.Series(df.iloc[0], index=df.columns), ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     8-QAM  \\\n",
            "0      1.22474487139159-0.408248290463863i   \n",
            "1     0.408248290463863-0.408248290463863i   \n",
            "2      1.22474487139159-0.408248290463863i   \n",
            "3      1.22474487139159-0.408248290463863i   \n",
            "4      1.22474487139159-0.408248290463863i   \n",
            "...                                    ...   \n",
            "997    1.22474487139159-0.408248290463863i   \n",
            "998    1.22474487139159-0.408248290463863i   \n",
            "999    1.22474487139159-0.408248290463863i   \n",
            "1000   1.22474487139159-0.408248290463863i   \n",
            "1001   1.22474487139159-0.408248290463863i   \n",
            "\n",
            "                                     16-QAM  \\\n",
            "0      -1.11803398874990-0.670820393249937i   \n",
            "1     -0.223606797749979+0.223606797749979i   \n",
            "2      -1.11803398874990-0.670820393249937i   \n",
            "3      -1.11803398874990-0.670820393249937i   \n",
            "4      -1.11803398874990-0.670820393249937i   \n",
            "...                                     ...   \n",
            "997    -1.11803398874990-0.670820393249937i   \n",
            "998    -1.11803398874990-0.670820393249937i   \n",
            "999    -1.11803398874990-0.670820393249937i   \n",
            "1000   -1.11803398874990-0.670820393249937i   \n",
            "1001   -1.11803398874990-0.670820393249937i   \n",
            "\n",
            "                                     32-QAM  \\\n",
            "0      -1.11803398874990-0.670820393249937i   \n",
            "1     -0.223606797749979+0.223606797749979i   \n",
            "2      -1.11803398874990-0.670820393249937i   \n",
            "3      -1.11803398874990-0.670820393249937i   \n",
            "4      -1.11803398874990-0.670820393249937i   \n",
            "...                                     ...   \n",
            "997    -1.11803398874990-0.670820393249937i   \n",
            "998    -1.11803398874990-0.670820393249937i   \n",
            "999    -1.11803398874990-0.670820393249937i   \n",
            "1000   -1.11803398874990-0.670820393249937i   \n",
            "1001   -1.11803398874990-0.670820393249937i   \n",
            "\n",
            "                                     64-QAM  \\\n",
            "0      -1.11803398874990-0.670820393249937i   \n",
            "1     -0.223606797749979+0.223606797749979i   \n",
            "2      -1.11803398874990-0.670820393249937i   \n",
            "3      -1.11803398874990-0.670820393249937i   \n",
            "4      -1.11803398874990-0.670820393249937i   \n",
            "...                                     ...   \n",
            "997    -1.11803398874990-0.670820393249937i   \n",
            "998    -1.11803398874990-0.670820393249937i   \n",
            "999    -1.11803398874990-0.670820393249937i   \n",
            "1000   -1.11803398874990-0.670820393249937i   \n",
            "1001   -1.11803398874990-0.670820393249937i   \n",
            "\n",
            "                                    128-QAM  \n",
            "0     -0.773020682523926-0.993883734673619i  \n",
            "1     -0.773020682523926-0.552157630374233i  \n",
            "2     -0.773020682523926-0.993883734673619i  \n",
            "3     -0.773020682523926-0.993883734673619i  \n",
            "4     -0.773020682523926-0.993883734673619i  \n",
            "...                                     ...  \n",
            "997   -0.773020682523926-0.993883734673619i  \n",
            "998   -0.773020682523926-0.993883734673619i  \n",
            "999   -0.773020682523926-0.993883734673619i  \n",
            "1000  -0.773020682523926-0.993883734673619i  \n",
            "1001  -0.773020682523926-0.993883734673619i  \n",
            "\n",
            "[1002 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.tail(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "OQugoA6JPYvR",
        "outputId": "28b4384b-ab00-4336-9f11-d20bcc919e69"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      8-QAM  \\\n",
              "8566  -0.408248290463863+0.408248290463863i   \n",
              "8567   -1.22474487139159+0.408248290463863i   \n",
              "8568  -0.408248290463863-0.408248290463863i   \n",
              "8569   -1.22474487139159+0.408248290463863i   \n",
              "8570   -1.22474487139159-0.408248290463863i   \n",
              "\n",
              "                                     32-QAM  \\\n",
              "8566   0.670820393249937+0.670820393249937i   \n",
              "8567   0.670820393249937+0.670820393249937i   \n",
              "8568  -0.223606797749979+0.670820393249937i   \n",
              "8569   -0.223606797749979+1.11803398874990i   \n",
              "8570    0.670820393249937+1.11803398874990i   \n",
              "\n",
              "                                    128-QAM  \\\n",
              "8566  -0.331294578224540+0.773020682523926i   \n",
              "8567   0.993883734673619-0.773020682523926i   \n",
              "8568   0.552157630374233+0.773020682523926i   \n",
              "8569   0.773020682523926+0.331294578224540i   \n",
              "8570  -0.552157630374233+0.331294578224540i   \n",
              "\n",
              "                                       OFDM  \\\n",
              "8566  -0.331294578224540+0.773020682523926i   \n",
              "8567   0.993883734673619-0.773020682523926i   \n",
              "8568   0.552157630374233+0.773020682523926i   \n",
              "8569   0.773020682523926+0.331294578224540i   \n",
              "8570  -0.552157630374233+0.331294578224540i   \n",
              "\n",
              "                                           LTE  \n",
              "8566   -0.0134020184082583+0.0151515590934546i  \n",
              "8567   0.0178589901836325+0.00442549831866548i  \n",
              "8568  -0.00370077804665655-0.0160566215312079i  \n",
              "8569  -0.0112847516557207+0.00911319731625038i  \n",
              "8570   0.0112186969285489+0.00559665549095463i  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36e754a3-e7da-40a4-b9ec-6a59fb2a9e6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>8-QAM</th>\n",
              "      <th>32-QAM</th>\n",
              "      <th>128-QAM</th>\n",
              "      <th>OFDM</th>\n",
              "      <th>LTE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8566</th>\n",
              "      <td>-0.408248290463863+0.408248290463863i</td>\n",
              "      <td>0.670820393249937+0.670820393249937i</td>\n",
              "      <td>-0.331294578224540+0.773020682523926i</td>\n",
              "      <td>-0.331294578224540+0.773020682523926i</td>\n",
              "      <td>-0.0134020184082583+0.0151515590934546i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8567</th>\n",
              "      <td>-1.22474487139159+0.408248290463863i</td>\n",
              "      <td>0.670820393249937+0.670820393249937i</td>\n",
              "      <td>0.993883734673619-0.773020682523926i</td>\n",
              "      <td>0.993883734673619-0.773020682523926i</td>\n",
              "      <td>0.0178589901836325+0.00442549831866548i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8568</th>\n",
              "      <td>-0.408248290463863-0.408248290463863i</td>\n",
              "      <td>-0.223606797749979+0.670820393249937i</td>\n",
              "      <td>0.552157630374233+0.773020682523926i</td>\n",
              "      <td>0.552157630374233+0.773020682523926i</td>\n",
              "      <td>-0.00370077804665655-0.0160566215312079i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8569</th>\n",
              "      <td>-1.22474487139159+0.408248290463863i</td>\n",
              "      <td>-0.223606797749979+1.11803398874990i</td>\n",
              "      <td>0.773020682523926+0.331294578224540i</td>\n",
              "      <td>0.773020682523926+0.331294578224540i</td>\n",
              "      <td>-0.0112847516557207+0.00911319731625038i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8570</th>\n",
              "      <td>-1.22474487139159-0.408248290463863i</td>\n",
              "      <td>0.670820393249937+1.11803398874990i</td>\n",
              "      <td>-0.552157630374233+0.331294578224540i</td>\n",
              "      <td>-0.552157630374233+0.331294578224540i</td>\n",
              "      <td>0.0112186969285489+0.00559665549095463i</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36e754a3-e7da-40a4-b9ec-6a59fb2a9e6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36e754a3-e7da-40a4-b9ec-6a59fb2a9e6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36e754a3-e7da-40a4-b9ec-6a59fb2a9e6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf1c5319-d93a-4fba-b9dd-1e6957078a0a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf1c5319-d93a-4fba-b9dd-1e6957078a0a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf1c5319-d93a-4fba-b9dd-1e6957078a0a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply complex conversion\n",
        "for col in df.columns:\n",
        "    df[col] = df[col].apply(lambda x: complex(x.replace('i', 'j') if 'i' in x else x + 'j'))\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_8ftkXGQKiF",
        "outputId": "27607dd4-d999-4b6b-e0af-392bacbf05dd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   8-QAM              32-QAM             128-QAM  \\\n",
            "0     1.224745-0.408248j -1.118034-0.670820j -0.773021-0.993884j   \n",
            "1     0.408248-0.408248j -0.223607+0.223607j -0.773021-0.552158j   \n",
            "2    -1.224745-0.408248j -0.670820+0.670820j  1.214747-0.110432j   \n",
            "3    -0.408248+0.408248j -0.223607-1.118034j -0.993884+0.110432j   \n",
            "4    -1.224745+0.408248j -1.118034-0.670820j  0.773021+0.331295j   \n",
            "...                  ...                 ...                 ...   \n",
            "8566 -0.408248+0.408248j  0.670820+0.670820j -0.331295+0.773021j   \n",
            "8567 -1.224745+0.408248j  0.670820+0.670820j  0.993884-0.773021j   \n",
            "8568 -0.408248-0.408248j -0.223607+0.670820j  0.552158+0.773021j   \n",
            "8569 -1.224745+0.408248j -0.223607+1.118034j  0.773021+0.331295j   \n",
            "8570 -1.224745-0.408248j  0.670820+1.118034j -0.552158+0.331295j   \n",
            "\n",
            "                    OFDM                 LTE  \n",
            "0    -0.773021-0.993884j -0.022723+0.025834j  \n",
            "1    -0.773021-0.552158j -0.019453-0.012123j  \n",
            "2     1.214747-0.110432j  0.012864-0.002218j  \n",
            "3    -0.993884+0.110432j  0.009480-0.000852j  \n",
            "4     0.773021+0.331295j -0.039604+0.009750j  \n",
            "...                  ...                 ...  \n",
            "8566 -0.331295+0.773021j -0.013402+0.015152j  \n",
            "8567  0.993884-0.773021j  0.017859+0.004425j  \n",
            "8568  0.552158+0.773021j -0.003701-0.016057j  \n",
            "8569  0.773021+0.331295j -0.011285+0.009113j  \n",
            "8570 -0.552158+0.331295j  0.011219+0.005597j  \n",
            "\n",
            "[8571 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Feature engineering\n",
        "df['real_8QAM'] = df['8-QAM'].apply(lambda x: x.real)\n",
        "df['imag_8QAM'] = df['8-QAM'].apply(lambda x: x.imag)\n",
        "\n",
        "df['real_32QAM'] = df['32-QAM'].apply(lambda x: x.real)\n",
        "df['imag_32QAM'] = df['32-QAM'].apply(lambda x: x.imag)\n",
        "\n",
        "df['real_128QAM'] = df['128-QAM'].apply(lambda x: x.real)\n",
        "df['imag_128QAM'] = df['128-QAM'].apply(lambda x: x.imag)\n",
        "\n",
        "df['real_OFDM'] = df['OFDM'].apply(lambda x: x.real)\n",
        "df['imag_OFDM'] = df['OFDM'].apply(lambda x: x.imag)\n",
        "\n",
        "df['real_LTE'] = df['LTE'].apply(lambda x: x.real)\n",
        "df['imag_LTE'] = df['LTE'].apply(lambda x: x.imag)\n",
        "\n",
        "\n",
        "# Create a synthetic target for classification\n",
        "modulation_schemes = ['8-QAM', '32-QAM', '128-QAM','16-QAM', '64-QAM', 'OFDM', 'LTE']\n",
        "df['target_class'] = np.random.choice(modulation_schemes, size=len(df))\n"
      ],
      "metadata": {
        "id": "-_HuLzTURZB7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the modulation scheme of a single signal\n",
        "# Creating a synthetic target for individual signal prediction\n",
        "df['target_signal'] = np.random.choice(modulation_schemes, size=len(df))\n",
        "\n",
        "# Drop original columns\n",
        "df = df.drop(columns=['8-QAM', '32-QAM', '128-QAM','OFDM', 'LTE'])\n",
        "\n",
        "# Split data into features and labels for classification\n",
        "X_class = df.drop(columns=['target_class'])\n",
        "y_class = df['target_class']\n",
        "\n",
        "# Split data into features and labels for individual signal prediction\n",
        "X_signal = df.drop(columns=['target_signal'])\n",
        "y_signal = df['target_signal']\n"
      ],
      "metadata": {
        "id": "o747KJLRSTQC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels for classification\n",
        "le = LabelEncoder()\n",
        "df['target_class_encoded'] = le.fit_transform(y_class)\n",
        "\n",
        "# Extracting only numeric features for standardization\n",
        "numeric_features_class = X_class.select_dtypes(include=[np.number])\n",
        "\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(numeric_features_class, df['target_class_encoded'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler_class = StandardScaler()\n",
        "X_train_scaled_class = scaler_class.fit_transform(X_train_class)\n",
        "X_test_scaled_class = scaler_class.transform(X_test_class)"
      ],
      "metadata": {
        "id": "nHx-qRVTTLrh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building neural network model for classification\n",
        "model_class = Sequential()\n",
        "model_class.add(Dense(128, activation='relu', input_dim=X_train_scaled_class.shape[1]))\n",
        "model_class.add(Dense(64, activation='relu'))\n",
        "model_class.add(Dense(len(modulation_schemes), activation='softmax'))  # Output layer for classification\n",
        "\n",
        "# Compiling the model\n",
        "model_class.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model_class.fit(X_train_scaled_class, y_train_class, epochs=1000, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuPsQqBYTOm8",
        "outputId": "3cb4907a-b822-4a3b-dcbd-2d3e13ec98b8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "172/172 [==============================] - 2s 5ms/step - loss: 1.9579 - accuracy: 0.1437 - val_loss: 1.9648 - val_accuracy: 0.1290\n",
            "Epoch 2/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9404 - accuracy: 0.1605 - val_loss: 1.9617 - val_accuracy: 0.1312\n",
            "Epoch 3/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9314 - accuracy: 0.1823 - val_loss: 1.9626 - val_accuracy: 0.1356\n",
            "Epoch 4/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9265 - accuracy: 0.1820 - val_loss: 1.9651 - val_accuracy: 0.1305\n",
            "Epoch 5/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9207 - accuracy: 0.1920 - val_loss: 1.9626 - val_accuracy: 0.1414\n",
            "Epoch 6/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9158 - accuracy: 0.1895 - val_loss: 1.9647 - val_accuracy: 0.1363\n",
            "Epoch 7/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9100 - accuracy: 0.2020 - val_loss: 1.9714 - val_accuracy: 0.1399\n",
            "Epoch 8/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9030 - accuracy: 0.2097 - val_loss: 1.9762 - val_accuracy: 0.1334\n",
            "Epoch 9/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8971 - accuracy: 0.2154 - val_loss: 1.9835 - val_accuracy: 0.1254\n",
            "Epoch 10/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8937 - accuracy: 0.2133 - val_loss: 1.9840 - val_accuracy: 0.1392\n",
            "Epoch 11/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8866 - accuracy: 0.2170 - val_loss: 1.9890 - val_accuracy: 0.1363\n",
            "Epoch 12/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8779 - accuracy: 0.2305 - val_loss: 1.9993 - val_accuracy: 0.1436\n",
            "Epoch 13/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8747 - accuracy: 0.2341 - val_loss: 2.0035 - val_accuracy: 0.1246\n",
            "Epoch 14/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8661 - accuracy: 0.2471 - val_loss: 2.0092 - val_accuracy: 0.1378\n",
            "Epoch 15/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8617 - accuracy: 0.2363 - val_loss: 2.0049 - val_accuracy: 0.1436\n",
            "Epoch 16/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8528 - accuracy: 0.2434 - val_loss: 2.0104 - val_accuracy: 0.1450\n",
            "Epoch 17/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8469 - accuracy: 0.2546 - val_loss: 2.0081 - val_accuracy: 0.1385\n",
            "Epoch 18/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8429 - accuracy: 0.2575 - val_loss: 2.0161 - val_accuracy: 0.1450\n",
            "Epoch 19/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8341 - accuracy: 0.2628 - val_loss: 2.0228 - val_accuracy: 0.1458\n",
            "Epoch 20/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8276 - accuracy: 0.2657 - val_loss: 2.0284 - val_accuracy: 0.1348\n",
            "Epoch 21/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8221 - accuracy: 0.2699 - val_loss: 2.0335 - val_accuracy: 0.1450\n",
            "Epoch 22/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8137 - accuracy: 0.2733 - val_loss: 2.0410 - val_accuracy: 0.1268\n",
            "Epoch 23/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8054 - accuracy: 0.2848 - val_loss: 2.0408 - val_accuracy: 0.1399\n",
            "Epoch 24/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8026 - accuracy: 0.2865 - val_loss: 2.0455 - val_accuracy: 0.1487\n",
            "Epoch 25/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7937 - accuracy: 0.2877 - val_loss: 2.0558 - val_accuracy: 0.1378\n",
            "Epoch 26/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7889 - accuracy: 0.2896 - val_loss: 2.0553 - val_accuracy: 0.1232\n",
            "Epoch 27/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7799 - accuracy: 0.2980 - val_loss: 2.0700 - val_accuracy: 0.1363\n",
            "Epoch 28/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7752 - accuracy: 0.2983 - val_loss: 2.0794 - val_accuracy: 0.1297\n",
            "Epoch 29/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7669 - accuracy: 0.3043 - val_loss: 2.0769 - val_accuracy: 0.1261\n",
            "Epoch 30/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7628 - accuracy: 0.3049 - val_loss: 2.0779 - val_accuracy: 0.1494\n",
            "Epoch 31/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7573 - accuracy: 0.3087 - val_loss: 2.0958 - val_accuracy: 0.1407\n",
            "Epoch 32/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7492 - accuracy: 0.3056 - val_loss: 2.1019 - val_accuracy: 0.1370\n",
            "Epoch 33/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7442 - accuracy: 0.3124 - val_loss: 2.0998 - val_accuracy: 0.1414\n",
            "Epoch 34/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7348 - accuracy: 0.3260 - val_loss: 2.1117 - val_accuracy: 0.1385\n",
            "Epoch 35/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7341 - accuracy: 0.3198 - val_loss: 2.1083 - val_accuracy: 0.1392\n",
            "Epoch 36/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7260 - accuracy: 0.3237 - val_loss: 2.1170 - val_accuracy: 0.1297\n",
            "Epoch 37/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7223 - accuracy: 0.3302 - val_loss: 2.1262 - val_accuracy: 0.1414\n",
            "Epoch 38/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.7145 - accuracy: 0.3313 - val_loss: 2.1344 - val_accuracy: 0.1348\n",
            "Epoch 39/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.7098 - accuracy: 0.3321 - val_loss: 2.1409 - val_accuracy: 0.1283\n",
            "Epoch 40/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.7051 - accuracy: 0.3388 - val_loss: 2.1269 - val_accuracy: 0.1429\n",
            "Epoch 41/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.7004 - accuracy: 0.3381 - val_loss: 2.1334 - val_accuracy: 0.1487\n",
            "Epoch 42/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.6939 - accuracy: 0.3435 - val_loss: 2.1447 - val_accuracy: 0.1399\n",
            "Epoch 43/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.6915 - accuracy: 0.3415 - val_loss: 2.1709 - val_accuracy: 0.1436\n",
            "Epoch 44/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.6843 - accuracy: 0.3463 - val_loss: 2.1551 - val_accuracy: 0.1429\n",
            "Epoch 45/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.6817 - accuracy: 0.3466 - val_loss: 2.1929 - val_accuracy: 0.1414\n",
            "Epoch 46/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6740 - accuracy: 0.3492 - val_loss: 2.1790 - val_accuracy: 0.1480\n",
            "Epoch 47/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6670 - accuracy: 0.3558 - val_loss: 2.1844 - val_accuracy: 0.1385\n",
            "Epoch 48/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6657 - accuracy: 0.3592 - val_loss: 2.1793 - val_accuracy: 0.1414\n",
            "Epoch 49/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6576 - accuracy: 0.3567 - val_loss: 2.1828 - val_accuracy: 0.1334\n",
            "Epoch 50/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6533 - accuracy: 0.3581 - val_loss: 2.2058 - val_accuracy: 0.1290\n",
            "Epoch 51/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6527 - accuracy: 0.3590 - val_loss: 2.1862 - val_accuracy: 0.1465\n",
            "Epoch 52/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6448 - accuracy: 0.3623 - val_loss: 2.2054 - val_accuracy: 0.1429\n",
            "Epoch 53/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6401 - accuracy: 0.3671 - val_loss: 2.2206 - val_accuracy: 0.1429\n",
            "Epoch 54/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6362 - accuracy: 0.3658 - val_loss: 2.2279 - val_accuracy: 0.1443\n",
            "Epoch 55/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6309 - accuracy: 0.3711 - val_loss: 2.2477 - val_accuracy: 0.1370\n",
            "Epoch 56/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6275 - accuracy: 0.3738 - val_loss: 2.2207 - val_accuracy: 0.1487\n",
            "Epoch 57/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6207 - accuracy: 0.3782 - val_loss: 2.2259 - val_accuracy: 0.1407\n",
            "Epoch 58/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6158 - accuracy: 0.3802 - val_loss: 2.2474 - val_accuracy: 0.1341\n",
            "Epoch 59/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6097 - accuracy: 0.3800 - val_loss: 2.2579 - val_accuracy: 0.1458\n",
            "Epoch 60/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6078 - accuracy: 0.3846 - val_loss: 2.2560 - val_accuracy: 0.1399\n",
            "Epoch 61/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.6084 - accuracy: 0.3822 - val_loss: 2.2590 - val_accuracy: 0.1421\n",
            "Epoch 62/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5981 - accuracy: 0.3871 - val_loss: 2.2597 - val_accuracy: 0.1436\n",
            "Epoch 63/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.5955 - accuracy: 0.3811 - val_loss: 2.2570 - val_accuracy: 0.1501\n",
            "Epoch 64/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5931 - accuracy: 0.3888 - val_loss: 2.3045 - val_accuracy: 0.1297\n",
            "Epoch 65/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5885 - accuracy: 0.3869 - val_loss: 2.2779 - val_accuracy: 0.1509\n",
            "Epoch 66/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5834 - accuracy: 0.3899 - val_loss: 2.2882 - val_accuracy: 0.1392\n",
            "Epoch 67/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5770 - accuracy: 0.3946 - val_loss: 2.2793 - val_accuracy: 0.1458\n",
            "Epoch 68/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5725 - accuracy: 0.3995 - val_loss: 2.3072 - val_accuracy: 0.1414\n",
            "Epoch 69/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5735 - accuracy: 0.3986 - val_loss: 2.3205 - val_accuracy: 0.1363\n",
            "Epoch 70/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5646 - accuracy: 0.4001 - val_loss: 2.3034 - val_accuracy: 0.1487\n",
            "Epoch 71/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.5637 - accuracy: 0.3984 - val_loss: 2.3143 - val_accuracy: 0.1465\n",
            "Epoch 72/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.5645 - accuracy: 0.3953 - val_loss: 2.3123 - val_accuracy: 0.1407\n",
            "Epoch 73/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.5558 - accuracy: 0.4037 - val_loss: 2.3307 - val_accuracy: 0.1385\n",
            "Epoch 74/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.5503 - accuracy: 0.4052 - val_loss: 2.3270 - val_accuracy: 0.1494\n",
            "Epoch 75/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.5471 - accuracy: 0.4090 - val_loss: 2.3273 - val_accuracy: 0.1414\n",
            "Epoch 76/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.5417 - accuracy: 0.4158 - val_loss: 2.3390 - val_accuracy: 0.1392\n",
            "Epoch 77/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.5376 - accuracy: 0.4143 - val_loss: 2.3675 - val_accuracy: 0.1421\n",
            "Epoch 78/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5362 - accuracy: 0.4139 - val_loss: 2.3460 - val_accuracy: 0.1436\n",
            "Epoch 79/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5299 - accuracy: 0.4158 - val_loss: 2.3521 - val_accuracy: 0.1327\n",
            "Epoch 80/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5269 - accuracy: 0.4158 - val_loss: 2.3603 - val_accuracy: 0.1385\n",
            "Epoch 81/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5260 - accuracy: 0.4223 - val_loss: 2.3637 - val_accuracy: 0.1465\n",
            "Epoch 82/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5205 - accuracy: 0.4216 - val_loss: 2.3724 - val_accuracy: 0.1363\n",
            "Epoch 83/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5170 - accuracy: 0.4163 - val_loss: 2.3959 - val_accuracy: 0.1407\n",
            "Epoch 84/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5132 - accuracy: 0.4227 - val_loss: 2.4061 - val_accuracy: 0.1276\n",
            "Epoch 85/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5143 - accuracy: 0.4272 - val_loss: 2.4031 - val_accuracy: 0.1392\n",
            "Epoch 86/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5070 - accuracy: 0.4271 - val_loss: 2.3894 - val_accuracy: 0.1407\n",
            "Epoch 87/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.5053 - accuracy: 0.4223 - val_loss: 2.4283 - val_accuracy: 0.1407\n",
            "Epoch 88/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4981 - accuracy: 0.4271 - val_loss: 2.4241 - val_accuracy: 0.1399\n",
            "Epoch 89/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4930 - accuracy: 0.4322 - val_loss: 2.4136 - val_accuracy: 0.1487\n",
            "Epoch 90/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4893 - accuracy: 0.4320 - val_loss: 2.4265 - val_accuracy: 0.1443\n",
            "Epoch 91/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4890 - accuracy: 0.4314 - val_loss: 2.4233 - val_accuracy: 0.1436\n",
            "Epoch 92/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4878 - accuracy: 0.4345 - val_loss: 2.4477 - val_accuracy: 0.1480\n",
            "Epoch 93/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4846 - accuracy: 0.4395 - val_loss: 2.4509 - val_accuracy: 0.1458\n",
            "Epoch 94/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4784 - accuracy: 0.4416 - val_loss: 2.4373 - val_accuracy: 0.1429\n",
            "Epoch 95/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4774 - accuracy: 0.4294 - val_loss: 2.4450 - val_accuracy: 0.1458\n",
            "Epoch 96/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4757 - accuracy: 0.4327 - val_loss: 2.4918 - val_accuracy: 0.1378\n",
            "Epoch 97/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4655 - accuracy: 0.4499 - val_loss: 2.4529 - val_accuracy: 0.1494\n",
            "Epoch 98/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4667 - accuracy: 0.4466 - val_loss: 2.4632 - val_accuracy: 0.1392\n",
            "Epoch 99/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4608 - accuracy: 0.4458 - val_loss: 2.4625 - val_accuracy: 0.1480\n",
            "Epoch 100/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4577 - accuracy: 0.4508 - val_loss: 2.4852 - val_accuracy: 0.1545\n",
            "Epoch 101/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4602 - accuracy: 0.4460 - val_loss: 2.4814 - val_accuracy: 0.1436\n",
            "Epoch 102/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4537 - accuracy: 0.4429 - val_loss: 2.5018 - val_accuracy: 0.1472\n",
            "Epoch 103/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.4506 - accuracy: 0.4462 - val_loss: 2.4918 - val_accuracy: 0.1443\n",
            "Epoch 104/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.4470 - accuracy: 0.4519 - val_loss: 2.4871 - val_accuracy: 0.1494\n",
            "Epoch 105/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.4412 - accuracy: 0.4515 - val_loss: 2.4967 - val_accuracy: 0.1472\n",
            "Epoch 106/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.4438 - accuracy: 0.4548 - val_loss: 2.5025 - val_accuracy: 0.1480\n",
            "Epoch 107/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.4362 - accuracy: 0.4624 - val_loss: 2.5046 - val_accuracy: 0.1494\n",
            "Epoch 108/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.4317 - accuracy: 0.4586 - val_loss: 2.5165 - val_accuracy: 0.1501\n",
            "Epoch 109/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4320 - accuracy: 0.4584 - val_loss: 2.5182 - val_accuracy: 0.1458\n",
            "Epoch 110/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4302 - accuracy: 0.4575 - val_loss: 2.5394 - val_accuracy: 0.1480\n",
            "Epoch 111/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.4661 - val_loss: 2.5319 - val_accuracy: 0.1458\n",
            "Epoch 112/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4155 - accuracy: 0.4690 - val_loss: 2.5563 - val_accuracy: 0.1414\n",
            "Epoch 113/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4158 - accuracy: 0.4635 - val_loss: 2.5531 - val_accuracy: 0.1443\n",
            "Epoch 114/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4154 - accuracy: 0.4685 - val_loss: 2.5563 - val_accuracy: 0.1443\n",
            "Epoch 115/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4136 - accuracy: 0.4648 - val_loss: 2.5703 - val_accuracy: 0.1509\n",
            "Epoch 116/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.4728 - val_loss: 2.5733 - val_accuracy: 0.1538\n",
            "Epoch 117/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4036 - accuracy: 0.4701 - val_loss: 2.5737 - val_accuracy: 0.1494\n",
            "Epoch 118/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4016 - accuracy: 0.4752 - val_loss: 2.6006 - val_accuracy: 0.1414\n",
            "Epoch 119/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.4659 - val_loss: 2.5820 - val_accuracy: 0.1465\n",
            "Epoch 120/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.4719 - val_loss: 2.5777 - val_accuracy: 0.1589\n",
            "Epoch 121/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3948 - accuracy: 0.4725 - val_loss: 2.5847 - val_accuracy: 0.1589\n",
            "Epoch 122/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3906 - accuracy: 0.4741 - val_loss: 2.5987 - val_accuracy: 0.1407\n",
            "Epoch 123/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3886 - accuracy: 0.4752 - val_loss: 2.6061 - val_accuracy: 0.1458\n",
            "Epoch 124/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3878 - accuracy: 0.4767 - val_loss: 2.6179 - val_accuracy: 0.1312\n",
            "Epoch 125/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3853 - accuracy: 0.4754 - val_loss: 2.6381 - val_accuracy: 0.1465\n",
            "Epoch 126/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3771 - accuracy: 0.4830 - val_loss: 2.6535 - val_accuracy: 0.1450\n",
            "Epoch 127/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3793 - accuracy: 0.4768 - val_loss: 2.6370 - val_accuracy: 0.1443\n",
            "Epoch 128/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3774 - accuracy: 0.4807 - val_loss: 2.6293 - val_accuracy: 0.1450\n",
            "Epoch 129/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3773 - accuracy: 0.4834 - val_loss: 2.6366 - val_accuracy: 0.1414\n",
            "Epoch 130/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3650 - accuracy: 0.4858 - val_loss: 2.6449 - val_accuracy: 0.1399\n",
            "Epoch 131/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3685 - accuracy: 0.4825 - val_loss: 2.6493 - val_accuracy: 0.1450\n",
            "Epoch 132/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3693 - accuracy: 0.4847 - val_loss: 2.6528 - val_accuracy: 0.1480\n",
            "Epoch 133/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3631 - accuracy: 0.4896 - val_loss: 2.6849 - val_accuracy: 0.1487\n",
            "Epoch 134/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3634 - accuracy: 0.4871 - val_loss: 2.6793 - val_accuracy: 0.1407\n",
            "Epoch 135/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.3524 - accuracy: 0.4883 - val_loss: 2.6746 - val_accuracy: 0.1545\n",
            "Epoch 136/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.3514 - accuracy: 0.5029 - val_loss: 2.6953 - val_accuracy: 0.1421\n",
            "Epoch 137/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.3470 - accuracy: 0.4962 - val_loss: 2.6756 - val_accuracy: 0.1458\n",
            "Epoch 138/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.3501 - accuracy: 0.5022 - val_loss: 2.6846 - val_accuracy: 0.1494\n",
            "Epoch 139/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.3461 - accuracy: 0.4938 - val_loss: 2.6988 - val_accuracy: 0.1487\n",
            "Epoch 140/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.3427 - accuracy: 0.5005 - val_loss: 2.7536 - val_accuracy: 0.1392\n",
            "Epoch 141/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.3423 - accuracy: 0.4933 - val_loss: 2.7132 - val_accuracy: 0.1516\n",
            "Epoch 142/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3406 - accuracy: 0.4980 - val_loss: 2.7163 - val_accuracy: 0.1341\n",
            "Epoch 143/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3393 - accuracy: 0.4991 - val_loss: 2.7309 - val_accuracy: 0.1487\n",
            "Epoch 144/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3325 - accuracy: 0.5024 - val_loss: 2.7486 - val_accuracy: 0.1487\n",
            "Epoch 145/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3325 - accuracy: 0.5038 - val_loss: 2.7305 - val_accuracy: 0.1327\n",
            "Epoch 146/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3266 - accuracy: 0.4989 - val_loss: 2.7565 - val_accuracy: 0.1399\n",
            "Epoch 147/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3213 - accuracy: 0.5080 - val_loss: 2.7426 - val_accuracy: 0.1378\n",
            "Epoch 148/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3223 - accuracy: 0.5108 - val_loss: 2.7329 - val_accuracy: 0.1465\n",
            "Epoch 149/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3222 - accuracy: 0.4984 - val_loss: 2.7514 - val_accuracy: 0.1414\n",
            "Epoch 150/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3166 - accuracy: 0.5080 - val_loss: 2.7730 - val_accuracy: 0.1429\n",
            "Epoch 151/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3112 - accuracy: 0.5077 - val_loss: 2.7754 - val_accuracy: 0.1363\n",
            "Epoch 152/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3131 - accuracy: 0.5144 - val_loss: 2.7699 - val_accuracy: 0.1450\n",
            "Epoch 153/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3065 - accuracy: 0.5124 - val_loss: 2.7534 - val_accuracy: 0.1429\n",
            "Epoch 154/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3064 - accuracy: 0.5062 - val_loss: 2.7877 - val_accuracy: 0.1399\n",
            "Epoch 155/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3016 - accuracy: 0.5146 - val_loss: 2.7924 - val_accuracy: 0.1531\n",
            "Epoch 156/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2994 - accuracy: 0.5104 - val_loss: 2.7964 - val_accuracy: 0.1414\n",
            "Epoch 157/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3009 - accuracy: 0.5111 - val_loss: 2.8012 - val_accuracy: 0.1450\n",
            "Epoch 158/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.3014 - accuracy: 0.5166 - val_loss: 2.8174 - val_accuracy: 0.1472\n",
            "Epoch 159/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2984 - accuracy: 0.5157 - val_loss: 2.8158 - val_accuracy: 0.1429\n",
            "Epoch 160/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2926 - accuracy: 0.5201 - val_loss: 2.8233 - val_accuracy: 0.1487\n",
            "Epoch 161/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2930 - accuracy: 0.5115 - val_loss: 2.8338 - val_accuracy: 0.1443\n",
            "Epoch 162/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2882 - accuracy: 0.5133 - val_loss: 2.8503 - val_accuracy: 0.1363\n",
            "Epoch 163/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2948 - accuracy: 0.5171 - val_loss: 2.8427 - val_accuracy: 0.1450\n",
            "Epoch 164/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2860 - accuracy: 0.5257 - val_loss: 2.8506 - val_accuracy: 0.1378\n",
            "Epoch 165/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2809 - accuracy: 0.5173 - val_loss: 2.8712 - val_accuracy: 0.1480\n",
            "Epoch 166/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2776 - accuracy: 0.5237 - val_loss: 2.8682 - val_accuracy: 0.1385\n",
            "Epoch 167/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.2800 - accuracy: 0.5186 - val_loss: 2.8937 - val_accuracy: 0.1385\n",
            "Epoch 168/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.2737 - accuracy: 0.5252 - val_loss: 2.8859 - val_accuracy: 0.1385\n",
            "Epoch 169/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.2743 - accuracy: 0.5208 - val_loss: 2.8701 - val_accuracy: 0.1421\n",
            "Epoch 170/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.2687 - accuracy: 0.5244 - val_loss: 2.8953 - val_accuracy: 0.1429\n",
            "Epoch 171/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.2694 - accuracy: 0.5281 - val_loss: 2.9400 - val_accuracy: 0.1319\n",
            "Epoch 172/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.2667 - accuracy: 0.5272 - val_loss: 2.9043 - val_accuracy: 0.1378\n",
            "Epoch 173/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.2671 - accuracy: 0.5274 - val_loss: 2.9089 - val_accuracy: 0.1429\n",
            "Epoch 174/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2628 - accuracy: 0.5286 - val_loss: 2.8861 - val_accuracy: 0.1327\n",
            "Epoch 175/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2615 - accuracy: 0.5284 - val_loss: 2.8875 - val_accuracy: 0.1443\n",
            "Epoch 176/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2567 - accuracy: 0.5312 - val_loss: 2.9415 - val_accuracy: 0.1414\n",
            "Epoch 177/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2569 - accuracy: 0.5315 - val_loss: 2.9327 - val_accuracy: 0.1341\n",
            "Epoch 178/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2504 - accuracy: 0.5361 - val_loss: 2.9162 - val_accuracy: 0.1378\n",
            "Epoch 179/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2471 - accuracy: 0.5367 - val_loss: 2.9298 - val_accuracy: 0.1407\n",
            "Epoch 180/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2493 - accuracy: 0.5334 - val_loss: 2.9272 - val_accuracy: 0.1414\n",
            "Epoch 181/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2474 - accuracy: 0.5356 - val_loss: 2.9398 - val_accuracy: 0.1392\n",
            "Epoch 182/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2434 - accuracy: 0.5430 - val_loss: 2.9359 - val_accuracy: 0.1480\n",
            "Epoch 183/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2449 - accuracy: 0.5299 - val_loss: 2.9445 - val_accuracy: 0.1429\n",
            "Epoch 184/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2431 - accuracy: 0.5361 - val_loss: 2.9598 - val_accuracy: 0.1370\n",
            "Epoch 185/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2417 - accuracy: 0.5387 - val_loss: 2.9927 - val_accuracy: 0.1363\n",
            "Epoch 186/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2399 - accuracy: 0.5388 - val_loss: 2.9963 - val_accuracy: 0.1341\n",
            "Epoch 187/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2430 - accuracy: 0.5334 - val_loss: 2.9915 - val_accuracy: 0.1407\n",
            "Epoch 188/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2276 - accuracy: 0.5418 - val_loss: 2.9720 - val_accuracy: 0.1443\n",
            "Epoch 189/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2282 - accuracy: 0.5432 - val_loss: 2.9561 - val_accuracy: 0.1480\n",
            "Epoch 190/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2242 - accuracy: 0.5401 - val_loss: 2.9689 - val_accuracy: 0.1472\n",
            "Epoch 191/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2272 - accuracy: 0.5399 - val_loss: 3.0349 - val_accuracy: 0.1392\n",
            "Epoch 192/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2239 - accuracy: 0.5423 - val_loss: 3.0147 - val_accuracy: 0.1246\n",
            "Epoch 193/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2260 - accuracy: 0.5538 - val_loss: 3.0269 - val_accuracy: 0.1341\n",
            "Epoch 194/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2253 - accuracy: 0.5398 - val_loss: 3.0397 - val_accuracy: 0.1370\n",
            "Epoch 195/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2193 - accuracy: 0.5401 - val_loss: 3.0067 - val_accuracy: 0.1458\n",
            "Epoch 196/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2136 - accuracy: 0.5450 - val_loss: 3.0728 - val_accuracy: 0.1348\n",
            "Epoch 197/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2132 - accuracy: 0.5472 - val_loss: 3.0485 - val_accuracy: 0.1319\n",
            "Epoch 198/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2171 - accuracy: 0.5447 - val_loss: 3.0093 - val_accuracy: 0.1392\n",
            "Epoch 199/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.2132 - accuracy: 0.5480 - val_loss: 3.0183 - val_accuracy: 0.1334\n",
            "Epoch 200/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.2105 - accuracy: 0.5441 - val_loss: 3.0547 - val_accuracy: 0.1348\n",
            "Epoch 201/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.2093 - accuracy: 0.5396 - val_loss: 3.0651 - val_accuracy: 0.1348\n",
            "Epoch 202/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.2083 - accuracy: 0.5447 - val_loss: 3.0618 - val_accuracy: 0.1334\n",
            "Epoch 203/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.2008 - accuracy: 0.5574 - val_loss: 3.0498 - val_accuracy: 0.1429\n",
            "Epoch 204/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.1973 - accuracy: 0.5512 - val_loss: 3.0983 - val_accuracy: 0.1443\n",
            "Epoch 205/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.2021 - accuracy: 0.5514 - val_loss: 3.0832 - val_accuracy: 0.1399\n",
            "Epoch 206/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.1974 - accuracy: 0.5470 - val_loss: 3.0774 - val_accuracy: 0.1465\n",
            "Epoch 207/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1947 - accuracy: 0.5565 - val_loss: 3.0940 - val_accuracy: 0.1407\n",
            "Epoch 208/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1914 - accuracy: 0.5529 - val_loss: 3.1043 - val_accuracy: 0.1414\n",
            "Epoch 209/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1908 - accuracy: 0.5512 - val_loss: 3.1033 - val_accuracy: 0.1268\n",
            "Epoch 210/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1871 - accuracy: 0.5598 - val_loss: 3.0943 - val_accuracy: 0.1290\n",
            "Epoch 211/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1883 - accuracy: 0.5536 - val_loss: 3.1126 - val_accuracy: 0.1414\n",
            "Epoch 212/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1854 - accuracy: 0.5587 - val_loss: 3.1053 - val_accuracy: 0.1378\n",
            "Epoch 213/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1832 - accuracy: 0.5591 - val_loss: 3.1256 - val_accuracy: 0.1370\n",
            "Epoch 214/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1794 - accuracy: 0.5563 - val_loss: 3.1450 - val_accuracy: 0.1341\n",
            "Epoch 215/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1797 - accuracy: 0.5532 - val_loss: 3.1476 - val_accuracy: 0.1407\n",
            "Epoch 216/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1741 - accuracy: 0.5622 - val_loss: 3.1377 - val_accuracy: 0.1429\n",
            "Epoch 217/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1768 - accuracy: 0.5629 - val_loss: 3.1214 - val_accuracy: 0.1392\n",
            "Epoch 218/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1703 - accuracy: 0.5646 - val_loss: 3.1785 - val_accuracy: 0.1443\n",
            "Epoch 219/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1752 - accuracy: 0.5584 - val_loss: 3.1683 - val_accuracy: 0.1414\n",
            "Epoch 220/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1741 - accuracy: 0.5622 - val_loss: 3.1935 - val_accuracy: 0.1356\n",
            "Epoch 221/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1675 - accuracy: 0.5675 - val_loss: 3.1470 - val_accuracy: 0.1509\n",
            "Epoch 222/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1670 - accuracy: 0.5594 - val_loss: 3.1793 - val_accuracy: 0.1443\n",
            "Epoch 223/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1609 - accuracy: 0.5669 - val_loss: 3.1904 - val_accuracy: 0.1399\n",
            "Epoch 224/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1612 - accuracy: 0.5642 - val_loss: 3.1971 - val_accuracy: 0.1378\n",
            "Epoch 225/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1583 - accuracy: 0.5673 - val_loss: 3.2243 - val_accuracy: 0.1399\n",
            "Epoch 226/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1620 - accuracy: 0.5607 - val_loss: 3.2323 - val_accuracy: 0.1378\n",
            "Epoch 227/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1614 - accuracy: 0.5708 - val_loss: 3.1968 - val_accuracy: 0.1312\n",
            "Epoch 228/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1573 - accuracy: 0.5656 - val_loss: 3.2301 - val_accuracy: 0.1443\n",
            "Epoch 229/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1499 - accuracy: 0.5702 - val_loss: 3.1836 - val_accuracy: 0.1341\n",
            "Epoch 230/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.1565 - accuracy: 0.5682 - val_loss: 3.2152 - val_accuracy: 0.1487\n",
            "Epoch 231/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.1481 - accuracy: 0.5697 - val_loss: 3.2242 - val_accuracy: 0.1399\n",
            "Epoch 232/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.1538 - accuracy: 0.5726 - val_loss: 3.2176 - val_accuracy: 0.1363\n",
            "Epoch 233/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.1464 - accuracy: 0.5728 - val_loss: 3.2537 - val_accuracy: 0.1378\n",
            "Epoch 234/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.1423 - accuracy: 0.5728 - val_loss: 3.2609 - val_accuracy: 0.1392\n",
            "Epoch 235/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.1465 - accuracy: 0.5737 - val_loss: 3.2750 - val_accuracy: 0.1327\n",
            "Epoch 236/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.1415 - accuracy: 0.5649 - val_loss: 3.2784 - val_accuracy: 0.1363\n",
            "Epoch 237/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1391 - accuracy: 0.5797 - val_loss: 3.2497 - val_accuracy: 0.1370\n",
            "Epoch 238/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1447 - accuracy: 0.5713 - val_loss: 3.2373 - val_accuracy: 0.1370\n",
            "Epoch 239/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1342 - accuracy: 0.5760 - val_loss: 3.2430 - val_accuracy: 0.1385\n",
            "Epoch 240/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1311 - accuracy: 0.5806 - val_loss: 3.2890 - val_accuracy: 0.1334\n",
            "Epoch 241/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1356 - accuracy: 0.5759 - val_loss: 3.2864 - val_accuracy: 0.1312\n",
            "Epoch 242/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1328 - accuracy: 0.5828 - val_loss: 3.3005 - val_accuracy: 0.1327\n",
            "Epoch 243/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1220 - accuracy: 0.5857 - val_loss: 3.2951 - val_accuracy: 0.1407\n",
            "Epoch 244/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.1213 - accuracy: 0.5724 - val_loss: 3.3645 - val_accuracy: 0.1327\n",
            "Epoch 245/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.1228 - accuracy: 0.5853 - val_loss: 3.3221 - val_accuracy: 0.1356\n",
            "Epoch 246/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1291 - accuracy: 0.5821 - val_loss: 3.2907 - val_accuracy: 0.1268\n",
            "Epoch 247/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1267 - accuracy: 0.5808 - val_loss: 3.3413 - val_accuracy: 0.1378\n",
            "Epoch 248/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1187 - accuracy: 0.5828 - val_loss: 3.3735 - val_accuracy: 0.1319\n",
            "Epoch 249/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1181 - accuracy: 0.5837 - val_loss: 3.3602 - val_accuracy: 0.1378\n",
            "Epoch 250/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1195 - accuracy: 0.5835 - val_loss: 3.3325 - val_accuracy: 0.1421\n",
            "Epoch 251/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1109 - accuracy: 0.5910 - val_loss: 3.3250 - val_accuracy: 0.1414\n",
            "Epoch 252/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1206 - accuracy: 0.5739 - val_loss: 3.3322 - val_accuracy: 0.1392\n",
            "Epoch 253/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1134 - accuracy: 0.5830 - val_loss: 3.3699 - val_accuracy: 0.1407\n",
            "Epoch 254/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1139 - accuracy: 0.5841 - val_loss: 3.3636 - val_accuracy: 0.1443\n",
            "Epoch 255/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1065 - accuracy: 0.5881 - val_loss: 3.3679 - val_accuracy: 0.1305\n",
            "Epoch 256/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1071 - accuracy: 0.5872 - val_loss: 3.3894 - val_accuracy: 0.1356\n",
            "Epoch 257/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1155 - accuracy: 0.5861 - val_loss: 3.4048 - val_accuracy: 0.1443\n",
            "Epoch 258/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0989 - accuracy: 0.5910 - val_loss: 3.4332 - val_accuracy: 0.1436\n",
            "Epoch 259/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.1073 - accuracy: 0.5895 - val_loss: 3.3931 - val_accuracy: 0.1429\n",
            "Epoch 260/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.5897 - val_loss: 3.3907 - val_accuracy: 0.1348\n",
            "Epoch 261/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.1025 - accuracy: 0.5872 - val_loss: 3.3792 - val_accuracy: 0.1385\n",
            "Epoch 262/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0967 - accuracy: 0.5945 - val_loss: 3.3991 - val_accuracy: 0.1443\n",
            "Epoch 263/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0958 - accuracy: 0.5883 - val_loss: 3.3813 - val_accuracy: 0.1472\n",
            "Epoch 264/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.0945 - accuracy: 0.5906 - val_loss: 3.4255 - val_accuracy: 0.1407\n",
            "Epoch 265/1000\n",
            "172/172 [==============================] - 1s 9ms/step - loss: 1.0958 - accuracy: 0.5937 - val_loss: 3.4072 - val_accuracy: 0.1450\n",
            "Epoch 266/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.0900 - accuracy: 0.5950 - val_loss: 3.4150 - val_accuracy: 0.1436\n",
            "Epoch 267/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.5976 - val_loss: 3.3927 - val_accuracy: 0.1472\n",
            "Epoch 268/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0884 - accuracy: 0.5937 - val_loss: 3.4374 - val_accuracy: 0.1399\n",
            "Epoch 269/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0899 - accuracy: 0.5914 - val_loss: 3.4274 - val_accuracy: 0.1501\n",
            "Epoch 270/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0923 - accuracy: 0.5954 - val_loss: 3.4526 - val_accuracy: 0.1363\n",
            "Epoch 271/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0864 - accuracy: 0.5903 - val_loss: 3.4511 - val_accuracy: 0.1472\n",
            "Epoch 272/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0834 - accuracy: 0.5979 - val_loss: 3.4345 - val_accuracy: 0.1363\n",
            "Epoch 273/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0847 - accuracy: 0.5976 - val_loss: 3.4301 - val_accuracy: 0.1436\n",
            "Epoch 274/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0879 - accuracy: 0.5914 - val_loss: 3.4463 - val_accuracy: 0.1399\n",
            "Epoch 275/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0772 - accuracy: 0.5959 - val_loss: 3.4829 - val_accuracy: 0.1399\n",
            "Epoch 276/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0816 - accuracy: 0.5904 - val_loss: 3.4792 - val_accuracy: 0.1421\n",
            "Epoch 277/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0695 - accuracy: 0.6016 - val_loss: 3.4485 - val_accuracy: 0.1407\n",
            "Epoch 278/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0761 - accuracy: 0.5981 - val_loss: 3.5251 - val_accuracy: 0.1385\n",
            "Epoch 279/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0657 - accuracy: 0.6018 - val_loss: 3.4927 - val_accuracy: 0.1443\n",
            "Epoch 280/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0748 - accuracy: 0.6008 - val_loss: 3.5332 - val_accuracy: 0.1458\n",
            "Epoch 281/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0749 - accuracy: 0.5992 - val_loss: 3.4970 - val_accuracy: 0.1480\n",
            "Epoch 282/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0614 - accuracy: 0.6052 - val_loss: 3.5087 - val_accuracy: 0.1509\n",
            "Epoch 283/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0644 - accuracy: 0.6061 - val_loss: 3.5434 - val_accuracy: 0.1494\n",
            "Epoch 284/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0638 - accuracy: 0.6014 - val_loss: 3.5503 - val_accuracy: 0.1414\n",
            "Epoch 285/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0623 - accuracy: 0.5999 - val_loss: 3.5006 - val_accuracy: 0.1443\n",
            "Epoch 286/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0642 - accuracy: 0.5987 - val_loss: 3.5512 - val_accuracy: 0.1385\n",
            "Epoch 287/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0707 - accuracy: 0.6010 - val_loss: 3.5728 - val_accuracy: 0.1378\n",
            "Epoch 288/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0642 - accuracy: 0.5966 - val_loss: 3.5743 - val_accuracy: 0.1334\n",
            "Epoch 289/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0527 - accuracy: 0.6078 - val_loss: 3.5992 - val_accuracy: 0.1276\n",
            "Epoch 290/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0533 - accuracy: 0.6083 - val_loss: 3.5658 - val_accuracy: 0.1254\n",
            "Epoch 291/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0520 - accuracy: 0.6152 - val_loss: 3.5467 - val_accuracy: 0.1414\n",
            "Epoch 292/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0546 - accuracy: 0.6107 - val_loss: 3.5900 - val_accuracy: 0.1429\n",
            "Epoch 293/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0539 - accuracy: 0.5987 - val_loss: 3.6157 - val_accuracy: 0.1414\n",
            "Epoch 294/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.0456 - accuracy: 0.6173 - val_loss: 3.5900 - val_accuracy: 0.1458\n",
            "Epoch 295/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0500 - accuracy: 0.6111 - val_loss: 3.5725 - val_accuracy: 0.1487\n",
            "Epoch 296/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0451 - accuracy: 0.6118 - val_loss: 3.6183 - val_accuracy: 0.1399\n",
            "Epoch 297/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.0511 - accuracy: 0.6070 - val_loss: 3.5911 - val_accuracy: 0.1268\n",
            "Epoch 298/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0460 - accuracy: 0.6063 - val_loss: 3.5739 - val_accuracy: 0.1480\n",
            "Epoch 299/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0341 - accuracy: 0.6160 - val_loss: 3.6350 - val_accuracy: 0.1421\n",
            "Epoch 300/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0405 - accuracy: 0.6145 - val_loss: 3.6556 - val_accuracy: 0.1370\n",
            "Epoch 301/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0383 - accuracy: 0.6149 - val_loss: 3.6669 - val_accuracy: 0.1443\n",
            "Epoch 302/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0422 - accuracy: 0.6152 - val_loss: 3.6338 - val_accuracy: 0.1290\n",
            "Epoch 303/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0325 - accuracy: 0.6114 - val_loss: 3.6644 - val_accuracy: 0.1414\n",
            "Epoch 304/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0330 - accuracy: 0.6222 - val_loss: 3.6504 - val_accuracy: 0.1341\n",
            "Epoch 305/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0299 - accuracy: 0.6160 - val_loss: 3.6882 - val_accuracy: 0.1399\n",
            "Epoch 306/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0360 - accuracy: 0.6169 - val_loss: 3.6386 - val_accuracy: 0.1436\n",
            "Epoch 307/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0298 - accuracy: 0.6136 - val_loss: 3.6642 - val_accuracy: 0.1378\n",
            "Epoch 308/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0365 - accuracy: 0.6116 - val_loss: 3.6908 - val_accuracy: 0.1348\n",
            "Epoch 309/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0268 - accuracy: 0.6211 - val_loss: 3.6754 - val_accuracy: 0.1421\n",
            "Epoch 310/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0334 - accuracy: 0.6134 - val_loss: 3.6878 - val_accuracy: 0.1392\n",
            "Epoch 311/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0254 - accuracy: 0.6154 - val_loss: 3.6527 - val_accuracy: 0.1356\n",
            "Epoch 312/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0225 - accuracy: 0.6136 - val_loss: 3.7162 - val_accuracy: 0.1465\n",
            "Epoch 313/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0187 - accuracy: 0.6173 - val_loss: 3.7158 - val_accuracy: 0.1407\n",
            "Epoch 314/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0262 - accuracy: 0.6158 - val_loss: 3.6826 - val_accuracy: 0.1458\n",
            "Epoch 315/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0280 - accuracy: 0.6098 - val_loss: 3.6948 - val_accuracy: 0.1443\n",
            "Epoch 316/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0157 - accuracy: 0.6291 - val_loss: 3.7228 - val_accuracy: 0.1341\n",
            "Epoch 317/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0194 - accuracy: 0.6222 - val_loss: 3.7551 - val_accuracy: 0.1378\n",
            "Epoch 318/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0239 - accuracy: 0.6160 - val_loss: 3.7129 - val_accuracy: 0.1370\n",
            "Epoch 319/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0101 - accuracy: 0.6194 - val_loss: 3.7556 - val_accuracy: 0.1370\n",
            "Epoch 320/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0204 - accuracy: 0.6198 - val_loss: 3.7475 - val_accuracy: 0.1399\n",
            "Epoch 321/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0163 - accuracy: 0.6218 - val_loss: 3.7239 - val_accuracy: 0.1341\n",
            "Epoch 322/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0071 - accuracy: 0.6260 - val_loss: 3.7696 - val_accuracy: 0.1378\n",
            "Epoch 323/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0126 - accuracy: 0.6276 - val_loss: 3.7882 - val_accuracy: 0.1356\n",
            "Epoch 324/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.0019 - accuracy: 0.6238 - val_loss: 3.7405 - val_accuracy: 0.1465\n",
            "Epoch 325/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.0059 - accuracy: 0.6227 - val_loss: 3.7635 - val_accuracy: 0.1378\n",
            "Epoch 326/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0048 - accuracy: 0.6236 - val_loss: 3.7774 - val_accuracy: 0.1392\n",
            "Epoch 327/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0023 - accuracy: 0.6258 - val_loss: 3.7371 - val_accuracy: 0.1480\n",
            "Epoch 328/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.0026 - accuracy: 0.6284 - val_loss: 3.7875 - val_accuracy: 0.1312\n",
            "Epoch 329/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.0077 - accuracy: 0.6267 - val_loss: 3.7930 - val_accuracy: 0.1429\n",
            "Epoch 330/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.0025 - accuracy: 0.6211 - val_loss: 3.8243 - val_accuracy: 0.1356\n",
            "Epoch 331/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.6220 - val_loss: 3.7440 - val_accuracy: 0.1399\n",
            "Epoch 332/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9944 - accuracy: 0.6317 - val_loss: 3.8070 - val_accuracy: 0.1458\n",
            "Epoch 333/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9919 - accuracy: 0.6242 - val_loss: 3.7854 - val_accuracy: 0.1458\n",
            "Epoch 334/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9987 - accuracy: 0.6265 - val_loss: 3.7791 - val_accuracy: 0.1399\n",
            "Epoch 335/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.6349 - val_loss: 3.8012 - val_accuracy: 0.1378\n",
            "Epoch 336/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9976 - accuracy: 0.6271 - val_loss: 3.8674 - val_accuracy: 0.1487\n",
            "Epoch 337/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9888 - accuracy: 0.6205 - val_loss: 3.8623 - val_accuracy: 0.1297\n",
            "Epoch 338/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9878 - accuracy: 0.6327 - val_loss: 3.8034 - val_accuracy: 0.1450\n",
            "Epoch 339/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9916 - accuracy: 0.6333 - val_loss: 3.8541 - val_accuracy: 0.1348\n",
            "Epoch 340/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9911 - accuracy: 0.6255 - val_loss: 3.8706 - val_accuracy: 0.1392\n",
            "Epoch 341/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9900 - accuracy: 0.6375 - val_loss: 3.8878 - val_accuracy: 0.1399\n",
            "Epoch 342/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9803 - accuracy: 0.6322 - val_loss: 3.8397 - val_accuracy: 0.1450\n",
            "Epoch 343/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9818 - accuracy: 0.6315 - val_loss: 3.8910 - val_accuracy: 0.1370\n",
            "Epoch 344/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9843 - accuracy: 0.6364 - val_loss: 3.8560 - val_accuracy: 0.1399\n",
            "Epoch 345/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9788 - accuracy: 0.6355 - val_loss: 3.8929 - val_accuracy: 0.1407\n",
            "Epoch 346/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9730 - accuracy: 0.6379 - val_loss: 3.8864 - val_accuracy: 0.1399\n",
            "Epoch 347/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9771 - accuracy: 0.6348 - val_loss: 3.8640 - val_accuracy: 0.1421\n",
            "Epoch 348/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9780 - accuracy: 0.6362 - val_loss: 3.8777 - val_accuracy: 0.1523\n",
            "Epoch 349/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9666 - accuracy: 0.6417 - val_loss: 3.9060 - val_accuracy: 0.1341\n",
            "Epoch 350/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9699 - accuracy: 0.6358 - val_loss: 3.8992 - val_accuracy: 0.1399\n",
            "Epoch 351/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9700 - accuracy: 0.6373 - val_loss: 3.9141 - val_accuracy: 0.1370\n",
            "Epoch 352/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9699 - accuracy: 0.6351 - val_loss: 3.9308 - val_accuracy: 0.1414\n",
            "Epoch 353/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9688 - accuracy: 0.6357 - val_loss: 3.9139 - val_accuracy: 0.1385\n",
            "Epoch 354/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9735 - accuracy: 0.6302 - val_loss: 3.9659 - val_accuracy: 0.1370\n",
            "Epoch 355/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.9721 - accuracy: 0.6397 - val_loss: 3.9277 - val_accuracy: 0.1407\n",
            "Epoch 356/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9686 - accuracy: 0.6366 - val_loss: 3.9239 - val_accuracy: 0.1443\n",
            "Epoch 357/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.9575 - accuracy: 0.6439 - val_loss: 3.9768 - val_accuracy: 0.1385\n",
            "Epoch 358/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9660 - accuracy: 0.6439 - val_loss: 3.9188 - val_accuracy: 0.1385\n",
            "Epoch 359/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9601 - accuracy: 0.6450 - val_loss: 3.9689 - val_accuracy: 0.1407\n",
            "Epoch 360/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9620 - accuracy: 0.6358 - val_loss: 3.9862 - val_accuracy: 0.1348\n",
            "Epoch 361/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9588 - accuracy: 0.6404 - val_loss: 3.9331 - val_accuracy: 0.1443\n",
            "Epoch 362/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9592 - accuracy: 0.6437 - val_loss: 4.0127 - val_accuracy: 0.1399\n",
            "Epoch 363/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9540 - accuracy: 0.6470 - val_loss: 4.0050 - val_accuracy: 0.1378\n",
            "Epoch 364/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9535 - accuracy: 0.6442 - val_loss: 4.0044 - val_accuracy: 0.1334\n",
            "Epoch 365/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9584 - accuracy: 0.6482 - val_loss: 3.9785 - val_accuracy: 0.1348\n",
            "Epoch 366/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9574 - accuracy: 0.6481 - val_loss: 4.0432 - val_accuracy: 0.1407\n",
            "Epoch 367/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9647 - accuracy: 0.6380 - val_loss: 3.9939 - val_accuracy: 0.1370\n",
            "Epoch 368/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9557 - accuracy: 0.6413 - val_loss: 4.0398 - val_accuracy: 0.1356\n",
            "Epoch 369/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9465 - accuracy: 0.6528 - val_loss: 4.0651 - val_accuracy: 0.1407\n",
            "Epoch 370/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9558 - accuracy: 0.6457 - val_loss: 4.0306 - val_accuracy: 0.1297\n",
            "Epoch 371/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9453 - accuracy: 0.6526 - val_loss: 4.0418 - val_accuracy: 0.1385\n",
            "Epoch 372/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9537 - accuracy: 0.6422 - val_loss: 4.0202 - val_accuracy: 0.1319\n",
            "Epoch 373/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9466 - accuracy: 0.6475 - val_loss: 4.0732 - val_accuracy: 0.1334\n",
            "Epoch 374/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9430 - accuracy: 0.6508 - val_loss: 4.0358 - val_accuracy: 0.1421\n",
            "Epoch 375/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9464 - accuracy: 0.6448 - val_loss: 4.0861 - val_accuracy: 0.1458\n",
            "Epoch 376/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9413 - accuracy: 0.6530 - val_loss: 4.0860 - val_accuracy: 0.1356\n",
            "Epoch 377/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9420 - accuracy: 0.6501 - val_loss: 4.0675 - val_accuracy: 0.1414\n",
            "Epoch 378/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9477 - accuracy: 0.6453 - val_loss: 4.1663 - val_accuracy: 0.1385\n",
            "Epoch 379/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9426 - accuracy: 0.6462 - val_loss: 4.0748 - val_accuracy: 0.1385\n",
            "Epoch 380/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9520 - accuracy: 0.6371 - val_loss: 4.1023 - val_accuracy: 0.1443\n",
            "Epoch 381/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9402 - accuracy: 0.6535 - val_loss: 4.0689 - val_accuracy: 0.1480\n",
            "Epoch 382/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9357 - accuracy: 0.6515 - val_loss: 4.1638 - val_accuracy: 0.1421\n",
            "Epoch 383/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.6484 - val_loss: 4.1150 - val_accuracy: 0.1436\n",
            "Epoch 384/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9324 - accuracy: 0.6570 - val_loss: 4.1219 - val_accuracy: 0.1407\n",
            "Epoch 385/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9238 - accuracy: 0.6559 - val_loss: 4.1420 - val_accuracy: 0.1443\n",
            "Epoch 386/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.9333 - accuracy: 0.6455 - val_loss: 4.1255 - val_accuracy: 0.1429\n",
            "Epoch 387/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.9365 - accuracy: 0.6550 - val_loss: 4.1656 - val_accuracy: 0.1385\n",
            "Epoch 388/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9304 - accuracy: 0.6530 - val_loss: 4.1403 - val_accuracy: 0.1348\n",
            "Epoch 389/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.9241 - accuracy: 0.6596 - val_loss: 4.1258 - val_accuracy: 0.1436\n",
            "Epoch 390/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9321 - accuracy: 0.6557 - val_loss: 4.1383 - val_accuracy: 0.1458\n",
            "Epoch 391/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.9254 - accuracy: 0.6504 - val_loss: 4.1432 - val_accuracy: 0.1378\n",
            "Epoch 392/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9185 - accuracy: 0.6628 - val_loss: 4.1797 - val_accuracy: 0.1341\n",
            "Epoch 393/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9234 - accuracy: 0.6588 - val_loss: 4.1665 - val_accuracy: 0.1494\n",
            "Epoch 394/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9267 - accuracy: 0.6530 - val_loss: 4.1679 - val_accuracy: 0.1421\n",
            "Epoch 395/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.6603 - val_loss: 4.1917 - val_accuracy: 0.1370\n",
            "Epoch 396/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9265 - accuracy: 0.6563 - val_loss: 4.1599 - val_accuracy: 0.1436\n",
            "Epoch 397/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9222 - accuracy: 0.6570 - val_loss: 4.2394 - val_accuracy: 0.1407\n",
            "Epoch 398/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9273 - accuracy: 0.6535 - val_loss: 4.2358 - val_accuracy: 0.1341\n",
            "Epoch 399/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 0.6539 - val_loss: 4.2582 - val_accuracy: 0.1341\n",
            "Epoch 400/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9133 - accuracy: 0.6658 - val_loss: 4.2800 - val_accuracy: 0.1334\n",
            "Epoch 401/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9154 - accuracy: 0.6637 - val_loss: 4.3408 - val_accuracy: 0.1429\n",
            "Epoch 402/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9150 - accuracy: 0.6586 - val_loss: 4.2580 - val_accuracy: 0.1429\n",
            "Epoch 403/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.6696 - val_loss: 4.2760 - val_accuracy: 0.1290\n",
            "Epoch 404/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9127 - accuracy: 0.6689 - val_loss: 4.2395 - val_accuracy: 0.1370\n",
            "Epoch 405/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9058 - accuracy: 0.6658 - val_loss: 4.2545 - val_accuracy: 0.1399\n",
            "Epoch 406/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9111 - accuracy: 0.6537 - val_loss: 4.2468 - val_accuracy: 0.1378\n",
            "Epoch 407/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.6632 - val_loss: 4.2529 - val_accuracy: 0.1458\n",
            "Epoch 408/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9074 - accuracy: 0.6605 - val_loss: 4.2623 - val_accuracy: 0.1370\n",
            "Epoch 409/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9066 - accuracy: 0.6667 - val_loss: 4.3228 - val_accuracy: 0.1327\n",
            "Epoch 410/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9058 - accuracy: 0.6639 - val_loss: 4.2976 - val_accuracy: 0.1348\n",
            "Epoch 411/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9077 - accuracy: 0.6636 - val_loss: 4.2885 - val_accuracy: 0.1414\n",
            "Epoch 412/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9075 - accuracy: 0.6685 - val_loss: 4.2829 - val_accuracy: 0.1348\n",
            "Epoch 413/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9042 - accuracy: 0.6676 - val_loss: 4.3385 - val_accuracy: 0.1341\n",
            "Epoch 414/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.9005 - accuracy: 0.6747 - val_loss: 4.3255 - val_accuracy: 0.1232\n",
            "Epoch 415/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8963 - accuracy: 0.6659 - val_loss: 4.3960 - val_accuracy: 0.1283\n",
            "Epoch 416/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.8985 - accuracy: 0.6685 - val_loss: 4.2657 - val_accuracy: 0.1399\n",
            "Epoch 417/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.9001 - accuracy: 0.6652 - val_loss: 4.3595 - val_accuracy: 0.1407\n",
            "Epoch 418/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.8996 - accuracy: 0.6652 - val_loss: 4.3187 - val_accuracy: 0.1378\n",
            "Epoch 419/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.9067 - accuracy: 0.6612 - val_loss: 4.3688 - val_accuracy: 0.1370\n",
            "Epoch 420/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.8908 - accuracy: 0.6645 - val_loss: 4.3979 - val_accuracy: 0.1487\n",
            "Epoch 421/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8975 - accuracy: 0.6730 - val_loss: 4.4282 - val_accuracy: 0.1334\n",
            "Epoch 422/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8906 - accuracy: 0.6740 - val_loss: 4.3328 - val_accuracy: 0.1450\n",
            "Epoch 423/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.8967 - accuracy: 0.6694 - val_loss: 4.3503 - val_accuracy: 0.1443\n",
            "Epoch 424/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8895 - accuracy: 0.6698 - val_loss: 4.3505 - val_accuracy: 0.1465\n",
            "Epoch 425/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.6718 - val_loss: 4.3648 - val_accuracy: 0.1458\n",
            "Epoch 426/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8857 - accuracy: 0.6751 - val_loss: 4.3909 - val_accuracy: 0.1421\n",
            "Epoch 427/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8996 - accuracy: 0.6652 - val_loss: 4.3985 - val_accuracy: 0.1494\n",
            "Epoch 428/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8920 - accuracy: 0.6699 - val_loss: 4.4411 - val_accuracy: 0.1341\n",
            "Epoch 429/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8828 - accuracy: 0.6756 - val_loss: 4.4070 - val_accuracy: 0.1421\n",
            "Epoch 430/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8881 - accuracy: 0.6699 - val_loss: 4.4378 - val_accuracy: 0.1385\n",
            "Epoch 431/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8791 - accuracy: 0.6763 - val_loss: 4.4201 - val_accuracy: 0.1443\n",
            "Epoch 432/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8831 - accuracy: 0.6749 - val_loss: 4.4313 - val_accuracy: 0.1399\n",
            "Epoch 433/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8852 - accuracy: 0.6707 - val_loss: 4.4677 - val_accuracy: 0.1414\n",
            "Epoch 434/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8777 - accuracy: 0.6758 - val_loss: 4.4515 - val_accuracy: 0.1363\n",
            "Epoch 435/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8789 - accuracy: 0.6778 - val_loss: 4.4920 - val_accuracy: 0.1327\n",
            "Epoch 436/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.6761 - val_loss: 4.4590 - val_accuracy: 0.1312\n",
            "Epoch 437/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8734 - accuracy: 0.6752 - val_loss: 4.4277 - val_accuracy: 0.1429\n",
            "Epoch 438/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8741 - accuracy: 0.6756 - val_loss: 4.5056 - val_accuracy: 0.1341\n",
            "Epoch 439/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 0.6749 - val_loss: 4.4253 - val_accuracy: 0.1487\n",
            "Epoch 440/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8789 - accuracy: 0.6738 - val_loss: 4.4415 - val_accuracy: 0.1407\n",
            "Epoch 441/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8849 - accuracy: 0.6758 - val_loss: 4.4850 - val_accuracy: 0.1443\n",
            "Epoch 442/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8719 - accuracy: 0.6838 - val_loss: 4.4679 - val_accuracy: 0.1407\n",
            "Epoch 443/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8724 - accuracy: 0.6782 - val_loss: 4.5615 - val_accuracy: 0.1363\n",
            "Epoch 444/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8705 - accuracy: 0.6783 - val_loss: 4.4908 - val_accuracy: 0.1312\n",
            "Epoch 445/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.6769 - val_loss: 4.5423 - val_accuracy: 0.1392\n",
            "Epoch 446/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8638 - accuracy: 0.6780 - val_loss: 4.5033 - val_accuracy: 0.1458\n",
            "Epoch 447/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8687 - accuracy: 0.6783 - val_loss: 4.4990 - val_accuracy: 0.1399\n",
            "Epoch 448/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8593 - accuracy: 0.6880 - val_loss: 4.6118 - val_accuracy: 0.1334\n",
            "Epoch 449/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.8729 - accuracy: 0.6767 - val_loss: 4.5933 - val_accuracy: 0.1378\n",
            "Epoch 450/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8706 - accuracy: 0.6763 - val_loss: 4.4866 - val_accuracy: 0.1392\n",
            "Epoch 451/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.8626 - accuracy: 0.6816 - val_loss: 4.5364 - val_accuracy: 0.1385\n",
            "Epoch 452/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8622 - accuracy: 0.6813 - val_loss: 4.5963 - val_accuracy: 0.1334\n",
            "Epoch 453/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8664 - accuracy: 0.6783 - val_loss: 4.5511 - val_accuracy: 0.1429\n",
            "Epoch 454/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.8599 - accuracy: 0.6805 - val_loss: 4.5579 - val_accuracy: 0.1392\n",
            "Epoch 455/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8596 - accuracy: 0.6847 - val_loss: 4.5390 - val_accuracy: 0.1443\n",
            "Epoch 456/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.6782 - val_loss: 4.5574 - val_accuracy: 0.1407\n",
            "Epoch 457/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8617 - accuracy: 0.6787 - val_loss: 4.6066 - val_accuracy: 0.1385\n",
            "Epoch 458/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8657 - accuracy: 0.6774 - val_loss: 4.5981 - val_accuracy: 0.1450\n",
            "Epoch 459/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8550 - accuracy: 0.6820 - val_loss: 4.5477 - val_accuracy: 0.1443\n",
            "Epoch 460/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8498 - accuracy: 0.6862 - val_loss: 4.5516 - val_accuracy: 0.1414\n",
            "Epoch 461/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8471 - accuracy: 0.6860 - val_loss: 4.6044 - val_accuracy: 0.1414\n",
            "Epoch 462/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8478 - accuracy: 0.6811 - val_loss: 4.6692 - val_accuracy: 0.1421\n",
            "Epoch 463/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8566 - accuracy: 0.6813 - val_loss: 4.6620 - val_accuracy: 0.1305\n",
            "Epoch 464/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8357 - accuracy: 0.6915 - val_loss: 4.6444 - val_accuracy: 0.1399\n",
            "Epoch 465/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8556 - accuracy: 0.6802 - val_loss: 4.6120 - val_accuracy: 0.1378\n",
            "Epoch 466/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8533 - accuracy: 0.6829 - val_loss: 4.6372 - val_accuracy: 0.1348\n",
            "Epoch 467/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8413 - accuracy: 0.6880 - val_loss: 4.6324 - val_accuracy: 0.1414\n",
            "Epoch 468/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8469 - accuracy: 0.6864 - val_loss: 4.6180 - val_accuracy: 0.1436\n",
            "Epoch 469/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8471 - accuracy: 0.6869 - val_loss: 4.6788 - val_accuracy: 0.1378\n",
            "Epoch 470/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8442 - accuracy: 0.6864 - val_loss: 4.7467 - val_accuracy: 0.1392\n",
            "Epoch 471/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8471 - accuracy: 0.6834 - val_loss: 4.6247 - val_accuracy: 0.1487\n",
            "Epoch 472/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8393 - accuracy: 0.6893 - val_loss: 4.7466 - val_accuracy: 0.1370\n",
            "Epoch 473/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8470 - accuracy: 0.6895 - val_loss: 4.7101 - val_accuracy: 0.1312\n",
            "Epoch 474/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8388 - accuracy: 0.6869 - val_loss: 4.6459 - val_accuracy: 0.1421\n",
            "Epoch 475/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8370 - accuracy: 0.6885 - val_loss: 4.6960 - val_accuracy: 0.1385\n",
            "Epoch 476/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8335 - accuracy: 0.6929 - val_loss: 4.7434 - val_accuracy: 0.1407\n",
            "Epoch 477/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8469 - accuracy: 0.6946 - val_loss: 4.6894 - val_accuracy: 0.1334\n",
            "Epoch 478/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8444 - accuracy: 0.6918 - val_loss: 4.7577 - val_accuracy: 0.1378\n",
            "Epoch 479/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8465 - accuracy: 0.6882 - val_loss: 4.7593 - val_accuracy: 0.1268\n",
            "Epoch 480/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.8292 - accuracy: 0.6949 - val_loss: 4.6965 - val_accuracy: 0.1458\n",
            "Epoch 481/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.8380 - accuracy: 0.6893 - val_loss: 4.7573 - val_accuracy: 0.1378\n",
            "Epoch 482/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8377 - accuracy: 0.6927 - val_loss: 4.7223 - val_accuracy: 0.1370\n",
            "Epoch 483/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8291 - accuracy: 0.6969 - val_loss: 4.7469 - val_accuracy: 0.1363\n",
            "Epoch 484/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8232 - accuracy: 0.6953 - val_loss: 4.7509 - val_accuracy: 0.1407\n",
            "Epoch 485/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.8299 - accuracy: 0.6900 - val_loss: 4.7602 - val_accuracy: 0.1414\n",
            "Epoch 486/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8386 - accuracy: 0.6953 - val_loss: 4.7597 - val_accuracy: 0.1458\n",
            "Epoch 487/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8175 - accuracy: 0.7004 - val_loss: 4.8584 - val_accuracy: 0.1356\n",
            "Epoch 488/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8179 - accuracy: 0.7020 - val_loss: 4.7553 - val_accuracy: 0.1385\n",
            "Epoch 489/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8295 - accuracy: 0.6955 - val_loss: 4.7666 - val_accuracy: 0.1443\n",
            "Epoch 490/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8186 - accuracy: 0.6964 - val_loss: 4.7745 - val_accuracy: 0.1436\n",
            "Epoch 491/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8286 - accuracy: 0.6944 - val_loss: 4.8049 - val_accuracy: 0.1480\n",
            "Epoch 492/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8320 - accuracy: 0.6927 - val_loss: 4.7613 - val_accuracy: 0.1443\n",
            "Epoch 493/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8231 - accuracy: 0.6896 - val_loss: 4.8391 - val_accuracy: 0.1414\n",
            "Epoch 494/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8204 - accuracy: 0.6968 - val_loss: 4.7845 - val_accuracy: 0.1370\n",
            "Epoch 495/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8226 - accuracy: 0.6916 - val_loss: 4.8514 - val_accuracy: 0.1399\n",
            "Epoch 496/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8203 - accuracy: 0.6995 - val_loss: 4.8074 - val_accuracy: 0.1392\n",
            "Epoch 497/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8234 - accuracy: 0.7057 - val_loss: 4.8512 - val_accuracy: 0.1443\n",
            "Epoch 498/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.6885 - val_loss: 4.7793 - val_accuracy: 0.1407\n",
            "Epoch 499/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8170 - accuracy: 0.6991 - val_loss: 4.8323 - val_accuracy: 0.1443\n",
            "Epoch 500/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8092 - accuracy: 0.6986 - val_loss: 4.8528 - val_accuracy: 0.1472\n",
            "Epoch 501/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8071 - accuracy: 0.7004 - val_loss: 4.8015 - val_accuracy: 0.1443\n",
            "Epoch 502/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8148 - accuracy: 0.7017 - val_loss: 4.8612 - val_accuracy: 0.1414\n",
            "Epoch 503/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8130 - accuracy: 0.6962 - val_loss: 4.8941 - val_accuracy: 0.1523\n",
            "Epoch 504/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8166 - accuracy: 0.6995 - val_loss: 4.8471 - val_accuracy: 0.1356\n",
            "Epoch 505/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8155 - accuracy: 0.6940 - val_loss: 4.9326 - val_accuracy: 0.1348\n",
            "Epoch 506/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8048 - accuracy: 0.7050 - val_loss: 4.8899 - val_accuracy: 0.1370\n",
            "Epoch 507/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8148 - accuracy: 0.6986 - val_loss: 4.8915 - val_accuracy: 0.1399\n",
            "Epoch 508/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8016 - accuracy: 0.7061 - val_loss: 4.8745 - val_accuracy: 0.1385\n",
            "Epoch 509/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.7093 - val_loss: 4.9035 - val_accuracy: 0.1458\n",
            "Epoch 510/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8124 - accuracy: 0.6984 - val_loss: 4.9236 - val_accuracy: 0.1465\n",
            "Epoch 511/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8082 - accuracy: 0.7101 - val_loss: 4.8958 - val_accuracy: 0.1538\n",
            "Epoch 512/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8006 - accuracy: 0.6971 - val_loss: 4.8615 - val_accuracy: 0.1327\n",
            "Epoch 513/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.8064 - accuracy: 0.6991 - val_loss: 4.9503 - val_accuracy: 0.1429\n",
            "Epoch 514/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7981 - accuracy: 0.7121 - val_loss: 4.9248 - val_accuracy: 0.1509\n",
            "Epoch 515/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7998 - accuracy: 0.7046 - val_loss: 4.9521 - val_accuracy: 0.1465\n",
            "Epoch 516/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.8027 - accuracy: 0.7040 - val_loss: 4.9631 - val_accuracy: 0.1370\n",
            "Epoch 517/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8075 - accuracy: 0.6947 - val_loss: 4.9226 - val_accuracy: 0.1472\n",
            "Epoch 518/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7969 - accuracy: 0.7048 - val_loss: 4.9057 - val_accuracy: 0.1472\n",
            "Epoch 519/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8023 - accuracy: 0.7017 - val_loss: 4.9817 - val_accuracy: 0.1348\n",
            "Epoch 520/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7998 - accuracy: 0.7015 - val_loss: 5.0070 - val_accuracy: 0.1392\n",
            "Epoch 521/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7873 - accuracy: 0.7070 - val_loss: 4.9521 - val_accuracy: 0.1436\n",
            "Epoch 522/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8030 - accuracy: 0.6997 - val_loss: 5.0160 - val_accuracy: 0.1378\n",
            "Epoch 523/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8002 - accuracy: 0.7082 - val_loss: 4.9862 - val_accuracy: 0.1370\n",
            "Epoch 524/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7968 - accuracy: 0.7039 - val_loss: 5.0050 - val_accuracy: 0.1421\n",
            "Epoch 525/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8031 - accuracy: 0.7030 - val_loss: 5.0734 - val_accuracy: 0.1399\n",
            "Epoch 526/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.8008 - accuracy: 0.7050 - val_loss: 4.9578 - val_accuracy: 0.1443\n",
            "Epoch 527/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7988 - accuracy: 0.7046 - val_loss: 5.0366 - val_accuracy: 0.1429\n",
            "Epoch 528/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7966 - accuracy: 0.7030 - val_loss: 4.9695 - val_accuracy: 0.1443\n",
            "Epoch 529/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7877 - accuracy: 0.7057 - val_loss: 5.0242 - val_accuracy: 0.1385\n",
            "Epoch 530/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7925 - accuracy: 0.7084 - val_loss: 5.0478 - val_accuracy: 0.1370\n",
            "Epoch 531/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7967 - accuracy: 0.7068 - val_loss: 5.0813 - val_accuracy: 0.1399\n",
            "Epoch 532/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7920 - accuracy: 0.7090 - val_loss: 5.0754 - val_accuracy: 0.1421\n",
            "Epoch 533/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7907 - accuracy: 0.7092 - val_loss: 5.0236 - val_accuracy: 0.1385\n",
            "Epoch 534/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7842 - accuracy: 0.7152 - val_loss: 5.0970 - val_accuracy: 0.1399\n",
            "Epoch 535/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7908 - accuracy: 0.7077 - val_loss: 5.1117 - val_accuracy: 0.1399\n",
            "Epoch 536/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7848 - accuracy: 0.7053 - val_loss: 5.0537 - val_accuracy: 0.1297\n",
            "Epoch 537/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7893 - accuracy: 0.7117 - val_loss: 5.0698 - val_accuracy: 0.1378\n",
            "Epoch 538/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7809 - accuracy: 0.7044 - val_loss: 5.0874 - val_accuracy: 0.1450\n",
            "Epoch 539/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7768 - accuracy: 0.7104 - val_loss: 5.0838 - val_accuracy: 0.1458\n",
            "Epoch 540/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7874 - accuracy: 0.7095 - val_loss: 5.1012 - val_accuracy: 0.1370\n",
            "Epoch 541/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7834 - accuracy: 0.7144 - val_loss: 5.0965 - val_accuracy: 0.1429\n",
            "Epoch 542/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7736 - accuracy: 0.7152 - val_loss: 5.1920 - val_accuracy: 0.1399\n",
            "Epoch 543/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7940 - accuracy: 0.7061 - val_loss: 5.2144 - val_accuracy: 0.1341\n",
            "Epoch 544/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7787 - accuracy: 0.7168 - val_loss: 5.1162 - val_accuracy: 0.1429\n",
            "Epoch 545/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7729 - accuracy: 0.7172 - val_loss: 5.1173 - val_accuracy: 0.1429\n",
            "Epoch 546/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7780 - accuracy: 0.7159 - val_loss: 5.1286 - val_accuracy: 0.1363\n",
            "Epoch 547/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7838 - accuracy: 0.7093 - val_loss: 5.1556 - val_accuracy: 0.1429\n",
            "Epoch 548/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7691 - accuracy: 0.7170 - val_loss: 5.1393 - val_accuracy: 0.1348\n",
            "Epoch 549/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7800 - accuracy: 0.7124 - val_loss: 5.1197 - val_accuracy: 0.1407\n",
            "Epoch 550/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7679 - accuracy: 0.7186 - val_loss: 5.1431 - val_accuracy: 0.1312\n",
            "Epoch 551/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7754 - accuracy: 0.7095 - val_loss: 5.1641 - val_accuracy: 0.1443\n",
            "Epoch 552/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7680 - accuracy: 0.7135 - val_loss: 5.1550 - val_accuracy: 0.1385\n",
            "Epoch 553/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7787 - accuracy: 0.7124 - val_loss: 5.2497 - val_accuracy: 0.1327\n",
            "Epoch 554/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7732 - accuracy: 0.7146 - val_loss: 5.2031 - val_accuracy: 0.1363\n",
            "Epoch 555/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7672 - accuracy: 0.7150 - val_loss: 5.1535 - val_accuracy: 0.1305\n",
            "Epoch 556/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.7144 - val_loss: 5.1880 - val_accuracy: 0.1421\n",
            "Epoch 557/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.7141 - val_loss: 5.2057 - val_accuracy: 0.1378\n",
            "Epoch 558/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7669 - accuracy: 0.7157 - val_loss: 5.1488 - val_accuracy: 0.1436\n",
            "Epoch 559/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7600 - accuracy: 0.7250 - val_loss: 5.2308 - val_accuracy: 0.1385\n",
            "Epoch 560/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7723 - accuracy: 0.7164 - val_loss: 5.2069 - val_accuracy: 0.1421\n",
            "Epoch 561/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7649 - accuracy: 0.7212 - val_loss: 5.2209 - val_accuracy: 0.1334\n",
            "Epoch 562/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.7230 - val_loss: 5.1917 - val_accuracy: 0.1378\n",
            "Epoch 563/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7625 - accuracy: 0.7221 - val_loss: 5.2408 - val_accuracy: 0.1429\n",
            "Epoch 564/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.7192 - val_loss: 5.2541 - val_accuracy: 0.1392\n",
            "Epoch 565/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7610 - accuracy: 0.7214 - val_loss: 5.2264 - val_accuracy: 0.1443\n",
            "Epoch 566/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7604 - accuracy: 0.7261 - val_loss: 5.2434 - val_accuracy: 0.1443\n",
            "Epoch 567/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7522 - accuracy: 0.7250 - val_loss: 5.2256 - val_accuracy: 0.1436\n",
            "Epoch 568/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.7226 - val_loss: 5.2577 - val_accuracy: 0.1378\n",
            "Epoch 569/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.7256 - val_loss: 5.2446 - val_accuracy: 0.1334\n",
            "Epoch 570/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7591 - accuracy: 0.7185 - val_loss: 5.2984 - val_accuracy: 0.1480\n",
            "Epoch 571/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.7237 - val_loss: 5.2646 - val_accuracy: 0.1429\n",
            "Epoch 572/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7576 - accuracy: 0.7195 - val_loss: 5.3338 - val_accuracy: 0.1392\n",
            "Epoch 573/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7458 - accuracy: 0.7261 - val_loss: 5.3093 - val_accuracy: 0.1348\n",
            "Epoch 574/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7596 - accuracy: 0.7199 - val_loss: 5.3391 - val_accuracy: 0.1429\n",
            "Epoch 575/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7497 - accuracy: 0.7307 - val_loss: 5.3572 - val_accuracy: 0.1348\n",
            "Epoch 576/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7571 - accuracy: 0.7174 - val_loss: 5.3449 - val_accuracy: 0.1268\n",
            "Epoch 577/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7590 - accuracy: 0.7197 - val_loss: 5.2897 - val_accuracy: 0.1392\n",
            "Epoch 578/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7523 - accuracy: 0.7287 - val_loss: 5.3300 - val_accuracy: 0.1421\n",
            "Epoch 579/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.7188 - val_loss: 5.2787 - val_accuracy: 0.1421\n",
            "Epoch 580/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7237 - val_loss: 5.3273 - val_accuracy: 0.1407\n",
            "Epoch 581/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.7254 - val_loss: 5.3204 - val_accuracy: 0.1378\n",
            "Epoch 582/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7495 - accuracy: 0.7257 - val_loss: 5.3294 - val_accuracy: 0.1414\n",
            "Epoch 583/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7254 - val_loss: 5.3704 - val_accuracy: 0.1414\n",
            "Epoch 584/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7346 - accuracy: 0.7292 - val_loss: 5.3587 - val_accuracy: 0.1378\n",
            "Epoch 585/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7491 - accuracy: 0.7243 - val_loss: 5.3173 - val_accuracy: 0.1356\n",
            "Epoch 586/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7356 - accuracy: 0.7365 - val_loss: 5.3191 - val_accuracy: 0.1392\n",
            "Epoch 587/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7437 - accuracy: 0.7236 - val_loss: 5.4392 - val_accuracy: 0.1319\n",
            "Epoch 588/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7498 - accuracy: 0.7309 - val_loss: 5.4067 - val_accuracy: 0.1385\n",
            "Epoch 589/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.7248 - val_loss: 5.3856 - val_accuracy: 0.1443\n",
            "Epoch 590/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7536 - accuracy: 0.7236 - val_loss: 5.3512 - val_accuracy: 0.1399\n",
            "Epoch 591/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7379 - accuracy: 0.7256 - val_loss: 5.4695 - val_accuracy: 0.1429\n",
            "Epoch 592/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7410 - accuracy: 0.7332 - val_loss: 5.4331 - val_accuracy: 0.1399\n",
            "Epoch 593/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7303 - accuracy: 0.7363 - val_loss: 5.3575 - val_accuracy: 0.1363\n",
            "Epoch 594/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7593 - accuracy: 0.7168 - val_loss: 5.3972 - val_accuracy: 0.1370\n",
            "Epoch 595/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.7247 - val_loss: 5.3965 - val_accuracy: 0.1450\n",
            "Epoch 596/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7324 - accuracy: 0.7309 - val_loss: 5.5022 - val_accuracy: 0.1399\n",
            "Epoch 597/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7463 - accuracy: 0.7274 - val_loss: 5.4357 - val_accuracy: 0.1370\n",
            "Epoch 598/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7315 - accuracy: 0.7323 - val_loss: 5.4372 - val_accuracy: 0.1487\n",
            "Epoch 599/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7239 - accuracy: 0.7327 - val_loss: 5.4518 - val_accuracy: 0.1399\n",
            "Epoch 600/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7321 - accuracy: 0.7290 - val_loss: 5.5029 - val_accuracy: 0.1436\n",
            "Epoch 601/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7419 - accuracy: 0.7257 - val_loss: 5.4680 - val_accuracy: 0.1487\n",
            "Epoch 602/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7402 - accuracy: 0.7210 - val_loss: 5.4766 - val_accuracy: 0.1370\n",
            "Epoch 603/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7317 - accuracy: 0.7290 - val_loss: 5.4467 - val_accuracy: 0.1501\n",
            "Epoch 604/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7379 - accuracy: 0.7279 - val_loss: 5.4957 - val_accuracy: 0.1443\n",
            "Epoch 605/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7199 - accuracy: 0.7405 - val_loss: 5.4510 - val_accuracy: 0.1385\n",
            "Epoch 606/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7336 - accuracy: 0.7343 - val_loss: 5.4947 - val_accuracy: 0.1392\n",
            "Epoch 607/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7220 - accuracy: 0.7288 - val_loss: 5.4812 - val_accuracy: 0.1494\n",
            "Epoch 608/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7363 - accuracy: 0.7268 - val_loss: 5.4359 - val_accuracy: 0.1465\n",
            "Epoch 609/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7115 - accuracy: 0.7445 - val_loss: 5.5291 - val_accuracy: 0.1356\n",
            "Epoch 610/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7216 - accuracy: 0.7378 - val_loss: 5.4907 - val_accuracy: 0.1429\n",
            "Epoch 611/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.7345 - val_loss: 5.4803 - val_accuracy: 0.1414\n",
            "Epoch 612/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7254 - accuracy: 0.7396 - val_loss: 5.4706 - val_accuracy: 0.1385\n",
            "Epoch 613/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7224 - accuracy: 0.7352 - val_loss: 5.5163 - val_accuracy: 0.1363\n",
            "Epoch 614/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7201 - accuracy: 0.7405 - val_loss: 5.5005 - val_accuracy: 0.1450\n",
            "Epoch 615/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7181 - accuracy: 0.7345 - val_loss: 5.5784 - val_accuracy: 0.1370\n",
            "Epoch 616/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7180 - accuracy: 0.7303 - val_loss: 5.6077 - val_accuracy: 0.1334\n",
            "Epoch 617/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.7345 - val_loss: 5.5159 - val_accuracy: 0.1319\n",
            "Epoch 618/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7094 - accuracy: 0.7433 - val_loss: 5.5514 - val_accuracy: 0.1414\n",
            "Epoch 619/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.7347 - val_loss: 5.5755 - val_accuracy: 0.1370\n",
            "Epoch 620/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7228 - accuracy: 0.7369 - val_loss: 5.5631 - val_accuracy: 0.1319\n",
            "Epoch 621/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7182 - accuracy: 0.7354 - val_loss: 5.6027 - val_accuracy: 0.1392\n",
            "Epoch 622/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7197 - accuracy: 0.7369 - val_loss: 5.5690 - val_accuracy: 0.1378\n",
            "Epoch 623/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.7369 - val_loss: 5.5454 - val_accuracy: 0.1378\n",
            "Epoch 624/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7164 - accuracy: 0.7391 - val_loss: 5.6117 - val_accuracy: 0.1378\n",
            "Epoch 625/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.7383 - val_loss: 5.6571 - val_accuracy: 0.1429\n",
            "Epoch 626/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.7385 - val_loss: 5.6579 - val_accuracy: 0.1407\n",
            "Epoch 627/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.7416 - val_loss: 5.6093 - val_accuracy: 0.1356\n",
            "Epoch 628/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.7347 - val_loss: 5.6543 - val_accuracy: 0.1458\n",
            "Epoch 629/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7173 - accuracy: 0.7350 - val_loss: 5.6291 - val_accuracy: 0.1399\n",
            "Epoch 630/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.7423 - val_loss: 5.5865 - val_accuracy: 0.1378\n",
            "Epoch 631/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7139 - accuracy: 0.7360 - val_loss: 5.6149 - val_accuracy: 0.1399\n",
            "Epoch 632/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7149 - accuracy: 0.7385 - val_loss: 5.6261 - val_accuracy: 0.1363\n",
            "Epoch 633/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.7343 - val_loss: 5.6541 - val_accuracy: 0.1465\n",
            "Epoch 634/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6990 - accuracy: 0.7458 - val_loss: 5.6889 - val_accuracy: 0.1414\n",
            "Epoch 635/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7016 - accuracy: 0.7471 - val_loss: 5.6997 - val_accuracy: 0.1356\n",
            "Epoch 636/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7020 - accuracy: 0.7422 - val_loss: 5.7318 - val_accuracy: 0.1450\n",
            "Epoch 637/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7002 - accuracy: 0.7473 - val_loss: 5.6395 - val_accuracy: 0.1450\n",
            "Epoch 638/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7100 - accuracy: 0.7409 - val_loss: 5.6538 - val_accuracy: 0.1494\n",
            "Epoch 639/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.7438 - val_loss: 5.6574 - val_accuracy: 0.1480\n",
            "Epoch 640/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.7001 - accuracy: 0.7422 - val_loss: 5.7224 - val_accuracy: 0.1399\n",
            "Epoch 641/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.7067 - accuracy: 0.7391 - val_loss: 5.6649 - val_accuracy: 0.1472\n",
            "Epoch 642/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7147 - accuracy: 0.7358 - val_loss: 5.7285 - val_accuracy: 0.1414\n",
            "Epoch 643/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.7447 - val_loss: 5.6696 - val_accuracy: 0.1443\n",
            "Epoch 644/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.7436 - val_loss: 5.7209 - val_accuracy: 0.1436\n",
            "Epoch 645/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.7312 - val_loss: 5.6977 - val_accuracy: 0.1385\n",
            "Epoch 646/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.7407 - val_loss: 5.7297 - val_accuracy: 0.1407\n",
            "Epoch 647/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.7403 - val_loss: 5.8051 - val_accuracy: 0.1341\n",
            "Epoch 648/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.7469 - val_loss: 5.7190 - val_accuracy: 0.1407\n",
            "Epoch 649/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.7447 - val_loss: 5.7604 - val_accuracy: 0.1487\n",
            "Epoch 650/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.7449 - val_loss: 5.7572 - val_accuracy: 0.1458\n",
            "Epoch 651/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.7474 - val_loss: 5.8312 - val_accuracy: 0.1392\n",
            "Epoch 652/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.7420 - val_loss: 5.7737 - val_accuracy: 0.1436\n",
            "Epoch 653/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.7474 - val_loss: 5.7743 - val_accuracy: 0.1385\n",
            "Epoch 654/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.7474 - val_loss: 5.8343 - val_accuracy: 0.1523\n",
            "Epoch 655/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6954 - accuracy: 0.7487 - val_loss: 5.8075 - val_accuracy: 0.1356\n",
            "Epoch 656/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7551 - val_loss: 5.8217 - val_accuracy: 0.1414\n",
            "Epoch 657/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.7511 - val_loss: 5.8036 - val_accuracy: 0.1399\n",
            "Epoch 658/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.7411 - val_loss: 5.7910 - val_accuracy: 0.1407\n",
            "Epoch 659/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.7502 - val_loss: 5.7797 - val_accuracy: 0.1487\n",
            "Epoch 660/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.7513 - val_loss: 5.8442 - val_accuracy: 0.1421\n",
            "Epoch 661/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.7433 - val_loss: 5.8244 - val_accuracy: 0.1363\n",
            "Epoch 662/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.7473 - val_loss: 5.8429 - val_accuracy: 0.1421\n",
            "Epoch 663/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.7391 - val_loss: 5.9433 - val_accuracy: 0.1421\n",
            "Epoch 664/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.7474 - val_loss: 5.8497 - val_accuracy: 0.1487\n",
            "Epoch 665/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6859 - accuracy: 0.7464 - val_loss: 5.8412 - val_accuracy: 0.1436\n",
            "Epoch 666/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6670 - accuracy: 0.7513 - val_loss: 5.8695 - val_accuracy: 0.1443\n",
            "Epoch 667/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6748 - accuracy: 0.7551 - val_loss: 5.8445 - val_accuracy: 0.1429\n",
            "Epoch 668/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6736 - accuracy: 0.7542 - val_loss: 5.9113 - val_accuracy: 0.1472\n",
            "Epoch 669/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6794 - accuracy: 0.7522 - val_loss: 5.8327 - val_accuracy: 0.1443\n",
            "Epoch 670/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6829 - accuracy: 0.7493 - val_loss: 5.8188 - val_accuracy: 0.1523\n",
            "Epoch 671/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6778 - accuracy: 0.7520 - val_loss: 5.9023 - val_accuracy: 0.1472\n",
            "Epoch 672/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.7558 - val_loss: 5.8232 - val_accuracy: 0.1494\n",
            "Epoch 673/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.7458 - val_loss: 5.8968 - val_accuracy: 0.1494\n",
            "Epoch 674/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.7516 - val_loss: 5.9297 - val_accuracy: 0.1378\n",
            "Epoch 675/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.7551 - val_loss: 5.9139 - val_accuracy: 0.1560\n",
            "Epoch 676/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.7493 - val_loss: 5.8738 - val_accuracy: 0.1523\n",
            "Epoch 677/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.7518 - val_loss: 5.9057 - val_accuracy: 0.1487\n",
            "Epoch 678/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.7538 - val_loss: 5.8686 - val_accuracy: 0.1458\n",
            "Epoch 679/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.7624 - val_loss: 6.0140 - val_accuracy: 0.1458\n",
            "Epoch 680/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.7507 - val_loss: 5.9694 - val_accuracy: 0.1509\n",
            "Epoch 681/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6746 - accuracy: 0.7526 - val_loss: 5.8701 - val_accuracy: 0.1509\n",
            "Epoch 682/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.7535 - val_loss: 6.0474 - val_accuracy: 0.1436\n",
            "Epoch 683/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.7531 - val_loss: 6.0234 - val_accuracy: 0.1436\n",
            "Epoch 684/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.7547 - val_loss: 6.0155 - val_accuracy: 0.1399\n",
            "Epoch 685/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.7569 - val_loss: 5.9321 - val_accuracy: 0.1494\n",
            "Epoch 686/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.7606 - val_loss: 5.9190 - val_accuracy: 0.1443\n",
            "Epoch 687/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.7540 - val_loss: 5.9744 - val_accuracy: 0.1494\n",
            "Epoch 688/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.7509 - val_loss: 6.0100 - val_accuracy: 0.1472\n",
            "Epoch 689/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.7588 - val_loss: 6.0870 - val_accuracy: 0.1414\n",
            "Epoch 690/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.7553 - val_loss: 6.0396 - val_accuracy: 0.1509\n",
            "Epoch 691/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.7524 - val_loss: 6.0320 - val_accuracy: 0.1443\n",
            "Epoch 692/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.7535 - val_loss: 6.0293 - val_accuracy: 0.1458\n",
            "Epoch 693/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.7598 - val_loss: 6.0238 - val_accuracy: 0.1443\n",
            "Epoch 694/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7602 - val_loss: 5.9912 - val_accuracy: 0.1487\n",
            "Epoch 695/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6499 - accuracy: 0.7629 - val_loss: 6.0401 - val_accuracy: 0.1392\n",
            "Epoch 696/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6599 - accuracy: 0.7628 - val_loss: 5.9873 - val_accuracy: 0.1436\n",
            "Epoch 697/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6647 - accuracy: 0.7609 - val_loss: 5.9961 - val_accuracy: 0.1370\n",
            "Epoch 698/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6647 - accuracy: 0.7538 - val_loss: 6.0926 - val_accuracy: 0.1385\n",
            "Epoch 699/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6560 - accuracy: 0.7639 - val_loss: 6.1380 - val_accuracy: 0.1414\n",
            "Epoch 700/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6533 - accuracy: 0.7571 - val_loss: 6.0960 - val_accuracy: 0.1560\n",
            "Epoch 701/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6681 - accuracy: 0.7535 - val_loss: 6.1678 - val_accuracy: 0.1509\n",
            "Epoch 702/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.7681 - val_loss: 6.1089 - val_accuracy: 0.1465\n",
            "Epoch 703/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.7606 - val_loss: 6.1104 - val_accuracy: 0.1407\n",
            "Epoch 704/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.7651 - val_loss: 6.1653 - val_accuracy: 0.1450\n",
            "Epoch 705/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.7593 - val_loss: 6.0923 - val_accuracy: 0.1407\n",
            "Epoch 706/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.7589 - val_loss: 6.1529 - val_accuracy: 0.1363\n",
            "Epoch 707/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.7542 - val_loss: 6.1699 - val_accuracy: 0.1472\n",
            "Epoch 708/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.7580 - val_loss: 6.1089 - val_accuracy: 0.1465\n",
            "Epoch 709/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.7595 - val_loss: 6.1009 - val_accuracy: 0.1429\n",
            "Epoch 710/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.7686 - val_loss: 6.1810 - val_accuracy: 0.1472\n",
            "Epoch 711/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7591 - val_loss: 6.1661 - val_accuracy: 0.1509\n",
            "Epoch 712/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.7533 - val_loss: 6.1197 - val_accuracy: 0.1443\n",
            "Epoch 713/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7670 - val_loss: 6.1598 - val_accuracy: 0.1472\n",
            "Epoch 714/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.7673 - val_loss: 6.1810 - val_accuracy: 0.1414\n",
            "Epoch 715/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.7668 - val_loss: 6.1432 - val_accuracy: 0.1450\n",
            "Epoch 716/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.7655 - val_loss: 6.1749 - val_accuracy: 0.1465\n",
            "Epoch 717/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7606 - val_loss: 6.1655 - val_accuracy: 0.1443\n",
            "Epoch 718/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.7628 - val_loss: 6.1690 - val_accuracy: 0.1458\n",
            "Epoch 719/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.7633 - val_loss: 6.2221 - val_accuracy: 0.1494\n",
            "Epoch 720/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.7640 - val_loss: 6.1988 - val_accuracy: 0.1465\n",
            "Epoch 721/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7704 - val_loss: 6.1801 - val_accuracy: 0.1487\n",
            "Epoch 722/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7710 - val_loss: 6.2584 - val_accuracy: 0.1385\n",
            "Epoch 723/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6474 - accuracy: 0.7642 - val_loss: 6.2649 - val_accuracy: 0.1487\n",
            "Epoch 724/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6582 - accuracy: 0.7593 - val_loss: 6.2847 - val_accuracy: 0.1392\n",
            "Epoch 725/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6518 - accuracy: 0.7595 - val_loss: 6.1739 - val_accuracy: 0.1487\n",
            "Epoch 726/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6505 - accuracy: 0.7624 - val_loss: 6.3236 - val_accuracy: 0.1421\n",
            "Epoch 727/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6557 - accuracy: 0.7573 - val_loss: 6.2502 - val_accuracy: 0.1458\n",
            "Epoch 728/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6433 - accuracy: 0.7653 - val_loss: 6.2215 - val_accuracy: 0.1545\n",
            "Epoch 729/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6418 - accuracy: 0.7666 - val_loss: 6.3207 - val_accuracy: 0.1472\n",
            "Epoch 730/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6320 - accuracy: 0.7684 - val_loss: 6.2174 - val_accuracy: 0.1378\n",
            "Epoch 731/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7617 - val_loss: 6.3237 - val_accuracy: 0.1465\n",
            "Epoch 732/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7648 - val_loss: 6.2881 - val_accuracy: 0.1450\n",
            "Epoch 733/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.7677 - val_loss: 6.3451 - val_accuracy: 0.1436\n",
            "Epoch 734/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.7717 - val_loss: 6.2954 - val_accuracy: 0.1472\n",
            "Epoch 735/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.7681 - val_loss: 6.3363 - val_accuracy: 0.1421\n",
            "Epoch 736/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.7646 - val_loss: 6.3441 - val_accuracy: 0.1487\n",
            "Epoch 737/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.7722 - val_loss: 6.3015 - val_accuracy: 0.1443\n",
            "Epoch 738/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.7719 - val_loss: 6.4091 - val_accuracy: 0.1378\n",
            "Epoch 739/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.7659 - val_loss: 6.3313 - val_accuracy: 0.1385\n",
            "Epoch 740/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7677 - val_loss: 6.3404 - val_accuracy: 0.1465\n",
            "Epoch 741/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.7697 - val_loss: 6.3301 - val_accuracy: 0.1414\n",
            "Epoch 742/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.7792 - val_loss: 6.3628 - val_accuracy: 0.1421\n",
            "Epoch 743/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.7615 - val_loss: 6.3117 - val_accuracy: 0.1523\n",
            "Epoch 744/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7686 - val_loss: 6.3674 - val_accuracy: 0.1436\n",
            "Epoch 745/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.7706 - val_loss: 6.3520 - val_accuracy: 0.1480\n",
            "Epoch 746/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.7639 - val_loss: 6.3583 - val_accuracy: 0.1538\n",
            "Epoch 747/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.7733 - val_loss: 6.4015 - val_accuracy: 0.1407\n",
            "Epoch 748/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.7737 - val_loss: 6.4714 - val_accuracy: 0.1429\n",
            "Epoch 749/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.7717 - val_loss: 6.3796 - val_accuracy: 0.1436\n",
            "Epoch 750/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.7753 - val_loss: 6.4071 - val_accuracy: 0.1523\n",
            "Epoch 751/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7752 - val_loss: 6.4675 - val_accuracy: 0.1465\n",
            "Epoch 752/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.7761 - val_loss: 6.3753 - val_accuracy: 0.1487\n",
            "Epoch 753/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.7686 - val_loss: 6.4445 - val_accuracy: 0.1516\n",
            "Epoch 754/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6221 - accuracy: 0.7748 - val_loss: 6.4349 - val_accuracy: 0.1450\n",
            "Epoch 755/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.7726 - val_loss: 6.5345 - val_accuracy: 0.1429\n",
            "Epoch 756/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.7717 - val_loss: 6.4576 - val_accuracy: 0.1472\n",
            "Epoch 757/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6300 - accuracy: 0.7681 - val_loss: 6.4623 - val_accuracy: 0.1370\n",
            "Epoch 758/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6138 - accuracy: 0.7786 - val_loss: 6.4704 - val_accuracy: 0.1465\n",
            "Epoch 759/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6292 - accuracy: 0.7699 - val_loss: 6.4953 - val_accuracy: 0.1531\n",
            "Epoch 760/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6286 - accuracy: 0.7712 - val_loss: 6.5136 - val_accuracy: 0.1450\n",
            "Epoch 761/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.7722 - val_loss: 6.4765 - val_accuracy: 0.1465\n",
            "Epoch 762/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.7710 - val_loss: 6.4470 - val_accuracy: 0.1465\n",
            "Epoch 763/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7697 - val_loss: 6.4587 - val_accuracy: 0.1450\n",
            "Epoch 764/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.7795 - val_loss: 6.4853 - val_accuracy: 0.1465\n",
            "Epoch 765/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7777 - val_loss: 6.5336 - val_accuracy: 0.1450\n",
            "Epoch 766/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.7728 - val_loss: 6.5456 - val_accuracy: 0.1501\n",
            "Epoch 767/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.7706 - val_loss: 6.5999 - val_accuracy: 0.1443\n",
            "Epoch 768/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.7619 - val_loss: 6.5211 - val_accuracy: 0.1385\n",
            "Epoch 769/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7755 - val_loss: 6.6380 - val_accuracy: 0.1472\n",
            "Epoch 770/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7806 - val_loss: 6.5147 - val_accuracy: 0.1429\n",
            "Epoch 771/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.7706 - val_loss: 6.5199 - val_accuracy: 0.1501\n",
            "Epoch 772/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.7784 - val_loss: 6.5359 - val_accuracy: 0.1523\n",
            "Epoch 773/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.7808 - val_loss: 6.5041 - val_accuracy: 0.1429\n",
            "Epoch 774/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.7650 - val_loss: 6.6607 - val_accuracy: 0.1465\n",
            "Epoch 775/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.7795 - val_loss: 6.6072 - val_accuracy: 0.1472\n",
            "Epoch 776/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.7741 - val_loss: 6.5864 - val_accuracy: 0.1429\n",
            "Epoch 777/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.7688 - val_loss: 6.5717 - val_accuracy: 0.1421\n",
            "Epoch 778/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.7741 - val_loss: 6.6210 - val_accuracy: 0.1421\n",
            "Epoch 779/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.7781 - val_loss: 6.6586 - val_accuracy: 0.1392\n",
            "Epoch 780/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7803 - val_loss: 6.6582 - val_accuracy: 0.1487\n",
            "Epoch 781/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.7839 - val_loss: 6.6458 - val_accuracy: 0.1509\n",
            "Epoch 782/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.7848 - val_loss: 6.6690 - val_accuracy: 0.1494\n",
            "Epoch 783/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.7746 - val_loss: 6.6676 - val_accuracy: 0.1480\n",
            "Epoch 784/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5961 - accuracy: 0.7832 - val_loss: 6.5787 - val_accuracy: 0.1378\n",
            "Epoch 785/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6161 - accuracy: 0.7777 - val_loss: 6.6366 - val_accuracy: 0.1516\n",
            "Epoch 786/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.7717 - val_loss: 6.6838 - val_accuracy: 0.1494\n",
            "Epoch 787/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5948 - accuracy: 0.7761 - val_loss: 6.6763 - val_accuracy: 0.1538\n",
            "Epoch 788/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.7843 - val_loss: 6.6467 - val_accuracy: 0.1436\n",
            "Epoch 789/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6060 - accuracy: 0.7763 - val_loss: 6.7158 - val_accuracy: 0.1450\n",
            "Epoch 790/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5943 - accuracy: 0.7863 - val_loss: 6.7634 - val_accuracy: 0.1414\n",
            "Epoch 791/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5998 - accuracy: 0.7832 - val_loss: 6.6883 - val_accuracy: 0.1472\n",
            "Epoch 792/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.7719 - val_loss: 6.7157 - val_accuracy: 0.1531\n",
            "Epoch 793/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.7702 - val_loss: 6.6801 - val_accuracy: 0.1399\n",
            "Epoch 794/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.7799 - val_loss: 6.7262 - val_accuracy: 0.1385\n",
            "Epoch 795/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7859 - val_loss: 6.7592 - val_accuracy: 0.1501\n",
            "Epoch 796/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7868 - val_loss: 6.6850 - val_accuracy: 0.1429\n",
            "Epoch 797/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.7799 - val_loss: 6.7644 - val_accuracy: 0.1443\n",
            "Epoch 798/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.7817 - val_loss: 6.7484 - val_accuracy: 0.1385\n",
            "Epoch 799/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7726 - val_loss: 6.7467 - val_accuracy: 0.1480\n",
            "Epoch 800/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7841 - val_loss: 6.7322 - val_accuracy: 0.1399\n",
            "Epoch 801/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7857 - val_loss: 6.7778 - val_accuracy: 0.1472\n",
            "Epoch 802/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7828 - val_loss: 6.7419 - val_accuracy: 0.1552\n",
            "Epoch 803/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7867 - val_loss: 6.8814 - val_accuracy: 0.1363\n",
            "Epoch 804/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7850 - val_loss: 6.7833 - val_accuracy: 0.1421\n",
            "Epoch 805/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.7806 - val_loss: 6.7976 - val_accuracy: 0.1443\n",
            "Epoch 806/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7825 - val_loss: 6.8261 - val_accuracy: 0.1436\n",
            "Epoch 807/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7874 - val_loss: 6.7995 - val_accuracy: 0.1429\n",
            "Epoch 808/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7883 - val_loss: 6.8007 - val_accuracy: 0.1480\n",
            "Epoch 809/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7850 - val_loss: 6.7722 - val_accuracy: 0.1370\n",
            "Epoch 810/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7850 - val_loss: 6.7788 - val_accuracy: 0.1465\n",
            "Epoch 811/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7792 - val_loss: 6.7826 - val_accuracy: 0.1487\n",
            "Epoch 812/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7903 - val_loss: 6.8456 - val_accuracy: 0.1472\n",
            "Epoch 813/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7894 - val_loss: 6.8028 - val_accuracy: 0.1465\n",
            "Epoch 814/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7969 - val_loss: 6.8676 - val_accuracy: 0.1458\n",
            "Epoch 815/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6026 - accuracy: 0.7741 - val_loss: 6.9311 - val_accuracy: 0.1450\n",
            "Epoch 816/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5832 - accuracy: 0.7890 - val_loss: 6.8730 - val_accuracy: 0.1414\n",
            "Epoch 817/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5825 - accuracy: 0.7876 - val_loss: 6.8374 - val_accuracy: 0.1523\n",
            "Epoch 818/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.7784 - val_loss: 6.9712 - val_accuracy: 0.1523\n",
            "Epoch 819/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5843 - accuracy: 0.7912 - val_loss: 6.8947 - val_accuracy: 0.1450\n",
            "Epoch 820/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5818 - accuracy: 0.7865 - val_loss: 6.9546 - val_accuracy: 0.1363\n",
            "Epoch 821/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5902 - accuracy: 0.7841 - val_loss: 6.9426 - val_accuracy: 0.1458\n",
            "Epoch 822/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7786 - val_loss: 6.9239 - val_accuracy: 0.1436\n",
            "Epoch 823/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7912 - val_loss: 6.9107 - val_accuracy: 0.1436\n",
            "Epoch 824/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.7850 - val_loss: 6.9227 - val_accuracy: 0.1443\n",
            "Epoch 825/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5693 - accuracy: 0.7930 - val_loss: 6.9535 - val_accuracy: 0.1494\n",
            "Epoch 826/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7919 - val_loss: 6.8790 - val_accuracy: 0.1494\n",
            "Epoch 827/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7848 - val_loss: 6.9725 - val_accuracy: 0.1421\n",
            "Epoch 828/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7954 - val_loss: 6.9780 - val_accuracy: 0.1414\n",
            "Epoch 829/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7958 - val_loss: 6.9488 - val_accuracy: 0.1545\n",
            "Epoch 830/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7888 - val_loss: 6.9708 - val_accuracy: 0.1450\n",
            "Epoch 831/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7852 - val_loss: 6.9724 - val_accuracy: 0.1552\n",
            "Epoch 832/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7810 - val_loss: 6.9710 - val_accuracy: 0.1545\n",
            "Epoch 833/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7865 - val_loss: 7.0370 - val_accuracy: 0.1480\n",
            "Epoch 834/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7817 - val_loss: 7.0385 - val_accuracy: 0.1421\n",
            "Epoch 835/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7903 - val_loss: 7.0267 - val_accuracy: 0.1407\n",
            "Epoch 836/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7929 - val_loss: 7.0356 - val_accuracy: 0.1494\n",
            "Epoch 837/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7832 - val_loss: 7.0017 - val_accuracy: 0.1523\n",
            "Epoch 838/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7965 - val_loss: 6.9958 - val_accuracy: 0.1429\n",
            "Epoch 839/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7912 - val_loss: 7.0369 - val_accuracy: 0.1429\n",
            "Epoch 840/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.7936 - val_loss: 7.0263 - val_accuracy: 0.1407\n",
            "Epoch 841/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7899 - val_loss: 7.0527 - val_accuracy: 0.1399\n",
            "Epoch 842/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7914 - val_loss: 6.9693 - val_accuracy: 0.1421\n",
            "Epoch 843/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7954 - val_loss: 7.0674 - val_accuracy: 0.1501\n",
            "Epoch 844/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5806 - accuracy: 0.7857 - val_loss: 7.0619 - val_accuracy: 0.1509\n",
            "Epoch 845/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5696 - accuracy: 0.7956 - val_loss: 7.0194 - val_accuracy: 0.1480\n",
            "Epoch 846/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5771 - accuracy: 0.7901 - val_loss: 7.1037 - val_accuracy: 0.1458\n",
            "Epoch 847/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5599 - accuracy: 0.7981 - val_loss: 7.0874 - val_accuracy: 0.1407\n",
            "Epoch 848/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5609 - accuracy: 0.8020 - val_loss: 7.1151 - val_accuracy: 0.1450\n",
            "Epoch 849/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5828 - accuracy: 0.7867 - val_loss: 7.1397 - val_accuracy: 0.1458\n",
            "Epoch 850/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5671 - accuracy: 0.7967 - val_loss: 7.0929 - val_accuracy: 0.1487\n",
            "Epoch 851/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5662 - accuracy: 0.7903 - val_loss: 7.1510 - val_accuracy: 0.1494\n",
            "Epoch 852/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5649 - accuracy: 0.7947 - val_loss: 7.1027 - val_accuracy: 0.1429\n",
            "Epoch 853/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7954 - val_loss: 7.1730 - val_accuracy: 0.1458\n",
            "Epoch 854/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7952 - val_loss: 7.1542 - val_accuracy: 0.1450\n",
            "Epoch 855/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7939 - val_loss: 7.0926 - val_accuracy: 0.1421\n",
            "Epoch 856/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7989 - val_loss: 7.1766 - val_accuracy: 0.1458\n",
            "Epoch 857/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7881 - val_loss: 7.1688 - val_accuracy: 0.1538\n",
            "Epoch 858/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7859 - val_loss: 7.2321 - val_accuracy: 0.1421\n",
            "Epoch 859/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.8080 - val_loss: 7.2341 - val_accuracy: 0.1487\n",
            "Epoch 860/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.8011 - val_loss: 7.1617 - val_accuracy: 0.1487\n",
            "Epoch 861/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7958 - val_loss: 7.2124 - val_accuracy: 0.1501\n",
            "Epoch 862/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7932 - val_loss: 7.1634 - val_accuracy: 0.1429\n",
            "Epoch 863/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.8045 - val_loss: 7.1649 - val_accuracy: 0.1392\n",
            "Epoch 864/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.8036 - val_loss: 7.1901 - val_accuracy: 0.1509\n",
            "Epoch 865/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7943 - val_loss: 7.2354 - val_accuracy: 0.1487\n",
            "Epoch 866/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7954 - val_loss: 7.1897 - val_accuracy: 0.1501\n",
            "Epoch 867/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7970 - val_loss: 7.2217 - val_accuracy: 0.1436\n",
            "Epoch 868/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7903 - val_loss: 7.1747 - val_accuracy: 0.1465\n",
            "Epoch 869/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5541 - accuracy: 0.7939 - val_loss: 7.2240 - val_accuracy: 0.1407\n",
            "Epoch 870/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.8012 - val_loss: 7.1783 - val_accuracy: 0.1523\n",
            "Epoch 871/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7914 - val_loss: 7.2379 - val_accuracy: 0.1327\n",
            "Epoch 872/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.8029 - val_loss: 7.2550 - val_accuracy: 0.1501\n",
            "Epoch 873/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7981 - val_loss: 7.2164 - val_accuracy: 0.1480\n",
            "Epoch 874/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.8082 - val_loss: 7.3163 - val_accuracy: 0.1458\n",
            "Epoch 875/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5427 - accuracy: 0.8027 - val_loss: 7.2689 - val_accuracy: 0.1450\n",
            "Epoch 876/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5552 - accuracy: 0.7976 - val_loss: 7.3182 - val_accuracy: 0.1458\n",
            "Epoch 877/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5372 - accuracy: 0.8093 - val_loss: 7.3542 - val_accuracy: 0.1436\n",
            "Epoch 878/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5654 - accuracy: 0.7949 - val_loss: 7.3061 - val_accuracy: 0.1509\n",
            "Epoch 879/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5551 - accuracy: 0.7969 - val_loss: 7.2864 - val_accuracy: 0.1392\n",
            "Epoch 880/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5409 - accuracy: 0.8096 - val_loss: 7.2761 - val_accuracy: 0.1458\n",
            "Epoch 881/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5547 - accuracy: 0.8022 - val_loss: 7.2331 - val_accuracy: 0.1450\n",
            "Epoch 882/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5512 - accuracy: 0.7996 - val_loss: 7.3514 - val_accuracy: 0.1480\n",
            "Epoch 883/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5522 - accuracy: 0.7972 - val_loss: 7.3801 - val_accuracy: 0.1516\n",
            "Epoch 884/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.8060 - val_loss: 7.3577 - val_accuracy: 0.1472\n",
            "Epoch 885/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.8058 - val_loss: 7.3350 - val_accuracy: 0.1421\n",
            "Epoch 886/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.8060 - val_loss: 7.4109 - val_accuracy: 0.1421\n",
            "Epoch 887/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.8115 - val_loss: 7.3240 - val_accuracy: 0.1443\n",
            "Epoch 888/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.8012 - val_loss: 7.4485 - val_accuracy: 0.1450\n",
            "Epoch 889/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.8036 - val_loss: 7.3168 - val_accuracy: 0.1501\n",
            "Epoch 890/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7945 - val_loss: 7.3759 - val_accuracy: 0.1443\n",
            "Epoch 891/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5582 - accuracy: 0.7967 - val_loss: 7.4653 - val_accuracy: 0.1356\n",
            "Epoch 892/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7976 - val_loss: 7.4457 - val_accuracy: 0.1480\n",
            "Epoch 893/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.8045 - val_loss: 7.4562 - val_accuracy: 0.1392\n",
            "Epoch 894/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.8023 - val_loss: 7.3662 - val_accuracy: 0.1516\n",
            "Epoch 895/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.8018 - val_loss: 7.4905 - val_accuracy: 0.1458\n",
            "Epoch 896/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.8162 - val_loss: 7.5784 - val_accuracy: 0.1509\n",
            "Epoch 897/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.8014 - val_loss: 7.4523 - val_accuracy: 0.1480\n",
            "Epoch 898/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.8069 - val_loss: 7.4599 - val_accuracy: 0.1407\n",
            "Epoch 899/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7950 - val_loss: 7.5040 - val_accuracy: 0.1480\n",
            "Epoch 900/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.8025 - val_loss: 7.4376 - val_accuracy: 0.1458\n",
            "Epoch 901/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.8003 - val_loss: 7.4844 - val_accuracy: 0.1516\n",
            "Epoch 902/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.8089 - val_loss: 7.5290 - val_accuracy: 0.1480\n",
            "Epoch 903/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.8014 - val_loss: 7.4878 - val_accuracy: 0.1487\n",
            "Epoch 904/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.8080 - val_loss: 7.5480 - val_accuracy: 0.1385\n",
            "Epoch 905/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5273 - accuracy: 0.8078 - val_loss: 7.5501 - val_accuracy: 0.1450\n",
            "Epoch 906/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5335 - accuracy: 0.8049 - val_loss: 7.6108 - val_accuracy: 0.1494\n",
            "Epoch 907/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5359 - accuracy: 0.8058 - val_loss: 7.5226 - val_accuracy: 0.1501\n",
            "Epoch 908/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5455 - accuracy: 0.8020 - val_loss: 7.5835 - val_accuracy: 0.1472\n",
            "Epoch 909/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5288 - accuracy: 0.8082 - val_loss: 7.5831 - val_accuracy: 0.1370\n",
            "Epoch 910/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5345 - accuracy: 0.8060 - val_loss: 7.5006 - val_accuracy: 0.1509\n",
            "Epoch 911/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5310 - accuracy: 0.8084 - val_loss: 7.5989 - val_accuracy: 0.1443\n",
            "Epoch 912/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5368 - accuracy: 0.8084 - val_loss: 7.5727 - val_accuracy: 0.1538\n",
            "Epoch 913/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8082 - val_loss: 7.4890 - val_accuracy: 0.1421\n",
            "Epoch 914/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.8074 - val_loss: 7.5491 - val_accuracy: 0.1494\n",
            "Epoch 915/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.8076 - val_loss: 7.5223 - val_accuracy: 0.1472\n",
            "Epoch 916/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.8025 - val_loss: 7.5852 - val_accuracy: 0.1472\n",
            "Epoch 917/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.8027 - val_loss: 7.4924 - val_accuracy: 0.1523\n",
            "Epoch 918/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.8069 - val_loss: 7.6416 - val_accuracy: 0.1450\n",
            "Epoch 919/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.8020 - val_loss: 7.5946 - val_accuracy: 0.1480\n",
            "Epoch 920/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.8020 - val_loss: 7.6228 - val_accuracy: 0.1494\n",
            "Epoch 921/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.8091 - val_loss: 7.6026 - val_accuracy: 0.1487\n",
            "Epoch 922/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8124 - val_loss: 7.6414 - val_accuracy: 0.1458\n",
            "Epoch 923/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.8098 - val_loss: 7.6724 - val_accuracy: 0.1436\n",
            "Epoch 924/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.8175 - val_loss: 7.6308 - val_accuracy: 0.1465\n",
            "Epoch 925/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.8100 - val_loss: 7.6544 - val_accuracy: 0.1523\n",
            "Epoch 926/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.8043 - val_loss: 7.7599 - val_accuracy: 0.1538\n",
            "Epoch 927/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.8125 - val_loss: 7.6319 - val_accuracy: 0.1414\n",
            "Epoch 928/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.8058 - val_loss: 7.7348 - val_accuracy: 0.1472\n",
            "Epoch 929/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.8063 - val_loss: 7.6559 - val_accuracy: 0.1450\n",
            "Epoch 930/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.8129 - val_loss: 7.7369 - val_accuracy: 0.1443\n",
            "Epoch 931/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.8040 - val_loss: 7.7105 - val_accuracy: 0.1509\n",
            "Epoch 932/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.8146 - val_loss: 7.8292 - val_accuracy: 0.1472\n",
            "Epoch 933/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.8156 - val_loss: 7.7703 - val_accuracy: 0.1399\n",
            "Epoch 934/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.8166 - val_loss: 7.6808 - val_accuracy: 0.1458\n",
            "Epoch 935/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5352 - accuracy: 0.8063 - val_loss: 7.7267 - val_accuracy: 0.1523\n",
            "Epoch 936/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5173 - accuracy: 0.8118 - val_loss: 7.6873 - val_accuracy: 0.1567\n",
            "Epoch 937/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5106 - accuracy: 0.8169 - val_loss: 7.8012 - val_accuracy: 0.1363\n",
            "Epoch 938/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5222 - accuracy: 0.8100 - val_loss: 7.7689 - val_accuracy: 0.1494\n",
            "Epoch 939/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.8140 - val_loss: 7.7630 - val_accuracy: 0.1436\n",
            "Epoch 940/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.8149 - val_loss: 7.7181 - val_accuracy: 0.1487\n",
            "Epoch 941/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.8107 - val_loss: 7.7687 - val_accuracy: 0.1385\n",
            "Epoch 942/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5308 - accuracy: 0.8089 - val_loss: 7.8710 - val_accuracy: 0.1443\n",
            "Epoch 943/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5215 - accuracy: 0.8058 - val_loss: 7.7861 - val_accuracy: 0.1436\n",
            "Epoch 944/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5367 - accuracy: 0.8023 - val_loss: 7.7855 - val_accuracy: 0.1414\n",
            "Epoch 945/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5168 - accuracy: 0.8135 - val_loss: 7.8151 - val_accuracy: 0.1458\n",
            "Epoch 946/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5147 - accuracy: 0.8131 - val_loss: 7.9357 - val_accuracy: 0.1363\n",
            "Epoch 947/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5324 - accuracy: 0.8091 - val_loss: 7.8002 - val_accuracy: 0.1436\n",
            "Epoch 948/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5095 - accuracy: 0.8160 - val_loss: 7.8356 - val_accuracy: 0.1436\n",
            "Epoch 949/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.8069 - val_loss: 7.7838 - val_accuracy: 0.1458\n",
            "Epoch 950/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5110 - accuracy: 0.8109 - val_loss: 7.9029 - val_accuracy: 0.1472\n",
            "Epoch 951/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5225 - accuracy: 0.8063 - val_loss: 7.7845 - val_accuracy: 0.1494\n",
            "Epoch 952/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5190 - accuracy: 0.8158 - val_loss: 7.8446 - val_accuracy: 0.1443\n",
            "Epoch 953/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4994 - accuracy: 0.8204 - val_loss: 7.8888 - val_accuracy: 0.1494\n",
            "Epoch 954/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5140 - accuracy: 0.8193 - val_loss: 7.9118 - val_accuracy: 0.1363\n",
            "Epoch 955/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5152 - accuracy: 0.8125 - val_loss: 7.9077 - val_accuracy: 0.1399\n",
            "Epoch 956/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.8151 - val_loss: 7.8789 - val_accuracy: 0.1450\n",
            "Epoch 957/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8065 - val_loss: 7.9570 - val_accuracy: 0.1436\n",
            "Epoch 958/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8200 - val_loss: 7.8082 - val_accuracy: 0.1458\n",
            "Epoch 959/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8306 - val_loss: 7.9705 - val_accuracy: 0.1443\n",
            "Epoch 960/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8215 - val_loss: 7.9047 - val_accuracy: 0.1407\n",
            "Epoch 961/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.8118 - val_loss: 7.9476 - val_accuracy: 0.1465\n",
            "Epoch 962/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5050 - accuracy: 0.8162 - val_loss: 7.9434 - val_accuracy: 0.1465\n",
            "Epoch 963/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5130 - accuracy: 0.8131 - val_loss: 7.8817 - val_accuracy: 0.1458\n",
            "Epoch 964/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5128 - accuracy: 0.8091 - val_loss: 7.9192 - val_accuracy: 0.1312\n",
            "Epoch 965/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5139 - accuracy: 0.8171 - val_loss: 7.9325 - val_accuracy: 0.1487\n",
            "Epoch 966/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5070 - accuracy: 0.8180 - val_loss: 7.8899 - val_accuracy: 0.1465\n",
            "Epoch 967/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4921 - accuracy: 0.8264 - val_loss: 7.9988 - val_accuracy: 0.1436\n",
            "Epoch 968/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.8237 - val_loss: 7.9626 - val_accuracy: 0.1421\n",
            "Epoch 969/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4920 - accuracy: 0.8226 - val_loss: 8.0644 - val_accuracy: 0.1480\n",
            "Epoch 970/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8217 - val_loss: 7.9164 - val_accuracy: 0.1487\n",
            "Epoch 971/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8191 - val_loss: 7.9609 - val_accuracy: 0.1429\n",
            "Epoch 972/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8104 - val_loss: 8.1446 - val_accuracy: 0.1436\n",
            "Epoch 973/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8224 - val_loss: 8.0108 - val_accuracy: 0.1458\n",
            "Epoch 974/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.8229 - val_loss: 8.1090 - val_accuracy: 0.1450\n",
            "Epoch 975/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8085 - val_loss: 7.9719 - val_accuracy: 0.1378\n",
            "Epoch 976/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8151 - val_loss: 8.1691 - val_accuracy: 0.1392\n",
            "Epoch 977/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8220 - val_loss: 8.0478 - val_accuracy: 0.1414\n",
            "Epoch 978/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8178 - val_loss: 8.0772 - val_accuracy: 0.1582\n",
            "Epoch 979/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.8129 - val_loss: 8.1153 - val_accuracy: 0.1421\n",
            "Epoch 980/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.8147 - val_loss: 8.0816 - val_accuracy: 0.1531\n",
            "Epoch 981/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8297 - val_loss: 8.1124 - val_accuracy: 0.1414\n",
            "Epoch 982/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8268 - val_loss: 8.1635 - val_accuracy: 0.1348\n",
            "Epoch 983/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8182 - val_loss: 8.0005 - val_accuracy: 0.1487\n",
            "Epoch 984/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.8142 - val_loss: 8.1981 - val_accuracy: 0.1385\n",
            "Epoch 985/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8113 - val_loss: 8.1908 - val_accuracy: 0.1516\n",
            "Epoch 986/1000\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8260 - val_loss: 8.0729 - val_accuracy: 0.1458\n",
            "Epoch 987/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8217 - val_loss: 8.1817 - val_accuracy: 0.1421\n",
            "Epoch 988/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.8164 - val_loss: 8.1782 - val_accuracy: 0.1480\n",
            "Epoch 989/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8237 - val_loss: 8.2707 - val_accuracy: 0.1399\n",
            "Epoch 990/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8257 - val_loss: 8.1614 - val_accuracy: 0.1494\n",
            "Epoch 991/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8288 - val_loss: 8.1919 - val_accuracy: 0.1378\n",
            "Epoch 992/1000\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.8184 - val_loss: 8.1274 - val_accuracy: 0.1436\n",
            "Epoch 993/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5150 - accuracy: 0.8104 - val_loss: 8.2326 - val_accuracy: 0.1465\n",
            "Epoch 994/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4878 - accuracy: 0.8178 - val_loss: 8.1880 - val_accuracy: 0.1450\n",
            "Epoch 995/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4797 - accuracy: 0.8324 - val_loss: 8.2757 - val_accuracy: 0.1480\n",
            "Epoch 996/1000\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5060 - accuracy: 0.8164 - val_loss: 8.2309 - val_accuracy: 0.1443\n",
            "Epoch 997/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4913 - accuracy: 0.8246 - val_loss: 8.2280 - val_accuracy: 0.1450\n",
            "Epoch 998/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5153 - accuracy: 0.8115 - val_loss: 8.2694 - val_accuracy: 0.1414\n",
            "Epoch 999/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4809 - accuracy: 0.8264 - val_loss: 8.2384 - val_accuracy: 0.1465\n",
            "Epoch 1000/1000\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4853 - accuracy: 0.8264 - val_loss: 8.2264 - val_accuracy: 0.1385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e04195c0c40>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "T7Tc7JIRPgUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_pred_prob = model_class.predict(X_test_scaled_class)\n",
        "\n",
        "y_pred_class = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test_class, y_pred_class)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# classification report\n",
        "cr = classification_report(y_test_class, y_pred_class)\n",
        "print('Classification Report:')\n",
        "print(cr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPSA5yc6KHW5",
        "outputId": "c8234daf-807f-46e7-ca8c-78eb4e05a88b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54/54 [==============================] - 0s 2ms/step\n",
            "Confusion Matrix:\n",
            "[[26 19 26 48 40 29 29]\n",
            " [34 38 25 46 39 33 32]\n",
            " [25 39 34 39 42 33 38]\n",
            " [19 33 27 43 29 49 33]\n",
            " [23 30 33 43 43 41 50]\n",
            " [32 30 30 48 35 41 36]\n",
            " [27 26 43 51 37 35 34]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.12      0.13       217\n",
            "           1       0.18      0.15      0.16       247\n",
            "           2       0.16      0.14      0.15       250\n",
            "           3       0.14      0.18      0.16       233\n",
            "           4       0.16      0.16      0.16       263\n",
            "           5       0.16      0.16      0.16       252\n",
            "           6       0.13      0.13      0.13       253\n",
            "\n",
            "    accuracy                           0.15      1715\n",
            "   macro avg       0.15      0.15      0.15      1715\n",
            "weighted avg       0.15      0.15      0.15      1715\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_signal_onehot = pd.get_dummies(df['target_signal']).values\n",
        "\n",
        "# Dropping non-numeric columns for individual signal prediction\n",
        "X_signal_numeric = X_signal.select_dtypes(include=[np.number])\n",
        "\n",
        "X_train_signal, X_test_signal, y_train_signal, y_test_signal = train_test_split(X_signal_numeric, y_signal_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize\n",
        "scaler_signal = StandardScaler()\n",
        "X_train_scaled_signal = scaler_signal.fit_transform(X_train_signal)\n",
        "X_test_scaled_signal = scaler_signal.transform(X_test_signal)\n",
        "\n",
        "# Building neural network model\n",
        "model_signal = Sequential()\n",
        "model_signal.add(Dense(64, activation='relu', input_dim=X_train_scaled_signal.shape[1]))\n",
        "model_signal.add(Dense(len(df['target_signal'].unique()), activation='softmax'))  # Output layer for individual signal prediction\n",
        "\n",
        "# Compiling the model\n",
        "model_signal.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model_signal.fit(X_train_scaled_signal, y_train_signal, epochs=500, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCKlFWrTXtr7",
        "outputId": "e1303a45-60ff-490c-f473-d776a76dfa53"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "172/172 [==============================] - 2s 5ms/step - loss: 1.9868 - accuracy: 0.1450 - val_loss: 1.9672 - val_accuracy: 0.1407\n",
            "Epoch 2/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9553 - accuracy: 0.1543 - val_loss: 1.9628 - val_accuracy: 0.1443\n",
            "Epoch 3/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9477 - accuracy: 0.1663 - val_loss: 1.9605 - val_accuracy: 0.1429\n",
            "Epoch 4/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9424 - accuracy: 0.1690 - val_loss: 1.9630 - val_accuracy: 0.1305\n",
            "Epoch 5/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9393 - accuracy: 0.1732 - val_loss: 1.9642 - val_accuracy: 0.1407\n",
            "Epoch 6/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.9365 - accuracy: 0.1787 - val_loss: 1.9640 - val_accuracy: 0.1407\n",
            "Epoch 7/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9349 - accuracy: 0.1725 - val_loss: 1.9643 - val_accuracy: 0.1363\n",
            "Epoch 8/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9317 - accuracy: 0.1805 - val_loss: 1.9651 - val_accuracy: 0.1305\n",
            "Epoch 9/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9311 - accuracy: 0.1789 - val_loss: 1.9669 - val_accuracy: 0.1334\n",
            "Epoch 10/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9293 - accuracy: 0.1856 - val_loss: 1.9681 - val_accuracy: 0.1356\n",
            "Epoch 11/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9276 - accuracy: 0.1838 - val_loss: 1.9675 - val_accuracy: 0.1334\n",
            "Epoch 12/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9265 - accuracy: 0.1909 - val_loss: 1.9709 - val_accuracy: 0.1319\n",
            "Epoch 13/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9250 - accuracy: 0.1864 - val_loss: 1.9694 - val_accuracy: 0.1421\n",
            "Epoch 14/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9237 - accuracy: 0.1904 - val_loss: 1.9716 - val_accuracy: 0.1414\n",
            "Epoch 15/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9228 - accuracy: 0.1909 - val_loss: 1.9711 - val_accuracy: 0.1356\n",
            "Epoch 16/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9223 - accuracy: 0.1844 - val_loss: 1.9709 - val_accuracy: 0.1276\n",
            "Epoch 17/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9211 - accuracy: 0.1900 - val_loss: 1.9724 - val_accuracy: 0.1327\n",
            "Epoch 18/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9205 - accuracy: 0.1991 - val_loss: 1.9719 - val_accuracy: 0.1378\n",
            "Epoch 19/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9192 - accuracy: 0.1938 - val_loss: 1.9728 - val_accuracy: 0.1334\n",
            "Epoch 20/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9188 - accuracy: 0.1922 - val_loss: 1.9748 - val_accuracy: 0.1356\n",
            "Epoch 21/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9173 - accuracy: 0.1951 - val_loss: 1.9790 - val_accuracy: 0.1312\n",
            "Epoch 22/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9174 - accuracy: 0.2013 - val_loss: 1.9784 - val_accuracy: 0.1370\n",
            "Epoch 23/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9160 - accuracy: 0.1971 - val_loss: 1.9773 - val_accuracy: 0.1378\n",
            "Epoch 24/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9162 - accuracy: 0.1955 - val_loss: 1.9778 - val_accuracy: 0.1232\n",
            "Epoch 25/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9152 - accuracy: 0.1978 - val_loss: 1.9794 - val_accuracy: 0.1319\n",
            "Epoch 26/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9144 - accuracy: 0.1957 - val_loss: 1.9779 - val_accuracy: 0.1348\n",
            "Epoch 27/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9142 - accuracy: 0.2035 - val_loss: 1.9807 - val_accuracy: 0.1312\n",
            "Epoch 28/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9136 - accuracy: 0.2030 - val_loss: 1.9807 - val_accuracy: 0.1283\n",
            "Epoch 29/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9132 - accuracy: 0.1977 - val_loss: 1.9802 - val_accuracy: 0.1224\n",
            "Epoch 30/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.9130 - accuracy: 0.1971 - val_loss: 1.9812 - val_accuracy: 0.1239\n",
            "Epoch 31/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.9124 - accuracy: 0.1984 - val_loss: 1.9828 - val_accuracy: 0.1254\n",
            "Epoch 32/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9119 - accuracy: 0.1991 - val_loss: 1.9838 - val_accuracy: 0.1370\n",
            "Epoch 33/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9109 - accuracy: 0.2008 - val_loss: 1.9840 - val_accuracy: 0.1297\n",
            "Epoch 34/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9100 - accuracy: 0.2008 - val_loss: 1.9837 - val_accuracy: 0.1290\n",
            "Epoch 35/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9088 - accuracy: 0.2019 - val_loss: 1.9869 - val_accuracy: 0.1268\n",
            "Epoch 36/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9096 - accuracy: 0.2061 - val_loss: 1.9847 - val_accuracy: 0.1399\n",
            "Epoch 37/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9086 - accuracy: 0.1988 - val_loss: 1.9835 - val_accuracy: 0.1261\n",
            "Epoch 38/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9088 - accuracy: 0.2057 - val_loss: 1.9862 - val_accuracy: 0.1290\n",
            "Epoch 39/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9081 - accuracy: 0.2059 - val_loss: 1.9836 - val_accuracy: 0.1356\n",
            "Epoch 40/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9066 - accuracy: 0.2035 - val_loss: 1.9857 - val_accuracy: 0.1327\n",
            "Epoch 41/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9068 - accuracy: 0.2093 - val_loss: 1.9886 - val_accuracy: 0.1327\n",
            "Epoch 42/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9057 - accuracy: 0.2062 - val_loss: 1.9877 - val_accuracy: 0.1268\n",
            "Epoch 43/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9053 - accuracy: 0.2075 - val_loss: 1.9902 - val_accuracy: 0.1392\n",
            "Epoch 44/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9049 - accuracy: 0.2035 - val_loss: 1.9888 - val_accuracy: 0.1261\n",
            "Epoch 45/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9045 - accuracy: 0.2097 - val_loss: 1.9896 - val_accuracy: 0.1283\n",
            "Epoch 46/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9036 - accuracy: 0.2077 - val_loss: 1.9887 - val_accuracy: 0.1385\n",
            "Epoch 47/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9032 - accuracy: 0.2090 - val_loss: 1.9914 - val_accuracy: 0.1363\n",
            "Epoch 48/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9020 - accuracy: 0.2099 - val_loss: 1.9899 - val_accuracy: 0.1363\n",
            "Epoch 49/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9024 - accuracy: 0.2057 - val_loss: 1.9906 - val_accuracy: 0.1378\n",
            "Epoch 50/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9014 - accuracy: 0.2164 - val_loss: 1.9935 - val_accuracy: 0.1290\n",
            "Epoch 51/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9016 - accuracy: 0.2102 - val_loss: 1.9903 - val_accuracy: 0.1385\n",
            "Epoch 52/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9009 - accuracy: 0.2132 - val_loss: 1.9940 - val_accuracy: 0.1283\n",
            "Epoch 53/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9004 - accuracy: 0.2113 - val_loss: 1.9947 - val_accuracy: 0.1399\n",
            "Epoch 54/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8998 - accuracy: 0.2185 - val_loss: 1.9940 - val_accuracy: 0.1392\n",
            "Epoch 55/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.9002 - accuracy: 0.2126 - val_loss: 1.9929 - val_accuracy: 0.1297\n",
            "Epoch 56/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8981 - accuracy: 0.2148 - val_loss: 1.9935 - val_accuracy: 0.1319\n",
            "Epoch 57/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8987 - accuracy: 0.2112 - val_loss: 1.9918 - val_accuracy: 0.1429\n",
            "Epoch 58/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8977 - accuracy: 0.2112 - val_loss: 1.9949 - val_accuracy: 0.1363\n",
            "Epoch 59/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8986 - accuracy: 0.2164 - val_loss: 1.9941 - val_accuracy: 0.1327\n",
            "Epoch 60/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8960 - accuracy: 0.2139 - val_loss: 1.9964 - val_accuracy: 0.1203\n",
            "Epoch 61/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8972 - accuracy: 0.2119 - val_loss: 1.9962 - val_accuracy: 0.1297\n",
            "Epoch 62/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8954 - accuracy: 0.2161 - val_loss: 1.9966 - val_accuracy: 0.1356\n",
            "Epoch 63/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8952 - accuracy: 0.2132 - val_loss: 1.9985 - val_accuracy: 0.1370\n",
            "Epoch 64/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8954 - accuracy: 0.2208 - val_loss: 1.9966 - val_accuracy: 0.1363\n",
            "Epoch 65/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8943 - accuracy: 0.2154 - val_loss: 1.9966 - val_accuracy: 0.1378\n",
            "Epoch 66/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8938 - accuracy: 0.2185 - val_loss: 1.9972 - val_accuracy: 0.1334\n",
            "Epoch 67/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8929 - accuracy: 0.2219 - val_loss: 1.9963 - val_accuracy: 0.1392\n",
            "Epoch 68/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8927 - accuracy: 0.2133 - val_loss: 1.9972 - val_accuracy: 0.1341\n",
            "Epoch 69/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8929 - accuracy: 0.2175 - val_loss: 1.9991 - val_accuracy: 0.1465\n",
            "Epoch 70/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8924 - accuracy: 0.2163 - val_loss: 1.9992 - val_accuracy: 0.1399\n",
            "Epoch 71/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8913 - accuracy: 0.2241 - val_loss: 1.9995 - val_accuracy: 0.1297\n",
            "Epoch 72/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8906 - accuracy: 0.2141 - val_loss: 2.0020 - val_accuracy: 0.1370\n",
            "Epoch 73/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8907 - accuracy: 0.2152 - val_loss: 1.9994 - val_accuracy: 0.1392\n",
            "Epoch 74/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8899 - accuracy: 0.2141 - val_loss: 2.0028 - val_accuracy: 0.1290\n",
            "Epoch 75/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8905 - accuracy: 0.2234 - val_loss: 1.9992 - val_accuracy: 0.1319\n",
            "Epoch 76/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8899 - accuracy: 0.2261 - val_loss: 2.0011 - val_accuracy: 0.1297\n",
            "Epoch 77/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8893 - accuracy: 0.2237 - val_loss: 2.0003 - val_accuracy: 0.1341\n",
            "Epoch 78/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8876 - accuracy: 0.2261 - val_loss: 2.0038 - val_accuracy: 0.1385\n",
            "Epoch 79/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8875 - accuracy: 0.2208 - val_loss: 2.0018 - val_accuracy: 0.1297\n",
            "Epoch 80/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8885 - accuracy: 0.2247 - val_loss: 2.0067 - val_accuracy: 0.1399\n",
            "Epoch 81/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8868 - accuracy: 0.2263 - val_loss: 2.0066 - val_accuracy: 0.1334\n",
            "Epoch 82/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8863 - accuracy: 0.2254 - val_loss: 2.0058 - val_accuracy: 0.1305\n",
            "Epoch 83/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8868 - accuracy: 0.2225 - val_loss: 2.0058 - val_accuracy: 0.1327\n",
            "Epoch 84/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8862 - accuracy: 0.2265 - val_loss: 2.0033 - val_accuracy: 0.1363\n",
            "Epoch 85/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8851 - accuracy: 0.2261 - val_loss: 2.0056 - val_accuracy: 0.1305\n",
            "Epoch 86/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8843 - accuracy: 0.2318 - val_loss: 2.0072 - val_accuracy: 0.1276\n",
            "Epoch 87/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8843 - accuracy: 0.2274 - val_loss: 2.0087 - val_accuracy: 0.1334\n",
            "Epoch 88/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8847 - accuracy: 0.2221 - val_loss: 2.0062 - val_accuracy: 0.1261\n",
            "Epoch 89/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8837 - accuracy: 0.2230 - val_loss: 2.0047 - val_accuracy: 0.1399\n",
            "Epoch 90/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8817 - accuracy: 0.2345 - val_loss: 2.0097 - val_accuracy: 0.1356\n",
            "Epoch 91/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8826 - accuracy: 0.2278 - val_loss: 2.0085 - val_accuracy: 0.1421\n",
            "Epoch 92/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8824 - accuracy: 0.2234 - val_loss: 2.0071 - val_accuracy: 0.1254\n",
            "Epoch 93/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8819 - accuracy: 0.2299 - val_loss: 2.0082 - val_accuracy: 0.1370\n",
            "Epoch 94/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8810 - accuracy: 0.2236 - val_loss: 2.0079 - val_accuracy: 0.1334\n",
            "Epoch 95/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8815 - accuracy: 0.2309 - val_loss: 2.0105 - val_accuracy: 0.1254\n",
            "Epoch 96/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8815 - accuracy: 0.2265 - val_loss: 2.0098 - val_accuracy: 0.1392\n",
            "Epoch 97/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8805 - accuracy: 0.2265 - val_loss: 2.0128 - val_accuracy: 0.1254\n",
            "Epoch 98/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8794 - accuracy: 0.2285 - val_loss: 2.0133 - val_accuracy: 0.1348\n",
            "Epoch 99/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8800 - accuracy: 0.2287 - val_loss: 2.0100 - val_accuracy: 0.1319\n",
            "Epoch 100/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8793 - accuracy: 0.2330 - val_loss: 2.0121 - val_accuracy: 0.1312\n",
            "Epoch 101/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8791 - accuracy: 0.2290 - val_loss: 2.0113 - val_accuracy: 0.1370\n",
            "Epoch 102/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8792 - accuracy: 0.2288 - val_loss: 2.0109 - val_accuracy: 0.1276\n",
            "Epoch 103/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8778 - accuracy: 0.2316 - val_loss: 2.0157 - val_accuracy: 0.1297\n",
            "Epoch 104/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8781 - accuracy: 0.2329 - val_loss: 2.0136 - val_accuracy: 0.1290\n",
            "Epoch 105/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8779 - accuracy: 0.2310 - val_loss: 2.0117 - val_accuracy: 0.1319\n",
            "Epoch 106/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8773 - accuracy: 0.2257 - val_loss: 2.0141 - val_accuracy: 0.1268\n",
            "Epoch 107/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8771 - accuracy: 0.2310 - val_loss: 2.0111 - val_accuracy: 0.1443\n",
            "Epoch 108/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8773 - accuracy: 0.2298 - val_loss: 2.0128 - val_accuracy: 0.1341\n",
            "Epoch 109/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8761 - accuracy: 0.2287 - val_loss: 2.0181 - val_accuracy: 0.1407\n",
            "Epoch 110/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8759 - accuracy: 0.2327 - val_loss: 2.0185 - val_accuracy: 0.1297\n",
            "Epoch 111/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8745 - accuracy: 0.2329 - val_loss: 2.0144 - val_accuracy: 0.1319\n",
            "Epoch 112/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8755 - accuracy: 0.2268 - val_loss: 2.0151 - val_accuracy: 0.1348\n",
            "Epoch 113/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8754 - accuracy: 0.2292 - val_loss: 2.0169 - val_accuracy: 0.1217\n",
            "Epoch 114/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8745 - accuracy: 0.2303 - val_loss: 2.0159 - val_accuracy: 0.1254\n",
            "Epoch 115/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8738 - accuracy: 0.2283 - val_loss: 2.0172 - val_accuracy: 0.1327\n",
            "Epoch 116/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8744 - accuracy: 0.2349 - val_loss: 2.0205 - val_accuracy: 0.1297\n",
            "Epoch 117/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8730 - accuracy: 0.2319 - val_loss: 2.0204 - val_accuracy: 0.1341\n",
            "Epoch 118/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8728 - accuracy: 0.2299 - val_loss: 2.0213 - val_accuracy: 0.1246\n",
            "Epoch 119/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8740 - accuracy: 0.2367 - val_loss: 2.0175 - val_accuracy: 0.1356\n",
            "Epoch 120/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8730 - accuracy: 0.2301 - val_loss: 2.0174 - val_accuracy: 0.1254\n",
            "Epoch 121/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8718 - accuracy: 0.2312 - val_loss: 2.0172 - val_accuracy: 0.1261\n",
            "Epoch 122/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8725 - accuracy: 0.2321 - val_loss: 2.0186 - val_accuracy: 0.1203\n",
            "Epoch 123/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8722 - accuracy: 0.2292 - val_loss: 2.0183 - val_accuracy: 0.1297\n",
            "Epoch 124/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8707 - accuracy: 0.2327 - val_loss: 2.0194 - val_accuracy: 0.1399\n",
            "Epoch 125/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8711 - accuracy: 0.2378 - val_loss: 2.0198 - val_accuracy: 0.1254\n",
            "Epoch 126/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8694 - accuracy: 0.2349 - val_loss: 2.0224 - val_accuracy: 0.1414\n",
            "Epoch 127/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8711 - accuracy: 0.2349 - val_loss: 2.0196 - val_accuracy: 0.1224\n",
            "Epoch 128/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8697 - accuracy: 0.2383 - val_loss: 2.0214 - val_accuracy: 0.1276\n",
            "Epoch 129/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8687 - accuracy: 0.2440 - val_loss: 2.0214 - val_accuracy: 0.1232\n",
            "Epoch 130/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8696 - accuracy: 0.2345 - val_loss: 2.0181 - val_accuracy: 0.1254\n",
            "Epoch 131/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8680 - accuracy: 0.2365 - val_loss: 2.0250 - val_accuracy: 0.1290\n",
            "Epoch 132/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8681 - accuracy: 0.2409 - val_loss: 2.0232 - val_accuracy: 0.1188\n",
            "Epoch 133/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8691 - accuracy: 0.2374 - val_loss: 2.0213 - val_accuracy: 0.1283\n",
            "Epoch 134/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8671 - accuracy: 0.2385 - val_loss: 2.0261 - val_accuracy: 0.1385\n",
            "Epoch 135/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8670 - accuracy: 0.2387 - val_loss: 2.0225 - val_accuracy: 0.1305\n",
            "Epoch 136/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8673 - accuracy: 0.2336 - val_loss: 2.0225 - val_accuracy: 0.1246\n",
            "Epoch 137/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8681 - accuracy: 0.2387 - val_loss: 2.0251 - val_accuracy: 0.1203\n",
            "Epoch 138/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8662 - accuracy: 0.2396 - val_loss: 2.0273 - val_accuracy: 0.1356\n",
            "Epoch 139/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8661 - accuracy: 0.2398 - val_loss: 2.0242 - val_accuracy: 0.1297\n",
            "Epoch 140/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8658 - accuracy: 0.2440 - val_loss: 2.0257 - val_accuracy: 0.1195\n",
            "Epoch 141/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8650 - accuracy: 0.2354 - val_loss: 2.0266 - val_accuracy: 0.1246\n",
            "Epoch 142/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8648 - accuracy: 0.2405 - val_loss: 2.0299 - val_accuracy: 0.1407\n",
            "Epoch 143/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8680 - accuracy: 0.2369 - val_loss: 2.0263 - val_accuracy: 0.1305\n",
            "Epoch 144/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8655 - accuracy: 0.2350 - val_loss: 2.0231 - val_accuracy: 0.1181\n",
            "Epoch 145/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8647 - accuracy: 0.2369 - val_loss: 2.0277 - val_accuracy: 0.1232\n",
            "Epoch 146/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8644 - accuracy: 0.2365 - val_loss: 2.0294 - val_accuracy: 0.1334\n",
            "Epoch 147/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8647 - accuracy: 0.2371 - val_loss: 2.0298 - val_accuracy: 0.1224\n",
            "Epoch 148/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8644 - accuracy: 0.2447 - val_loss: 2.0314 - val_accuracy: 0.1210\n",
            "Epoch 149/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8634 - accuracy: 0.2433 - val_loss: 2.0316 - val_accuracy: 0.1297\n",
            "Epoch 150/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8636 - accuracy: 0.2352 - val_loss: 2.0289 - val_accuracy: 0.1290\n",
            "Epoch 151/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8631 - accuracy: 0.2420 - val_loss: 2.0299 - val_accuracy: 0.1239\n",
            "Epoch 152/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8637 - accuracy: 0.2352 - val_loss: 2.0288 - val_accuracy: 0.1312\n",
            "Epoch 153/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8627 - accuracy: 0.2425 - val_loss: 2.0284 - val_accuracy: 0.1312\n",
            "Epoch 154/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8623 - accuracy: 0.2433 - val_loss: 2.0306 - val_accuracy: 0.1181\n",
            "Epoch 155/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8626 - accuracy: 0.2411 - val_loss: 2.0302 - val_accuracy: 0.1268\n",
            "Epoch 156/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8619 - accuracy: 0.2414 - val_loss: 2.0340 - val_accuracy: 0.1363\n",
            "Epoch 157/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8609 - accuracy: 0.2367 - val_loss: 2.0319 - val_accuracy: 0.1188\n",
            "Epoch 158/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8622 - accuracy: 0.2400 - val_loss: 2.0328 - val_accuracy: 0.1166\n",
            "Epoch 159/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8610 - accuracy: 0.2360 - val_loss: 2.0336 - val_accuracy: 0.1341\n",
            "Epoch 160/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8610 - accuracy: 0.2436 - val_loss: 2.0315 - val_accuracy: 0.1246\n",
            "Epoch 161/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8620 - accuracy: 0.2411 - val_loss: 2.0314 - val_accuracy: 0.1348\n",
            "Epoch 162/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8600 - accuracy: 0.2438 - val_loss: 2.0339 - val_accuracy: 0.1312\n",
            "Epoch 163/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8598 - accuracy: 0.2416 - val_loss: 2.0325 - val_accuracy: 0.1217\n",
            "Epoch 164/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8613 - accuracy: 0.2442 - val_loss: 2.0340 - val_accuracy: 0.1254\n",
            "Epoch 165/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8599 - accuracy: 0.2431 - val_loss: 2.0319 - val_accuracy: 0.1268\n",
            "Epoch 166/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8605 - accuracy: 0.2405 - val_loss: 2.0331 - val_accuracy: 0.1385\n",
            "Epoch 167/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8570 - accuracy: 0.2394 - val_loss: 2.0424 - val_accuracy: 0.1348\n",
            "Epoch 168/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8611 - accuracy: 0.2380 - val_loss: 2.0381 - val_accuracy: 0.1210\n",
            "Epoch 169/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8600 - accuracy: 0.2409 - val_loss: 2.0320 - val_accuracy: 0.1356\n",
            "Epoch 170/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8590 - accuracy: 0.2433 - val_loss: 2.0358 - val_accuracy: 0.1224\n",
            "Epoch 171/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8587 - accuracy: 0.2429 - val_loss: 2.0396 - val_accuracy: 0.1173\n",
            "Epoch 172/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8586 - accuracy: 0.2420 - val_loss: 2.0358 - val_accuracy: 0.1246\n",
            "Epoch 173/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8580 - accuracy: 0.2405 - val_loss: 2.0360 - val_accuracy: 0.1261\n",
            "Epoch 174/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8588 - accuracy: 0.2454 - val_loss: 2.0372 - val_accuracy: 0.1254\n",
            "Epoch 175/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8577 - accuracy: 0.2449 - val_loss: 2.0378 - val_accuracy: 0.1276\n",
            "Epoch 176/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8577 - accuracy: 0.2443 - val_loss: 2.0393 - val_accuracy: 0.1276\n",
            "Epoch 177/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8563 - accuracy: 0.2473 - val_loss: 2.0381 - val_accuracy: 0.1232\n",
            "Epoch 178/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8560 - accuracy: 0.2451 - val_loss: 2.0362 - val_accuracy: 0.1312\n",
            "Epoch 179/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8571 - accuracy: 0.2392 - val_loss: 2.0408 - val_accuracy: 0.1246\n",
            "Epoch 180/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8571 - accuracy: 0.2400 - val_loss: 2.0394 - val_accuracy: 0.1378\n",
            "Epoch 181/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8566 - accuracy: 0.2482 - val_loss: 2.0381 - val_accuracy: 0.1246\n",
            "Epoch 182/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8567 - accuracy: 0.2462 - val_loss: 2.0382 - val_accuracy: 0.1217\n",
            "Epoch 183/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8570 - accuracy: 0.2423 - val_loss: 2.0407 - val_accuracy: 0.1276\n",
            "Epoch 184/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8573 - accuracy: 0.2429 - val_loss: 2.0377 - val_accuracy: 0.1246\n",
            "Epoch 185/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8556 - accuracy: 0.2385 - val_loss: 2.0392 - val_accuracy: 0.1181\n",
            "Epoch 186/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8551 - accuracy: 0.2449 - val_loss: 2.0395 - val_accuracy: 0.1305\n",
            "Epoch 187/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8568 - accuracy: 0.2436 - val_loss: 2.0424 - val_accuracy: 0.1305\n",
            "Epoch 188/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8545 - accuracy: 0.2420 - val_loss: 2.0450 - val_accuracy: 0.1341\n",
            "Epoch 189/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8552 - accuracy: 0.2467 - val_loss: 2.0452 - val_accuracy: 0.1232\n",
            "Epoch 190/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8548 - accuracy: 0.2529 - val_loss: 2.0461 - val_accuracy: 0.1239\n",
            "Epoch 191/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8561 - accuracy: 0.2427 - val_loss: 2.0423 - val_accuracy: 0.1327\n",
            "Epoch 192/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8549 - accuracy: 0.2474 - val_loss: 2.0428 - val_accuracy: 0.1239\n",
            "Epoch 193/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8545 - accuracy: 0.2467 - val_loss: 2.0427 - val_accuracy: 0.1246\n",
            "Epoch 194/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8542 - accuracy: 0.2427 - val_loss: 2.0424 - val_accuracy: 0.1276\n",
            "Epoch 195/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8539 - accuracy: 0.2453 - val_loss: 2.0430 - val_accuracy: 0.1297\n",
            "Epoch 196/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8547 - accuracy: 0.2476 - val_loss: 2.0525 - val_accuracy: 0.1276\n",
            "Epoch 197/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8528 - accuracy: 0.2480 - val_loss: 2.0479 - val_accuracy: 0.1290\n",
            "Epoch 198/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8536 - accuracy: 0.2438 - val_loss: 2.0420 - val_accuracy: 0.1181\n",
            "Epoch 199/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8548 - accuracy: 0.2469 - val_loss: 2.0444 - val_accuracy: 0.1254\n",
            "Epoch 200/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8544 - accuracy: 0.2433 - val_loss: 2.0434 - val_accuracy: 0.1173\n",
            "Epoch 201/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8525 - accuracy: 0.2478 - val_loss: 2.0456 - val_accuracy: 0.1305\n",
            "Epoch 202/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8550 - accuracy: 0.2451 - val_loss: 2.0445 - val_accuracy: 0.1327\n",
            "Epoch 203/500\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.8530 - accuracy: 0.2436 - val_loss: 2.0472 - val_accuracy: 0.1261\n",
            "Epoch 204/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8531 - accuracy: 0.2496 - val_loss: 2.0442 - val_accuracy: 0.1246\n",
            "Epoch 205/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8532 - accuracy: 0.2478 - val_loss: 2.0439 - val_accuracy: 0.1239\n",
            "Epoch 206/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8527 - accuracy: 0.2493 - val_loss: 2.0502 - val_accuracy: 0.1232\n",
            "Epoch 207/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8526 - accuracy: 0.2478 - val_loss: 2.0466 - val_accuracy: 0.1276\n",
            "Epoch 208/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8516 - accuracy: 0.2476 - val_loss: 2.0534 - val_accuracy: 0.1319\n",
            "Epoch 209/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8519 - accuracy: 0.2423 - val_loss: 2.0462 - val_accuracy: 0.1305\n",
            "Epoch 210/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8521 - accuracy: 0.2515 - val_loss: 2.0468 - val_accuracy: 0.1283\n",
            "Epoch 211/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8512 - accuracy: 0.2527 - val_loss: 2.0466 - val_accuracy: 0.1224\n",
            "Epoch 212/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8515 - accuracy: 0.2480 - val_loss: 2.0486 - val_accuracy: 0.1224\n",
            "Epoch 213/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8513 - accuracy: 0.2520 - val_loss: 2.0488 - val_accuracy: 0.1268\n",
            "Epoch 214/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8505 - accuracy: 0.2555 - val_loss: 2.0478 - val_accuracy: 0.1261\n",
            "Epoch 215/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8507 - accuracy: 0.2484 - val_loss: 2.0487 - val_accuracy: 0.1195\n",
            "Epoch 216/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8498 - accuracy: 0.2504 - val_loss: 2.0536 - val_accuracy: 0.1312\n",
            "Epoch 217/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8494 - accuracy: 0.2535 - val_loss: 2.0568 - val_accuracy: 0.1297\n",
            "Epoch 218/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8504 - accuracy: 0.2471 - val_loss: 2.0507 - val_accuracy: 0.1232\n",
            "Epoch 219/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8514 - accuracy: 0.2451 - val_loss: 2.0514 - val_accuracy: 0.1283\n",
            "Epoch 220/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8498 - accuracy: 0.2493 - val_loss: 2.0504 - val_accuracy: 0.1188\n",
            "Epoch 221/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8486 - accuracy: 0.2504 - val_loss: 2.0551 - val_accuracy: 0.1210\n",
            "Epoch 222/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8506 - accuracy: 0.2505 - val_loss: 2.0515 - val_accuracy: 0.1327\n",
            "Epoch 223/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8491 - accuracy: 0.2445 - val_loss: 2.0519 - val_accuracy: 0.1283\n",
            "Epoch 224/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8503 - accuracy: 0.2469 - val_loss: 2.0505 - val_accuracy: 0.1290\n",
            "Epoch 225/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8498 - accuracy: 0.2467 - val_loss: 2.0564 - val_accuracy: 0.1232\n",
            "Epoch 226/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8492 - accuracy: 0.2489 - val_loss: 2.0528 - val_accuracy: 0.1290\n",
            "Epoch 227/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8498 - accuracy: 0.2478 - val_loss: 2.0533 - val_accuracy: 0.1217\n",
            "Epoch 228/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8493 - accuracy: 0.2471 - val_loss: 2.0510 - val_accuracy: 0.1239\n",
            "Epoch 229/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8498 - accuracy: 0.2422 - val_loss: 2.0522 - val_accuracy: 0.1327\n",
            "Epoch 230/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8471 - accuracy: 0.2538 - val_loss: 2.0589 - val_accuracy: 0.1297\n",
            "Epoch 231/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8495 - accuracy: 0.2462 - val_loss: 2.0546 - val_accuracy: 0.1276\n",
            "Epoch 232/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8491 - accuracy: 0.2526 - val_loss: 2.0512 - val_accuracy: 0.1246\n",
            "Epoch 233/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8476 - accuracy: 0.2536 - val_loss: 2.0556 - val_accuracy: 0.1239\n",
            "Epoch 234/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8491 - accuracy: 0.2487 - val_loss: 2.0529 - val_accuracy: 0.1283\n",
            "Epoch 235/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8484 - accuracy: 0.2555 - val_loss: 2.0556 - val_accuracy: 0.1334\n",
            "Epoch 236/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8489 - accuracy: 0.2480 - val_loss: 2.0521 - val_accuracy: 0.1254\n",
            "Epoch 237/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8488 - accuracy: 0.2533 - val_loss: 2.0580 - val_accuracy: 0.1246\n",
            "Epoch 238/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8478 - accuracy: 0.2526 - val_loss: 2.0592 - val_accuracy: 0.1276\n",
            "Epoch 239/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8486 - accuracy: 0.2507 - val_loss: 2.0558 - val_accuracy: 0.1276\n",
            "Epoch 240/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8465 - accuracy: 0.2516 - val_loss: 2.0569 - val_accuracy: 0.1261\n",
            "Epoch 241/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8476 - accuracy: 0.2440 - val_loss: 2.0583 - val_accuracy: 0.1268\n",
            "Epoch 242/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8475 - accuracy: 0.2522 - val_loss: 2.0597 - val_accuracy: 0.1246\n",
            "Epoch 243/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8463 - accuracy: 0.2538 - val_loss: 2.0561 - val_accuracy: 0.1261\n",
            "Epoch 244/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8464 - accuracy: 0.2542 - val_loss: 2.0593 - val_accuracy: 0.1319\n",
            "Epoch 245/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8457 - accuracy: 0.2582 - val_loss: 2.0616 - val_accuracy: 0.1224\n",
            "Epoch 246/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8457 - accuracy: 0.2520 - val_loss: 2.0573 - val_accuracy: 0.1290\n",
            "Epoch 247/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8457 - accuracy: 0.2504 - val_loss: 2.0572 - val_accuracy: 0.1254\n",
            "Epoch 248/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8456 - accuracy: 0.2546 - val_loss: 2.0583 - val_accuracy: 0.1312\n",
            "Epoch 249/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8459 - accuracy: 0.2516 - val_loss: 2.0571 - val_accuracy: 0.1283\n",
            "Epoch 250/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8470 - accuracy: 0.2575 - val_loss: 2.0567 - val_accuracy: 0.1188\n",
            "Epoch 251/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8459 - accuracy: 0.2493 - val_loss: 2.0617 - val_accuracy: 0.1276\n",
            "Epoch 252/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8448 - accuracy: 0.2571 - val_loss: 2.0608 - val_accuracy: 0.1261\n",
            "Epoch 253/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8460 - accuracy: 0.2489 - val_loss: 2.0644 - val_accuracy: 0.1203\n",
            "Epoch 254/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8469 - accuracy: 0.2515 - val_loss: 2.0601 - val_accuracy: 0.1268\n",
            "Epoch 255/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8458 - accuracy: 0.2462 - val_loss: 2.0576 - val_accuracy: 0.1319\n",
            "Epoch 256/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8454 - accuracy: 0.2533 - val_loss: 2.0575 - val_accuracy: 0.1276\n",
            "Epoch 257/500\n",
            "172/172 [==============================] - 1s 5ms/step - loss: 1.8452 - accuracy: 0.2515 - val_loss: 2.0582 - val_accuracy: 0.1188\n",
            "Epoch 258/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8457 - accuracy: 0.2509 - val_loss: 2.0613 - val_accuracy: 0.1385\n",
            "Epoch 259/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8449 - accuracy: 0.2513 - val_loss: 2.0609 - val_accuracy: 0.1239\n",
            "Epoch 260/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8448 - accuracy: 0.2560 - val_loss: 2.0611 - val_accuracy: 0.1327\n",
            "Epoch 261/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8461 - accuracy: 0.2500 - val_loss: 2.0583 - val_accuracy: 0.1246\n",
            "Epoch 262/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8446 - accuracy: 0.2606 - val_loss: 2.0615 - val_accuracy: 0.1370\n",
            "Epoch 263/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8438 - accuracy: 0.2513 - val_loss: 2.0622 - val_accuracy: 0.1290\n",
            "Epoch 264/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8451 - accuracy: 0.2531 - val_loss: 2.0623 - val_accuracy: 0.1224\n",
            "Epoch 265/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8436 - accuracy: 0.2560 - val_loss: 2.0674 - val_accuracy: 0.1276\n",
            "Epoch 266/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8447 - accuracy: 0.2571 - val_loss: 2.0622 - val_accuracy: 0.1239\n",
            "Epoch 267/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8428 - accuracy: 0.2591 - val_loss: 2.0665 - val_accuracy: 0.1195\n",
            "Epoch 268/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8443 - accuracy: 0.2562 - val_loss: 2.0655 - val_accuracy: 0.1254\n",
            "Epoch 269/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8431 - accuracy: 0.2542 - val_loss: 2.0653 - val_accuracy: 0.1268\n",
            "Epoch 270/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8450 - accuracy: 0.2504 - val_loss: 2.0602 - val_accuracy: 0.1254\n",
            "Epoch 271/500\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.8442 - accuracy: 0.2573 - val_loss: 2.0656 - val_accuracy: 0.1305\n",
            "Epoch 272/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8441 - accuracy: 0.2535 - val_loss: 2.0607 - val_accuracy: 0.1254\n",
            "Epoch 273/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8430 - accuracy: 0.2578 - val_loss: 2.0654 - val_accuracy: 0.1283\n",
            "Epoch 274/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.2553 - val_loss: 2.0657 - val_accuracy: 0.1297\n",
            "Epoch 275/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8437 - accuracy: 0.2531 - val_loss: 2.0652 - val_accuracy: 0.1327\n",
            "Epoch 276/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8435 - accuracy: 0.2518 - val_loss: 2.0668 - val_accuracy: 0.1305\n",
            "Epoch 277/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8443 - accuracy: 0.2493 - val_loss: 2.0716 - val_accuracy: 0.1283\n",
            "Epoch 278/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8431 - accuracy: 0.2535 - val_loss: 2.0697 - val_accuracy: 0.1297\n",
            "Epoch 279/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8421 - accuracy: 0.2617 - val_loss: 2.0676 - val_accuracy: 0.1297\n",
            "Epoch 280/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8433 - accuracy: 0.2513 - val_loss: 2.0674 - val_accuracy: 0.1261\n",
            "Epoch 281/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8444 - accuracy: 0.2535 - val_loss: 2.0680 - val_accuracy: 0.1210\n",
            "Epoch 282/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.2650 - val_loss: 2.0702 - val_accuracy: 0.1305\n",
            "Epoch 283/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8433 - accuracy: 0.2538 - val_loss: 2.0690 - val_accuracy: 0.1254\n",
            "Epoch 284/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.2593 - val_loss: 2.0641 - val_accuracy: 0.1312\n",
            "Epoch 285/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.2531 - val_loss: 2.0704 - val_accuracy: 0.1327\n",
            "Epoch 286/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8413 - accuracy: 0.2580 - val_loss: 2.0697 - val_accuracy: 0.1283\n",
            "Epoch 287/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8438 - accuracy: 0.2575 - val_loss: 2.0673 - val_accuracy: 0.1181\n",
            "Epoch 288/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8413 - accuracy: 0.2575 - val_loss: 2.0708 - val_accuracy: 0.1268\n",
            "Epoch 289/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8420 - accuracy: 0.2551 - val_loss: 2.0712 - val_accuracy: 0.1341\n",
            "Epoch 290/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.2540 - val_loss: 2.0683 - val_accuracy: 0.1290\n",
            "Epoch 291/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8409 - accuracy: 0.2591 - val_loss: 2.0704 - val_accuracy: 0.1312\n",
            "Epoch 292/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8422 - accuracy: 0.2518 - val_loss: 2.0732 - val_accuracy: 0.1276\n",
            "Epoch 293/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8404 - accuracy: 0.2557 - val_loss: 2.0736 - val_accuracy: 0.1363\n",
            "Epoch 294/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.2578 - val_loss: 2.0730 - val_accuracy: 0.1385\n",
            "Epoch 295/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8419 - accuracy: 0.2547 - val_loss: 2.0686 - val_accuracy: 0.1254\n",
            "Epoch 296/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8399 - accuracy: 0.2527 - val_loss: 2.0702 - val_accuracy: 0.1327\n",
            "Epoch 297/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8417 - accuracy: 0.2573 - val_loss: 2.0704 - val_accuracy: 0.1305\n",
            "Epoch 298/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8431 - accuracy: 0.2555 - val_loss: 2.0697 - val_accuracy: 0.1268\n",
            "Epoch 299/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8408 - accuracy: 0.2533 - val_loss: 2.0693 - val_accuracy: 0.1297\n",
            "Epoch 300/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8419 - accuracy: 0.2507 - val_loss: 2.0723 - val_accuracy: 0.1246\n",
            "Epoch 301/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8409 - accuracy: 0.2557 - val_loss: 2.0713 - val_accuracy: 0.1290\n",
            "Epoch 302/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8399 - accuracy: 0.2606 - val_loss: 2.0723 - val_accuracy: 0.1290\n",
            "Epoch 303/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8413 - accuracy: 0.2536 - val_loss: 2.0762 - val_accuracy: 0.1224\n",
            "Epoch 304/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8419 - accuracy: 0.2504 - val_loss: 2.0765 - val_accuracy: 0.1210\n",
            "Epoch 305/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8403 - accuracy: 0.2538 - val_loss: 2.0756 - val_accuracy: 0.1305\n",
            "Epoch 306/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8411 - accuracy: 0.2560 - val_loss: 2.0714 - val_accuracy: 0.1297\n",
            "Epoch 307/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8415 - accuracy: 0.2511 - val_loss: 2.0750 - val_accuracy: 0.1283\n",
            "Epoch 308/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8402 - accuracy: 0.2589 - val_loss: 2.0756 - val_accuracy: 0.1348\n",
            "Epoch 309/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8390 - accuracy: 0.2558 - val_loss: 2.0778 - val_accuracy: 0.1305\n",
            "Epoch 310/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8395 - accuracy: 0.2589 - val_loss: 2.0749 - val_accuracy: 0.1217\n",
            "Epoch 311/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8388 - accuracy: 0.2573 - val_loss: 2.0743 - val_accuracy: 0.1319\n",
            "Epoch 312/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8415 - accuracy: 0.2538 - val_loss: 2.0726 - val_accuracy: 0.1261\n",
            "Epoch 313/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8405 - accuracy: 0.2535 - val_loss: 2.0779 - val_accuracy: 0.1246\n",
            "Epoch 314/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8409 - accuracy: 0.2502 - val_loss: 2.0794 - val_accuracy: 0.1312\n",
            "Epoch 315/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8409 - accuracy: 0.2608 - val_loss: 2.0762 - val_accuracy: 0.1254\n",
            "Epoch 316/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8399 - accuracy: 0.2557 - val_loss: 2.0718 - val_accuracy: 0.1290\n",
            "Epoch 317/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8398 - accuracy: 0.2557 - val_loss: 2.0763 - val_accuracy: 0.1297\n",
            "Epoch 318/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8383 - accuracy: 0.2591 - val_loss: 2.0773 - val_accuracy: 0.1312\n",
            "Epoch 319/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8396 - accuracy: 0.2558 - val_loss: 2.0798 - val_accuracy: 0.1246\n",
            "Epoch 320/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8395 - accuracy: 0.2555 - val_loss: 2.0812 - val_accuracy: 0.1414\n",
            "Epoch 321/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8407 - accuracy: 0.2586 - val_loss: 2.0759 - val_accuracy: 0.1261\n",
            "Epoch 322/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8394 - accuracy: 0.2491 - val_loss: 2.0730 - val_accuracy: 0.1188\n",
            "Epoch 323/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8395 - accuracy: 0.2602 - val_loss: 2.0811 - val_accuracy: 0.1283\n",
            "Epoch 324/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8389 - accuracy: 0.2589 - val_loss: 2.0764 - val_accuracy: 0.1261\n",
            "Epoch 325/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8382 - accuracy: 0.2593 - val_loss: 2.0805 - val_accuracy: 0.1224\n",
            "Epoch 326/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8395 - accuracy: 0.2582 - val_loss: 2.0809 - val_accuracy: 0.1276\n",
            "Epoch 327/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8386 - accuracy: 0.2584 - val_loss: 2.0803 - val_accuracy: 0.1334\n",
            "Epoch 328/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8389 - accuracy: 0.2577 - val_loss: 2.0773 - val_accuracy: 0.1363\n",
            "Epoch 329/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8392 - accuracy: 0.2575 - val_loss: 2.0826 - val_accuracy: 0.1348\n",
            "Epoch 330/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8387 - accuracy: 0.2609 - val_loss: 2.0730 - val_accuracy: 0.1370\n",
            "Epoch 331/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8388 - accuracy: 0.2562 - val_loss: 2.0807 - val_accuracy: 0.1232\n",
            "Epoch 332/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8396 - accuracy: 0.2582 - val_loss: 2.0762 - val_accuracy: 0.1239\n",
            "Epoch 333/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8388 - accuracy: 0.2613 - val_loss: 2.0771 - val_accuracy: 0.1210\n",
            "Epoch 334/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8378 - accuracy: 0.2569 - val_loss: 2.0778 - val_accuracy: 0.1246\n",
            "Epoch 335/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8374 - accuracy: 0.2598 - val_loss: 2.0803 - val_accuracy: 0.1297\n",
            "Epoch 336/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8390 - accuracy: 0.2560 - val_loss: 2.0814 - val_accuracy: 0.1283\n",
            "Epoch 337/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8389 - accuracy: 0.2536 - val_loss: 2.0864 - val_accuracy: 0.1341\n",
            "Epoch 338/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8382 - accuracy: 0.2542 - val_loss: 2.0818 - val_accuracy: 0.1290\n",
            "Epoch 339/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8377 - accuracy: 0.2560 - val_loss: 2.0837 - val_accuracy: 0.1217\n",
            "Epoch 340/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8383 - accuracy: 0.2520 - val_loss: 2.0799 - val_accuracy: 0.1305\n",
            "Epoch 341/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8383 - accuracy: 0.2593 - val_loss: 2.0800 - val_accuracy: 0.1268\n",
            "Epoch 342/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8383 - accuracy: 0.2538 - val_loss: 2.0839 - val_accuracy: 0.1297\n",
            "Epoch 343/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8381 - accuracy: 0.2604 - val_loss: 2.0834 - val_accuracy: 0.1283\n",
            "Epoch 344/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8395 - accuracy: 0.2489 - val_loss: 2.0804 - val_accuracy: 0.1276\n",
            "Epoch 345/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8388 - accuracy: 0.2557 - val_loss: 2.0847 - val_accuracy: 0.1312\n",
            "Epoch 346/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8386 - accuracy: 0.2555 - val_loss: 2.0848 - val_accuracy: 0.1276\n",
            "Epoch 347/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8369 - accuracy: 0.2624 - val_loss: 2.0869 - val_accuracy: 0.1290\n",
            "Epoch 348/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8376 - accuracy: 0.2651 - val_loss: 2.0864 - val_accuracy: 0.1305\n",
            "Epoch 349/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8395 - accuracy: 0.2558 - val_loss: 2.0820 - val_accuracy: 0.1261\n",
            "Epoch 350/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8382 - accuracy: 0.2573 - val_loss: 2.0815 - val_accuracy: 0.1173\n",
            "Epoch 351/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8373 - accuracy: 0.2593 - val_loss: 2.0823 - val_accuracy: 0.1319\n",
            "Epoch 352/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8364 - accuracy: 0.2613 - val_loss: 2.0822 - val_accuracy: 0.1297\n",
            "Epoch 353/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8373 - accuracy: 0.2564 - val_loss: 2.0864 - val_accuracy: 0.1261\n",
            "Epoch 354/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8370 - accuracy: 0.2540 - val_loss: 2.0847 - val_accuracy: 0.1283\n",
            "Epoch 355/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8380 - accuracy: 0.2626 - val_loss: 2.0818 - val_accuracy: 0.1261\n",
            "Epoch 356/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8382 - accuracy: 0.2527 - val_loss: 2.0772 - val_accuracy: 0.1276\n",
            "Epoch 357/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8367 - accuracy: 0.2622 - val_loss: 2.0833 - val_accuracy: 0.1254\n",
            "Epoch 358/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8388 - accuracy: 0.2611 - val_loss: 2.0854 - val_accuracy: 0.1283\n",
            "Epoch 359/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8396 - accuracy: 0.2535 - val_loss: 2.0806 - val_accuracy: 0.1283\n",
            "Epoch 360/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8380 - accuracy: 0.2578 - val_loss: 2.0814 - val_accuracy: 0.1261\n",
            "Epoch 361/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8370 - accuracy: 0.2564 - val_loss: 2.0852 - val_accuracy: 0.1319\n",
            "Epoch 362/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8368 - accuracy: 0.2566 - val_loss: 2.0857 - val_accuracy: 0.1327\n",
            "Epoch 363/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8377 - accuracy: 0.2613 - val_loss: 2.0799 - val_accuracy: 0.1195\n",
            "Epoch 364/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8363 - accuracy: 0.2595 - val_loss: 2.0879 - val_accuracy: 0.1370\n",
            "Epoch 365/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8376 - accuracy: 0.2558 - val_loss: 2.0854 - val_accuracy: 0.1297\n",
            "Epoch 366/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8371 - accuracy: 0.2558 - val_loss: 2.0845 - val_accuracy: 0.1297\n",
            "Epoch 367/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8371 - accuracy: 0.2546 - val_loss: 2.0869 - val_accuracy: 0.1305\n",
            "Epoch 368/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8383 - accuracy: 0.2538 - val_loss: 2.0852 - val_accuracy: 0.1290\n",
            "Epoch 369/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8373 - accuracy: 0.2560 - val_loss: 2.0831 - val_accuracy: 0.1268\n",
            "Epoch 370/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8376 - accuracy: 0.2591 - val_loss: 2.0843 - val_accuracy: 0.1319\n",
            "Epoch 371/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8369 - accuracy: 0.2564 - val_loss: 2.0897 - val_accuracy: 0.1297\n",
            "Epoch 372/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8375 - accuracy: 0.2549 - val_loss: 2.0819 - val_accuracy: 0.1363\n",
            "Epoch 373/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8377 - accuracy: 0.2564 - val_loss: 2.0826 - val_accuracy: 0.1239\n",
            "Epoch 374/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8365 - accuracy: 0.2555 - val_loss: 2.0859 - val_accuracy: 0.1254\n",
            "Epoch 375/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8383 - accuracy: 0.2564 - val_loss: 2.0848 - val_accuracy: 0.1276\n",
            "Epoch 376/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8376 - accuracy: 0.2584 - val_loss: 2.0841 - val_accuracy: 0.1239\n",
            "Epoch 377/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8362 - accuracy: 0.2558 - val_loss: 2.0869 - val_accuracy: 0.1246\n",
            "Epoch 378/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8352 - accuracy: 0.2602 - val_loss: 2.0849 - val_accuracy: 0.1283\n",
            "Epoch 379/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8361 - accuracy: 0.2549 - val_loss: 2.0863 - val_accuracy: 0.1283\n",
            "Epoch 380/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8365 - accuracy: 0.2613 - val_loss: 2.0839 - val_accuracy: 0.1290\n",
            "Epoch 381/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8354 - accuracy: 0.2588 - val_loss: 2.0876 - val_accuracy: 0.1297\n",
            "Epoch 382/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8379 - accuracy: 0.2628 - val_loss: 2.0842 - val_accuracy: 0.1327\n",
            "Epoch 383/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8361 - accuracy: 0.2520 - val_loss: 2.0903 - val_accuracy: 0.1305\n",
            "Epoch 384/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8368 - accuracy: 0.2566 - val_loss: 2.0868 - val_accuracy: 0.1290\n",
            "Epoch 385/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8369 - accuracy: 0.2589 - val_loss: 2.0880 - val_accuracy: 0.1297\n",
            "Epoch 386/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8359 - accuracy: 0.2555 - val_loss: 2.0899 - val_accuracy: 0.1246\n",
            "Epoch 387/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8361 - accuracy: 0.2613 - val_loss: 2.0930 - val_accuracy: 0.1312\n",
            "Epoch 388/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8381 - accuracy: 0.2516 - val_loss: 2.0873 - val_accuracy: 0.1283\n",
            "Epoch 389/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8359 - accuracy: 0.2536 - val_loss: 2.0856 - val_accuracy: 0.1217\n",
            "Epoch 390/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8358 - accuracy: 0.2613 - val_loss: 2.0933 - val_accuracy: 0.1297\n",
            "Epoch 391/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8369 - accuracy: 0.2586 - val_loss: 2.0886 - val_accuracy: 0.1283\n",
            "Epoch 392/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8378 - accuracy: 0.2580 - val_loss: 2.0886 - val_accuracy: 0.1268\n",
            "Epoch 393/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8350 - accuracy: 0.2580 - val_loss: 2.0893 - val_accuracy: 0.1283\n",
            "Epoch 394/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8343 - accuracy: 0.2575 - val_loss: 2.0935 - val_accuracy: 0.1224\n",
            "Epoch 395/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8377 - accuracy: 0.2586 - val_loss: 2.0886 - val_accuracy: 0.1268\n",
            "Epoch 396/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8361 - accuracy: 0.2653 - val_loss: 2.0908 - val_accuracy: 0.1246\n",
            "Epoch 397/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8356 - accuracy: 0.2513 - val_loss: 2.0873 - val_accuracy: 0.1283\n",
            "Epoch 398/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8377 - accuracy: 0.2609 - val_loss: 2.0881 - val_accuracy: 0.1348\n",
            "Epoch 399/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8362 - accuracy: 0.2588 - val_loss: 2.0877 - val_accuracy: 0.1297\n",
            "Epoch 400/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8358 - accuracy: 0.2597 - val_loss: 2.0888 - val_accuracy: 0.1290\n",
            "Epoch 401/500\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.8353 - accuracy: 0.2553 - val_loss: 2.0920 - val_accuracy: 0.1290\n",
            "Epoch 402/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8357 - accuracy: 0.2582 - val_loss: 2.0900 - val_accuracy: 0.1232\n",
            "Epoch 403/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8371 - accuracy: 0.2533 - val_loss: 2.0858 - val_accuracy: 0.1210\n",
            "Epoch 404/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8341 - accuracy: 0.2604 - val_loss: 2.0895 - val_accuracy: 0.1290\n",
            "Epoch 405/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8370 - accuracy: 0.2569 - val_loss: 2.0850 - val_accuracy: 0.1319\n",
            "Epoch 406/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8353 - accuracy: 0.2589 - val_loss: 2.0877 - val_accuracy: 0.1276\n",
            "Epoch 407/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8341 - accuracy: 0.2604 - val_loss: 2.0879 - val_accuracy: 0.1334\n",
            "Epoch 408/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8363 - accuracy: 0.2617 - val_loss: 2.0930 - val_accuracy: 0.1254\n",
            "Epoch 409/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8351 - accuracy: 0.2600 - val_loss: 2.0929 - val_accuracy: 0.1239\n",
            "Epoch 410/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8358 - accuracy: 0.2602 - val_loss: 2.0943 - val_accuracy: 0.1290\n",
            "Epoch 411/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8348 - accuracy: 0.2619 - val_loss: 2.0900 - val_accuracy: 0.1319\n",
            "Epoch 412/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8350 - accuracy: 0.2544 - val_loss: 2.0970 - val_accuracy: 0.1254\n",
            "Epoch 413/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8354 - accuracy: 0.2631 - val_loss: 2.0888 - val_accuracy: 0.1341\n",
            "Epoch 414/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8353 - accuracy: 0.2578 - val_loss: 2.0880 - val_accuracy: 0.1341\n",
            "Epoch 415/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8351 - accuracy: 0.2567 - val_loss: 2.0884 - val_accuracy: 0.1297\n",
            "Epoch 416/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8338 - accuracy: 0.2595 - val_loss: 2.0869 - val_accuracy: 0.1297\n",
            "Epoch 417/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8354 - accuracy: 0.2598 - val_loss: 2.0948 - val_accuracy: 0.1305\n",
            "Epoch 418/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8332 - accuracy: 0.2591 - val_loss: 2.0893 - val_accuracy: 0.1290\n",
            "Epoch 419/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8337 - accuracy: 0.2640 - val_loss: 2.0948 - val_accuracy: 0.1334\n",
            "Epoch 420/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8362 - accuracy: 0.2620 - val_loss: 2.0902 - val_accuracy: 0.1290\n",
            "Epoch 421/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8343 - accuracy: 0.2597 - val_loss: 2.0949 - val_accuracy: 0.1327\n",
            "Epoch 422/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8363 - accuracy: 0.2524 - val_loss: 2.0889 - val_accuracy: 0.1305\n",
            "Epoch 423/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8341 - accuracy: 0.2575 - val_loss: 2.0919 - val_accuracy: 0.1232\n",
            "Epoch 424/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8356 - accuracy: 0.2555 - val_loss: 2.0950 - val_accuracy: 0.1334\n",
            "Epoch 425/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8353 - accuracy: 0.2642 - val_loss: 2.0868 - val_accuracy: 0.1246\n",
            "Epoch 426/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8350 - accuracy: 0.2588 - val_loss: 2.0963 - val_accuracy: 0.1327\n",
            "Epoch 427/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8357 - accuracy: 0.2597 - val_loss: 2.0941 - val_accuracy: 0.1341\n",
            "Epoch 428/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8337 - accuracy: 0.2582 - val_loss: 2.0967 - val_accuracy: 0.1356\n",
            "Epoch 429/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8355 - accuracy: 0.2597 - val_loss: 2.0909 - val_accuracy: 0.1363\n",
            "Epoch 430/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8349 - accuracy: 0.2593 - val_loss: 2.0924 - val_accuracy: 0.1261\n",
            "Epoch 431/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8356 - accuracy: 0.2562 - val_loss: 2.0899 - val_accuracy: 0.1341\n",
            "Epoch 432/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8350 - accuracy: 0.2569 - val_loss: 2.0897 - val_accuracy: 0.1348\n",
            "Epoch 433/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8326 - accuracy: 0.2633 - val_loss: 2.0950 - val_accuracy: 0.1261\n",
            "Epoch 434/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8362 - accuracy: 0.2578 - val_loss: 2.0925 - val_accuracy: 0.1268\n",
            "Epoch 435/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8352 - accuracy: 0.2577 - val_loss: 2.0935 - val_accuracy: 0.1283\n",
            "Epoch 436/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8342 - accuracy: 0.2611 - val_loss: 2.0910 - val_accuracy: 0.1392\n",
            "Epoch 437/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8358 - accuracy: 0.2609 - val_loss: 2.0909 - val_accuracy: 0.1297\n",
            "Epoch 438/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8347 - accuracy: 0.2586 - val_loss: 2.0965 - val_accuracy: 0.1356\n",
            "Epoch 439/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8351 - accuracy: 0.2613 - val_loss: 2.0934 - val_accuracy: 0.1334\n",
            "Epoch 440/500\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 1.8337 - accuracy: 0.2593 - val_loss: 2.0938 - val_accuracy: 0.1297\n",
            "Epoch 441/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8341 - accuracy: 0.2615 - val_loss: 2.0958 - val_accuracy: 0.1276\n",
            "Epoch 442/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8327 - accuracy: 0.2628 - val_loss: 2.0951 - val_accuracy: 0.1283\n",
            "Epoch 443/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8347 - accuracy: 0.2549 - val_loss: 2.0924 - val_accuracy: 0.1319\n",
            "Epoch 444/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8336 - accuracy: 0.2586 - val_loss: 2.0915 - val_accuracy: 0.1254\n",
            "Epoch 445/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8335 - accuracy: 0.2659 - val_loss: 2.1016 - val_accuracy: 0.1327\n",
            "Epoch 446/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8334 - accuracy: 0.2602 - val_loss: 2.0912 - val_accuracy: 0.1327\n",
            "Epoch 447/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8343 - accuracy: 0.2522 - val_loss: 2.0934 - val_accuracy: 0.1232\n",
            "Epoch 448/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8361 - accuracy: 0.2551 - val_loss: 2.0911 - val_accuracy: 0.1348\n",
            "Epoch 449/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8336 - accuracy: 0.2608 - val_loss: 2.0945 - val_accuracy: 0.1385\n",
            "Epoch 450/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8349 - accuracy: 0.2549 - val_loss: 2.0936 - val_accuracy: 0.1327\n",
            "Epoch 451/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8330 - accuracy: 0.2600 - val_loss: 2.0930 - val_accuracy: 0.1370\n",
            "Epoch 452/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8328 - accuracy: 0.2547 - val_loss: 2.0931 - val_accuracy: 0.1261\n",
            "Epoch 453/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8344 - accuracy: 0.2564 - val_loss: 2.0952 - val_accuracy: 0.1305\n",
            "Epoch 454/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8336 - accuracy: 0.2640 - val_loss: 2.0974 - val_accuracy: 0.1356\n",
            "Epoch 455/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8334 - accuracy: 0.2551 - val_loss: 2.0931 - val_accuracy: 0.1378\n",
            "Epoch 456/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8332 - accuracy: 0.2591 - val_loss: 2.0983 - val_accuracy: 0.1290\n",
            "Epoch 457/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8333 - accuracy: 0.2606 - val_loss: 2.0967 - val_accuracy: 0.1363\n",
            "Epoch 458/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8333 - accuracy: 0.2626 - val_loss: 2.0966 - val_accuracy: 0.1268\n",
            "Epoch 459/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8341 - accuracy: 0.2602 - val_loss: 2.0946 - val_accuracy: 0.1348\n",
            "Epoch 460/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8341 - accuracy: 0.2546 - val_loss: 2.0963 - val_accuracy: 0.1297\n",
            "Epoch 461/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8330 - accuracy: 0.2582 - val_loss: 2.0963 - val_accuracy: 0.1392\n",
            "Epoch 462/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8345 - accuracy: 0.2598 - val_loss: 2.0908 - val_accuracy: 0.1297\n",
            "Epoch 463/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8338 - accuracy: 0.2584 - val_loss: 2.0963 - val_accuracy: 0.1239\n",
            "Epoch 464/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8331 - accuracy: 0.2611 - val_loss: 2.0954 - val_accuracy: 0.1370\n",
            "Epoch 465/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8326 - accuracy: 0.2602 - val_loss: 2.0952 - val_accuracy: 0.1356\n",
            "Epoch 466/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8332 - accuracy: 0.2606 - val_loss: 2.0959 - val_accuracy: 0.1334\n",
            "Epoch 467/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8335 - accuracy: 0.2648 - val_loss: 2.0959 - val_accuracy: 0.1254\n",
            "Epoch 468/500\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 1.8339 - accuracy: 0.2566 - val_loss: 2.1002 - val_accuracy: 0.1385\n",
            "Epoch 469/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8339 - accuracy: 0.2606 - val_loss: 2.0974 - val_accuracy: 0.1297\n",
            "Epoch 470/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8349 - accuracy: 0.2600 - val_loss: 2.1011 - val_accuracy: 0.1334\n",
            "Epoch 471/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8338 - accuracy: 0.2577 - val_loss: 2.0938 - val_accuracy: 0.1268\n",
            "Epoch 472/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8328 - accuracy: 0.2620 - val_loss: 2.0953 - val_accuracy: 0.1261\n",
            "Epoch 473/500\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 1.8339 - accuracy: 0.2553 - val_loss: 2.0910 - val_accuracy: 0.1363\n",
            "Epoch 474/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8336 - accuracy: 0.2549 - val_loss: 2.0959 - val_accuracy: 0.1392\n",
            "Epoch 475/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8347 - accuracy: 0.2571 - val_loss: 2.0974 - val_accuracy: 0.1276\n",
            "Epoch 476/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8336 - accuracy: 0.2584 - val_loss: 2.0939 - val_accuracy: 0.1290\n",
            "Epoch 477/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8328 - accuracy: 0.2619 - val_loss: 2.0942 - val_accuracy: 0.1276\n",
            "Epoch 478/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8337 - accuracy: 0.2558 - val_loss: 2.1009 - val_accuracy: 0.1356\n",
            "Epoch 479/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8340 - accuracy: 0.2588 - val_loss: 2.0952 - val_accuracy: 0.1297\n",
            "Epoch 480/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8314 - accuracy: 0.2591 - val_loss: 2.0992 - val_accuracy: 0.1319\n",
            "Epoch 481/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8331 - accuracy: 0.2588 - val_loss: 2.0951 - val_accuracy: 0.1312\n",
            "Epoch 482/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8339 - accuracy: 0.2586 - val_loss: 2.0993 - val_accuracy: 0.1283\n",
            "Epoch 483/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8321 - accuracy: 0.2628 - val_loss: 2.0969 - val_accuracy: 0.1363\n",
            "Epoch 484/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8327 - accuracy: 0.2584 - val_loss: 2.0952 - val_accuracy: 0.1261\n",
            "Epoch 485/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8317 - accuracy: 0.2617 - val_loss: 2.1028 - val_accuracy: 0.1283\n",
            "Epoch 486/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8327 - accuracy: 0.2631 - val_loss: 2.1026 - val_accuracy: 0.1392\n",
            "Epoch 487/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8323 - accuracy: 0.2588 - val_loss: 2.0948 - val_accuracy: 0.1305\n",
            "Epoch 488/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8339 - accuracy: 0.2622 - val_loss: 2.0977 - val_accuracy: 0.1341\n",
            "Epoch 489/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8327 - accuracy: 0.2624 - val_loss: 2.0969 - val_accuracy: 0.1290\n",
            "Epoch 490/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8323 - accuracy: 0.2617 - val_loss: 2.0972 - val_accuracy: 0.1312\n",
            "Epoch 491/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8337 - accuracy: 0.2577 - val_loss: 2.0968 - val_accuracy: 0.1341\n",
            "Epoch 492/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8343 - accuracy: 0.2575 - val_loss: 2.0951 - val_accuracy: 0.1334\n",
            "Epoch 493/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8323 - accuracy: 0.2584 - val_loss: 2.0981 - val_accuracy: 0.1356\n",
            "Epoch 494/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8332 - accuracy: 0.2593 - val_loss: 2.1008 - val_accuracy: 0.1341\n",
            "Epoch 495/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8336 - accuracy: 0.2608 - val_loss: 2.0966 - val_accuracy: 0.1407\n",
            "Epoch 496/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8335 - accuracy: 0.2569 - val_loss: 2.0981 - val_accuracy: 0.1370\n",
            "Epoch 497/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8333 - accuracy: 0.2653 - val_loss: 2.0957 - val_accuracy: 0.1414\n",
            "Epoch 498/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8323 - accuracy: 0.2562 - val_loss: 2.0939 - val_accuracy: 0.1327\n",
            "Epoch 499/500\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 1.8327 - accuracy: 0.2644 - val_loss: 2.0999 - val_accuracy: 0.1312\n",
            "Epoch 500/500\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.8342 - accuracy: 0.2595 - val_loss: 2.0947 - val_accuracy: 0.1319\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 2.0638 - accuracy: 0.1429\n",
            "Individual Signal Prediction Test Loss: 2.0637872219085693, Test Accuracy: 0.1428571492433548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model on the test set"
      ],
      "metadata": {
        "id": "-8L4Y3qMPQf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_signal, accuracy_signal = model_signal.evaluate(X_test_scaled_signal, y_test_signal)\n",
        "print(f'Individual Signal Prediction Test Loss: {loss_signal}, Test Accuracy: {accuracy_signal}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE8SU4hePS3G",
        "outputId": "fbe88a04-b10e-4cfd-f9b7-95654a2dae4d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54/54 [==============================] - 0s 1ms/step - loss: 2.0638 - accuracy: 0.1429\n",
            "Individual Signal Prediction Test Loss: 2.0637872219085693, Test Accuracy: 0.1428571492433548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate confusion matrix"
      ],
      "metadata": {
        "id": "E6SkyV00PBWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_pred_prob = model_class.predict(X_test_scaled_signal)\n",
        "\n",
        "y_pred_class = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test_class, y_pred_class)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# classification report\n",
        "cr = classification_report(y_test_class, y_pred_class)\n",
        "print('Classification Report:')\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "j6m4tc2UanlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadab597-8c07-460c-9b65-7520039278f8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54/54 [==============================] - 0s 2ms/step\n",
            "Confusion Matrix:\n",
            "[[26 19 26 48 40 29 29]\n",
            " [34 38 25 46 39 33 32]\n",
            " [25 39 34 39 42 33 38]\n",
            " [19 33 27 43 29 49 33]\n",
            " [23 30 33 43 43 41 50]\n",
            " [32 30 30 48 35 41 36]\n",
            " [27 26 43 51 37 35 34]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.12      0.13       217\n",
            "           1       0.18      0.15      0.16       247\n",
            "           2       0.16      0.14      0.15       250\n",
            "           3       0.14      0.18      0.16       233\n",
            "           4       0.16      0.16      0.16       263\n",
            "           5       0.16      0.16      0.16       252\n",
            "           6       0.13      0.13      0.13       253\n",
            "\n",
            "    accuracy                           0.15      1715\n",
            "   macro avg       0.15      0.15      0.15      1715\n",
            "weighted avg       0.15      0.15      0.15      1715\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BT6U2lopQSuS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}